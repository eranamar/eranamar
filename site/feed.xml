<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.7.4">Jekyll</generator><link href="https://eranamar.github.io/site/feed.xml" rel="self" type="application/atom+xml" /><link href="https://eranamar.github.io/site/" rel="alternate" type="text/html" /><updated>2019-11-07T19:28:21+02:00</updated><id>https://eranamar.github.io/site/feed.xml</id><title type="html">TheoryLunch Blog</title><subtitle>Computer science topics over lunch</subtitle><author><name>Eran Amar</name></author><entry><title type="html">Dynamic-Graph Orientation</title><link href="https://eranamar.github.io/site/2018/01/17/Dynamic-Graph-Orientation.html" rel="alternate" type="text/html" title="Dynamic-Graph Orientation" /><published>2018-01-17T00:00:00+02:00</published><updated>2018-01-17T00:00:00+02:00</updated><id>https://eranamar.github.io/site/2018/01/17/Dynamic-Graph-Orientation</id><content type="html" xml:base="https://eranamar.github.io/site/2018/01/17/Dynamic-Graph-Orientation.html">&lt;script type=&quot;math/tex&quot;&gt;
\newcommand{\lyxlock}{}
&lt;/script&gt;

&lt;noscript&gt;
&lt;div class=&quot;warning&quot;&gt;
Warning: &lt;a href=&quot;http://www.mathjax.org/&quot;&gt;MathJax&lt;/a&gt; requires JavaScript to correctly process the mathematics on this page. Please enable JavaScript on your browser.
&lt;/div&gt;&lt;hr /&gt;
&amp;lt;/hr&amp;gt;&lt;/noscript&gt;

&lt;h1 class=&quot;Section&quot;&gt;
&lt;a class=&quot;toc&quot; name=&quot;toc-Section-1&quot;&gt;1&lt;/a&gt; Orienting Acyclic Graphs
&lt;/h1&gt;
&lt;div class=&quot;Unindented&quot;&gt;
Throughout this post, &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
G=\left(V,E\right)
&lt;/script&gt;
&lt;/span&gt; is an undirected acyclic graph on &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
n
&lt;/script&gt;
&lt;/span&gt; vertices and &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
m\le n-1
&lt;/script&gt;
&lt;/span&gt; edges. The problem we want to solve is called &lt;i&gt;graph orientation&lt;/i&gt;:
&lt;/div&gt;
&lt;div class=&quot;Indented&quot;&gt;
The input &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
G
&lt;/script&gt;
&lt;/span&gt; is given in the &lt;i&gt;insertion-only&lt;/i&gt; streaming model. That is, we know &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
V
&lt;/script&gt;
&lt;/span&gt; in advance, and the set &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
E
&lt;/script&gt;
&lt;/span&gt; is being revealed one edge at a time. For each edge &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\left(u,v\right)\in E
&lt;/script&gt;
&lt;/span&gt; that we get, we need to assign a direction (i.e. an orientation), meaning to decide that it either points to &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
u
&lt;/script&gt;
&lt;/span&gt; or to &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
v
&lt;/script&gt;
&lt;/span&gt;. When &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
u
&lt;/script&gt;
&lt;/span&gt; points to &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
v
&lt;/script&gt;
&lt;/span&gt; we denote it by &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
u\rightarrow v
&lt;/script&gt;
&lt;/span&gt;. Note that when we assign a direction to a new edge, we may as well update the orientation of previously seen edges. When the stream ends, we left with a directed version of &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
G
&lt;/script&gt;
&lt;/span&gt;, denote it &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\hat{G}=\left(V,\hat{E}\right)
&lt;/script&gt;
&lt;/span&gt;. 
&lt;/div&gt;
&lt;div class=&quot;Indented&quot;&gt;
We are interested in two metrics: the first is the&lt;i&gt; outgoing degree bound&lt;/i&gt;, which is defined by the term &lt;span class=&quot;MathJax_Preview&quot;&gt;
&lt;script type=&quot;math/tex;mode=display&quot;&gt;

deg\left(\hat{G}\right):=\max_{v\in V}deg_{out}\left(v;\hat{G}\right)

&lt;/script&gt;
&lt;/span&gt;
 where &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
deg_{out}(v;\hat{G}):=\left|\left\{ u\in V\mid v\rightarrow u\right\} \right|
&lt;/script&gt;
&lt;/span&gt; is the number of &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
v
&lt;/script&gt;
&lt;/span&gt;’s neighbors which &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
v
&lt;/script&gt;
&lt;/span&gt; points to, in the oriented graph &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\hat{G}
&lt;/script&gt;
&lt;/span&gt;.
&lt;/div&gt;
&lt;div class=&quot;Indented&quot;&gt;
The second metric is a bound on the &lt;i&gt;orientation cost&lt;/i&gt; for a single step of the stream. That is, a bound on the number of edge updates for every time a new edge is being revealed. 
&lt;/div&gt;
&lt;div class=&quot;Indented&quot;&gt;
Due to the fact that &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
G
&lt;/script&gt;
&lt;/span&gt; is acyclic, we know it is actually a collection of one or more trees, then there exists an orientation &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\hat{G}
&lt;/script&gt;
&lt;/span&gt; in which &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
deg\left(\hat{G}\right)\le1
&lt;/script&gt;
&lt;/span&gt; (think that each node points to its parent in its corresponding tree).
&lt;/div&gt;
&lt;h1 class=&quot;Section&quot;&gt;
&lt;a class=&quot;toc&quot; name=&quot;toc-Section-2&quot;&gt;2&lt;/a&gt; &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\mathcal{O}\left(1\right)
&lt;/script&gt;
&lt;/span&gt; Orientation Cost
&lt;/h1&gt;
&lt;div class=&quot;Unindented&quot;&gt;
Lets start with a very simple orientation rule: For every step of the stream, let &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
e_{i}=\left(u,v\right)
&lt;/script&gt;
&lt;/span&gt; be the edge given in the current step, and &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
E_{i}=\left\{ e_{1},..,e_{i}\right\} 
&lt;/script&gt;
&lt;/span&gt;. Consider the endpoints of &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
e_{i}
&lt;/script&gt;
&lt;/span&gt;. If &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
u
&lt;/script&gt;
&lt;/span&gt; belongs to a larger connected component relative to the connected component of &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
v
&lt;/script&gt;
&lt;/span&gt;, under the graph induced by &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
E_{i}
&lt;/script&gt;
&lt;/span&gt;, then orient &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
e_{i}
&lt;/script&gt;
&lt;/span&gt; to be &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
v\rightarrow u
&lt;/script&gt;
&lt;/span&gt;, otherwise orient it &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
u\rightarrow v
&lt;/script&gt;
&lt;/span&gt;. Note that &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
u
&lt;/script&gt;
&lt;/span&gt; and &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
v
&lt;/script&gt;
&lt;/span&gt; cannot be in the same connected component in &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
G_{i}=\left(V,E_{i}\right)
&lt;/script&gt;
&lt;/span&gt;.
&lt;/div&gt;
&lt;div class=&quot;Indented&quot;&gt;
Obviously, that update rule has constant orientation cost (in particular it never change the orientations of previous edges). However, the outgoing degree bound is &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\mathcal{O}\left(\log n\right)
&lt;/script&gt;
&lt;/span&gt;. To prove that, consider some arbitrary vertex &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
v
&lt;/script&gt;
&lt;/span&gt;. We increase its outgoing degree by &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
1
&lt;/script&gt;
&lt;/span&gt; when we make it points to another &lt;i&gt;larger&lt;/i&gt; connected component. So every time the outgoing degree of &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
v
&lt;/script&gt;
&lt;/span&gt; increases by &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
1
&lt;/script&gt;
&lt;/span&gt;, the size of its connected component is at least doubled. Since we have &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
n
&lt;/script&gt;
&lt;/span&gt; vertices, we cannot double that size more than &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\log_{2}n
&lt;/script&gt;
&lt;/span&gt; times.
&lt;/div&gt;
&lt;h1 class=&quot;Section&quot;&gt;
&lt;a class=&quot;toc&quot; name=&quot;toc-Section-3&quot;&gt;3&lt;/a&gt; &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\mathcal{O}\left(1\right)
&lt;/script&gt;
&lt;/span&gt; Outgoing Degree Bound
&lt;/h1&gt;
&lt;div class=&quot;Unindented&quot;&gt;
Now we will see an update rule that yields a constant degree bound, say &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
4
&lt;/script&gt;
&lt;/span&gt;: 
&lt;/div&gt;
&lt;div class=&quot;Indented&quot;&gt;
Upon receiving &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
e_{i}=\left(u,v\right)
&lt;/script&gt;
&lt;/span&gt;, orient it &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
v\rightarrow u
&lt;/script&gt;
&lt;/span&gt;. Then, if the outgoing degree of &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
v
&lt;/script&gt;
&lt;/span&gt; exceeds &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
4
&lt;/script&gt;
&lt;/span&gt;, we apply &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
makeSink\left(v\right)
&lt;/script&gt;
&lt;/span&gt;. This procedure will flip the orientation of any outgoing edge of &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
v
&lt;/script&gt;
&lt;/span&gt;. Next, check any neighbor &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
u
&lt;/script&gt;
&lt;/span&gt; that was affected by this change, and apply &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
makeSink\left(u\right)
&lt;/script&gt;
&lt;/span&gt; if it has more than &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
4
&lt;/script&gt;
&lt;/span&gt; outgoing edges. This process continues recursively until no orientation is changed.
&lt;/div&gt;
&lt;div class=&quot;Indented&quot;&gt;
Interesting question that immediately pops to mind is, &lt;i&gt;why this process of recursive updates eventually terminates? &lt;/i&gt;
&lt;/div&gt;
&lt;div class=&quot;Indented&quot;&gt;
To see that infinite oscillation is impossible, consider some optimal orientation of &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
G
&lt;/script&gt;
&lt;/span&gt;, denote it &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\hat{G}^{*}
&lt;/script&gt;
&lt;/span&gt;, in which &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
deg\left(\hat{G}^{*}\right)\le1
&lt;/script&gt;
&lt;/span&gt;. Suppose that &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
e_{i}=\left(v,u_{1}\right)
&lt;/script&gt;
&lt;/span&gt; was revealed to the stream, and let &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
u_{1},u_{2},...
&lt;/script&gt;
&lt;/span&gt; be the chain of vertices that we applied &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
makeSink\left(\cdot\right)
&lt;/script&gt;
&lt;/span&gt; to, after orienting it. Denote by &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\phi_{k}
&lt;/script&gt;
&lt;/span&gt; the number of edges in &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
G_{i}=\left(V,E_{i}\right)
&lt;/script&gt;
&lt;/span&gt; that don’t agree with &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\hat{G}^{*}
&lt;/script&gt;
&lt;/span&gt;, after applying &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
makeSink\left(\cdot\right)
&lt;/script&gt;
&lt;/span&gt; on &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
u_{1},..,u_{k}
&lt;/script&gt;
&lt;/span&gt;. So for example, &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\phi_{0}
&lt;/script&gt;
&lt;/span&gt; is the number of conflicting edges right after we inserted &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
e_{i}
&lt;/script&gt;
&lt;/span&gt; but before we start the recursive fixing process, and &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\phi_{1}
&lt;/script&gt;
&lt;/span&gt; is the number of conflicting edges after we flip all the outgoing edges of &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
u_{1}
&lt;/script&gt;
&lt;/span&gt;, and so on.
&lt;/div&gt;
&lt;div class=&quot;Indented&quot;&gt;
We will show that &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\phi_{0},\phi_{1},..
&lt;/script&gt;
&lt;/span&gt; is a strictly decreasing series, and since &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\phi_{k}
&lt;/script&gt;
&lt;/span&gt; cannot be negative, that series must terminates. Fix some &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\phi_{k}
&lt;/script&gt;
&lt;/span&gt;, which is the number of edges conflicting with &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\hat{G}^{*}
&lt;/script&gt;
&lt;/span&gt; before applying &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
makeSink\left(u_{k+1}\right)
&lt;/script&gt;
&lt;/span&gt;. In that moment, &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
deg_{out}\left(u_{k+1}\right)&gt;4
&lt;/script&gt;
&lt;/span&gt;, but in the optimal orientation it should be at most &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
1
&lt;/script&gt;
&lt;/span&gt;, which means that at least &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
4
&lt;/script&gt;
&lt;/span&gt; of &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
u_{k+1}
&lt;/script&gt;
&lt;/span&gt;’s outgoing edges have wrong orientations. So applying &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
makeSink\left(u_{k+1}\right)
&lt;/script&gt;
&lt;/span&gt; adding up to one conflicting edge, but on the other hand, fixing the orientation of at least &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
4
&lt;/script&gt;
&lt;/span&gt; other edges, thus the total number of conflicting edges with &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\hat{G}^{*}
&lt;/script&gt;
&lt;/span&gt; decreased by at least &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
3
&lt;/script&gt;
&lt;/span&gt;, i.e. &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\phi_{k}\ge3+\phi_{k+1}
&lt;/script&gt;
&lt;/span&gt;. 
&lt;/div&gt;
&lt;div class=&quot;Indented&quot;&gt;
It is immediate that this algorithm yields an orientation with outgoing degree bound of &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
4
&lt;/script&gt;
&lt;/span&gt;. We now move to show that the &lt;i&gt;amortize&lt;/i&gt; orientation cost is also constant. To show that we will use the &lt;a class=&quot;URL&quot; href=&quot;https://en.wikipedia.org/wiki/Accounting_method_(computer_science)&quot;&gt;accounting method&lt;/a&gt;, in which we assign positive and negative values to different operations that we perform during processing the stream. As long as those values are constants, if in every step of the stream the aggregated value is non-negative, then we may conclude that the amortize cost per operation is also constant. So suppose that the action of inserting a new edge has a value of &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
+2
&lt;/script&gt;
&lt;/span&gt;, and flipping orientation of an existing edge has a value of &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
-1
&lt;/script&gt;
&lt;/span&gt;. We first prove the following claim.
&lt;/div&gt;
&lt;div class=&quot;Claim&quot;&gt;
Suppose we got a new edge &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
e_{i}
&lt;/script&gt;
&lt;/span&gt;, and let &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
u_{1},u_{2},...,u_{k}
&lt;/script&gt;
&lt;/span&gt; be the series of vertices that we applied on &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
makeSink
&lt;/script&gt;
&lt;/span&gt; during the recursive fixing process, after inserting &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
e_{i}
&lt;/script&gt;
&lt;/span&gt; to the graph. Then, all &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
u_{1},u_{2},...,u_{k}
&lt;/script&gt;
&lt;/span&gt; are distinct, and the value of &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
makeSink\left(u_{t}\right)
&lt;/script&gt;
&lt;/span&gt; is exactly &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
-5
&lt;/script&gt;
&lt;/span&gt; for any &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
t\in\left\{ 1,...,k\right\} 
&lt;/script&gt;
&lt;/span&gt;.
&lt;/div&gt;
&lt;div class=&quot;Proof&quot;&gt;
For the first part, if there is a vertex in &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
u_{1},u_{2},...,u_{k}
&lt;/script&gt;
&lt;/span&gt; appearing twice, it means that we found a cycle in &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
G
&lt;/script&gt;
&lt;/span&gt; which is impossible. For the second part, assume toward contradiction that we have &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
t\in\left\{ 1,..,k\right\} 
&lt;/script&gt;
&lt;/span&gt; such that the outgoing degree of &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
u_{t}
&lt;/script&gt;
&lt;/span&gt; was at least 6. It must be due to &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
makeSink\left(\cdot\right)
&lt;/script&gt;
&lt;/span&gt; application on some vertices from &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\left\{ u_{1},...,u_{t-1}\right\} 
&lt;/script&gt;
&lt;/span&gt;, which means that &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
u_{t}
&lt;/script&gt;
&lt;/span&gt; has two neighbors in &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\left\{ u_{1},...,u_{t-1}\right\} 
&lt;/script&gt;
&lt;/span&gt;, and we know that those neighbors are connected, so we found a cycle in &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
G
&lt;/script&gt;
&lt;/span&gt; and that is a contradiction.
&lt;/div&gt;
&lt;div class=&quot;Unindented&quot;&gt;

&lt;/div&gt;
&lt;div class=&quot;Indented&quot;&gt;
It is left to show that at any point in time, the total value of previous operation is non negative. The following claim prove that.
&lt;/div&gt;
&lt;div class=&quot;Claim&quot;&gt;
For every step, &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
i
&lt;/script&gt;
&lt;/span&gt;, of the stream, let &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
e_{i}
&lt;/script&gt;
&lt;/span&gt; be the edge revealed on that step. Let &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
u_{i,1},u_{i,2},...,u_{i,k_{i}}
&lt;/script&gt;
&lt;/span&gt; be the series of vertices that we applied on &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
makeSink
&lt;/script&gt;
&lt;/span&gt; during the recursive fixing process, with &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\phi_{i,0,}...,\phi_{i,k_{i}}
&lt;/script&gt;
&lt;/span&gt; as defined before. Denote by &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\psi_{i,t}
&lt;/script&gt;
&lt;/span&gt; the aggregated value of all the operations done until inserting &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
e_{i}
&lt;/script&gt;
&lt;/span&gt; (including) and after applying &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
makeSink
&lt;/script&gt;
&lt;/span&gt; to &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\left\{ u_{1},..,u_{t}\right\} 
&lt;/script&gt;
&lt;/span&gt;. Then, &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\psi_{i,t}\ge2\cdot\phi_{i,t}
&lt;/script&gt;
&lt;/span&gt; for any &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
t
&lt;/script&gt;
&lt;/span&gt;.
&lt;/div&gt;
&lt;div class=&quot;Proof&quot;&gt;
By induction on &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
i
&lt;/script&gt;
&lt;/span&gt;. For &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
i=1
&lt;/script&gt;
&lt;/span&gt;, note that &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\phi_{1,0}=0
&lt;/script&gt;
&lt;/span&gt; and &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\psi_{1,0}=3
&lt;/script&gt;
&lt;/span&gt;. For &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
i&gt;1
&lt;/script&gt;
&lt;/span&gt;, we have &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\psi_{i,0}=\psi_{i-1,k_{i-1}}+2
&lt;/script&gt;
&lt;/span&gt; and &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\phi_{i,0}\le\phi_{i-1,k_{i-1}}+1
&lt;/script&gt;
&lt;/span&gt;, so using the induction hypothesis, &lt;span class=&quot;MathJax_Preview&quot;&gt;
&lt;script type=&quot;math/tex;mode=display&quot;&gt;

\psi_{i,0}\ge2+2\cdot\phi_{i-1,k_{i-1}}\ge2\cdot\phi_{i,0}

&lt;/script&gt;
&lt;/span&gt;
 for &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
t&gt;0
&lt;/script&gt;
&lt;/span&gt;, assume by induction on &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
t
&lt;/script&gt;
&lt;/span&gt; that the claim holds, then &lt;span class=&quot;MathJax_Preview&quot;&gt;
&lt;script type=&quot;math/tex;mode=display&quot;&gt;

\psi_{i,t}=\psi_{i,t-1}-5\ge2\cdot\phi_{i,t-1}-5\ge2\left(\phi_{i,t}+3\right)-5\ge2\phi_{i,t}

&lt;/script&gt;
&lt;/span&gt;
&lt;/div&gt;
&lt;div class=&quot;Unindented&quot;&gt;

&lt;/div&gt;
&lt;h1 class=&quot;Section&quot;&gt;
&lt;a class=&quot;toc&quot; name=&quot;toc-Section-4&quot;&gt;4&lt;/a&gt; Releasing the Assumptions
&lt;/h1&gt;
&lt;div class=&quot;Unindented&quot;&gt;
This post dealt with a relative simple model, in which the stream only revealing new edges but never deleting a previously seen one. In addition, we assume that our graph is acyclic which is also a very strong assumption. There are works that shows more sophisticated streaming algorithm for fully dynamic graphs (i.e. with edges insertions and &lt;i&gt;deletions&lt;/i&gt;), and also works on general graphs that are not necessarily acyclic. Further details can be found in this &lt;a class=&quot;URL&quot; href=&quot;https://arxiv.org/abs/1312.1382&quot;&gt;paper&lt;/a&gt;.
&lt;/div&gt;</content><author><name>Eran Amar</name></author><category term="graphs" /><category term="streaming_algorithm" /><summary type="html">Warning: MathJax requires JavaScript to correctly process the mathematics on this page. Please enable JavaScript on your browser. &amp;lt;/hr&amp;gt;</summary></entry><entry><title type="html">Last TheoryLunch at Weizmann - Cut Equivalent Trees</title><link href="https://eranamar.github.io/site/2017/10/08/Last-TheoryLunch-at-Weizmann-Cut-Equivalent-Trees.html" rel="alternate" type="text/html" title="Last TheoryLunch at Weizmann - Cut Equivalent Trees" /><published>2017-10-08T00:00:00+03:00</published><updated>2017-10-08T00:00:00+03:00</updated><id>https://eranamar.github.io/site/2017/10/08/Last-TheoryLunch-at-Weizmann---Cut-Equivalent-Trees</id><content type="html" xml:base="https://eranamar.github.io/site/2017/10/08/Last-TheoryLunch-at-Weizmann-Cut-Equivalent-Trees.html">&lt;script type=&quot;math/tex&quot;&gt;
\newcommand{\lyxlock}{}
&lt;/script&gt;

&lt;noscript&gt;
&lt;div class=&quot;warning&quot;&gt;
Warning: &lt;a href=&quot;http://www.mathjax.org/&quot;&gt;MathJax&lt;/a&gt; requires JavaScript to correctly process the mathematics on this page. Please enable JavaScript on your browser.
&lt;/div&gt;&lt;hr /&gt;
&amp;lt;/hr&amp;gt;&lt;/noscript&gt;

&lt;h1 class=&quot;Section&quot;&gt;
&lt;a class=&quot;toc&quot; name=&quot;toc-Section-1&quot;&gt;1&lt;/a&gt; Last TheoryLunch Meeting at Weizmann Institute of Science
&lt;/h1&gt;
&lt;div class=&quot;Unindented&quot;&gt;
For those of you who don’t know, this blog originated from my lunch meetings with my friends at &lt;a class=&quot;URL&quot; href=&quot;https://www.weizmann.ac.il/feinberg/academics/msc-program-outline&quot;&gt;Weizmann Institute of Science&lt;/a&gt; during my Master studies. As all good things comes to an end, also did my time at Weizmann, and last week our lunch group gathered for the last time. This post presents the topic discussed on that meeting.
&lt;/div&gt;
&lt;div class=&quot;Indented&quot;&gt;
I want to thank my good friends, Yosef Pogrow and Ron Shiff, for the great time we had and for all the enriching lunch meetings (also those which didn’t include theory). Without you guys, this blog would not have been created, I wish you both best of luck ahead!
&lt;/div&gt;
&lt;div class=&quot;Indented&quot;&gt;
This post, by the way, contains some results from the research of Yosef Pogrow (who also presented most of the meetings). 
&lt;/div&gt;
&lt;h1 class=&quot;Section&quot;&gt;
&lt;a class=&quot;toc&quot; name=&quot;toc-Section-2&quot;&gt;2&lt;/a&gt; Min-Cuts in a Graph
&lt;/h1&gt;
&lt;div class=&quot;Unindented&quot;&gt;
This post deals with undirected, weighted graphs and cuts on them. We denote by &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
G=\left(V,E_{G},w_{G}\right)
&lt;/script&gt;
&lt;/span&gt; the graph equipped with a weight function on its edges. A &lt;i&gt;cut&lt;/i&gt; in this graph is a partition of its vertices to &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\left(S,V\backslash S\right)
&lt;/script&gt;
&lt;/span&gt; where &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
S\subseteq V
&lt;/script&gt;
&lt;/span&gt;. For simplicity, we will only mention one of the parts in the partition, usually &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
S
&lt;/script&gt;
&lt;/span&gt;. Note that it doesn’t matter whether we refer to the first part in the partition &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
S
&lt;/script&gt;
&lt;/span&gt;, or to the second part &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
V\backslash S
&lt;/script&gt;
&lt;/span&gt;, because both parts define the same cut.
&lt;/div&gt;
&lt;div class=&quot;Indented&quot;&gt;
The &lt;i&gt;value&lt;/i&gt; of the cut is defined as&lt;span class=&quot;MathJax_Preview&quot;&gt;
&lt;script type=&quot;math/tex;mode=display&quot;&gt;

w_{G}\left(S\right):=\sum_{uv\in E_{G},u\in S,v\notin S}w_{G}\left(uv\right)

&lt;/script&gt;
&lt;/span&gt;
&lt;/div&gt;
&lt;div class=&quot;Indented&quot;&gt;
A &lt;i&gt;min &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
st
&lt;/script&gt;
&lt;/span&gt;-cut&lt;/i&gt; for a pair &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
s\ne t\in V
&lt;/script&gt;
&lt;/span&gt; is a cut defined by &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
S\subseteq V
&lt;/script&gt;
&lt;/span&gt; such that &lt;span class=&quot;MathJax_Preview&quot;&gt;
&lt;script type=&quot;math/tex;mode=display&quot;&gt;

S=\arg\min_{S'\subseteq V}w_{G}\left(S'\right)

&lt;/script&gt;
&lt;/span&gt;
note that it is possible that several cuts will satisfy the definition above, but for our purposes they are equivalent (since they all have the same value).
&lt;/div&gt;
&lt;div class=&quot;Indented&quot;&gt;
Before diving into the theorem about cut equivalent trees, we setup the following notation. For a given tree &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
T=\left(V,E\right)
&lt;/script&gt;
&lt;/span&gt; and any edge &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
uv\in E
&lt;/script&gt;
&lt;/span&gt;, removing that edge from the tree breaks it down into two connected components, one that contains &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
u
&lt;/script&gt;
&lt;/span&gt;, and another one that contains &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
v
&lt;/script&gt;
&lt;/span&gt;. Denote the component containing &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
u
&lt;/script&gt;
&lt;/span&gt; as &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
S_{T|u}\subseteq V
&lt;/script&gt;
&lt;/span&gt;, and then the other component is exactly &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
S_{T|v}:=V\backslash S_{T|u}
&lt;/script&gt;
&lt;/span&gt;. Since the only path connecting &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
u
&lt;/script&gt;
&lt;/span&gt; and &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
v
&lt;/script&gt;
&lt;/span&gt; was the removed edge, then &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
S_{T|u}
&lt;/script&gt;
&lt;/span&gt; is actually the min &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
uv
&lt;/script&gt;
&lt;/span&gt;-cut in &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
T
&lt;/script&gt;
&lt;/span&gt; (the same is true for &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
S_{T|v}
&lt;/script&gt;
&lt;/span&gt; since it defines the same cut). 
&lt;/div&gt;
&lt;div class=&quot;Indented&quot;&gt;
A simple fact about trees is, that for any tree &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
T
&lt;/script&gt;
&lt;/span&gt; and vertices &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
s\ne t
&lt;/script&gt;
&lt;/span&gt; inside it, the min &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
st
&lt;/script&gt;
&lt;/span&gt;-cut is given by &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
S_{T|u}
&lt;/script&gt;
&lt;/span&gt; where &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
uv\in E_{T}
&lt;/script&gt;
&lt;/span&gt; is the edge with &lt;i&gt;minimum weight&lt;/i&gt; along the path that connects &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
s
&lt;/script&gt;
&lt;/span&gt; and &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
t
&lt;/script&gt;
&lt;/span&gt;. Since any &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
n
&lt;/script&gt;
&lt;/span&gt; vertices tree has exactly &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
n-1
&lt;/script&gt;
&lt;/span&gt; edges, there are at most &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
n-1
&lt;/script&gt;
&lt;/span&gt; unique &lt;i&gt;values&lt;/i&gt; of min-cuts that the tree can yield.
&lt;/div&gt;
&lt;div class=&quot;Theorem&quot;&gt;
Cut-Equivalent Trees [Gomory and Hu, 1961]. For any weighted undirected graph &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
G=\left(V,E_{G},w_{G}\right)
&lt;/script&gt;
&lt;/span&gt; there is a weighted tree on the same set of vertices &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
T=\left(V,E_{T},w_{T}\right)
&lt;/script&gt;
&lt;/span&gt; such that:&lt;br /&gt;
(a) for any &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
s\ne t\in V
&lt;/script&gt;
&lt;/span&gt;, the value of the min &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
st
&lt;/script&gt;
&lt;/span&gt;-cut in &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
G
&lt;/script&gt;
&lt;/span&gt; is equal the value of the min &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
st
&lt;/script&gt;
&lt;/span&gt;-cut in &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
T
&lt;/script&gt;
&lt;/span&gt; (with respect to their respective weight functions), and&lt;br /&gt;
(b) for any edge &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
uv\in E_{T}
&lt;/script&gt;
&lt;/span&gt;, &lt;span class=&quot;MathJax_Preview&quot;&gt;
&lt;script type=&quot;math/tex;mode=display&quot;&gt;

w_{T}\left(S_{T|u}\right)=w_{G}\left(S_{T|u}\right)

&lt;/script&gt;
&lt;/span&gt;
Such trees are known as Cut-Equivalent trees (also known as GH-trees).
&lt;/div&gt;
&lt;div class=&quot;Unindented&quot;&gt;

&lt;/div&gt;
&lt;div class=&quot;Indented&quot;&gt;
The proof is omitted from this post, and we move to discuss a nice implication of that theorem: it puts a limit on the number of different min-cut &lt;i&gt;values&lt;/i&gt; that a graph can have. Since there are &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
{n \choose 2}
&lt;/script&gt;
&lt;/span&gt; different &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
st
&lt;/script&gt;
&lt;/span&gt; pairs in a graph there can be potentially &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
{n \choose 2}
&lt;/script&gt;
&lt;/span&gt; unique min-cut values, however, the theorem says that any value of a min-cut in &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
G
&lt;/script&gt;
&lt;/span&gt; is being represented by a (possibly different) min-cut in &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
T
&lt;/script&gt;
&lt;/span&gt;, and there are at most &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
n-1
&lt;/script&gt;
&lt;/span&gt; min-cut values in &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
T
&lt;/script&gt;
&lt;/span&gt;, then &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
G
&lt;/script&gt;
&lt;/span&gt; has at most &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
n-1
&lt;/script&gt;
&lt;/span&gt; unique min-cut values.
&lt;/div&gt;
&lt;h1 class=&quot;Section&quot;&gt;
&lt;a class=&quot;toc&quot; name=&quot;toc-Section-3&quot;&gt;3&lt;/a&gt; General Cuts in a Graph
&lt;/h1&gt;
&lt;div class=&quot;Unindented&quot;&gt;
Until now, we talked about minimum &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
st
&lt;/script&gt;
&lt;/span&gt; cuts. The theorem above state that for any graph &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
G
&lt;/script&gt;
&lt;/span&gt;, there is a cut-equivalent tree &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
T
&lt;/script&gt;
&lt;/span&gt; that can tell us much about all the minimum cuts in &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
G
&lt;/script&gt;
&lt;/span&gt;. It can tell us all the possible min-cut values that &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
G
&lt;/script&gt;
&lt;/span&gt; can have, moreover, for any min-cut value &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
x
&lt;/script&gt;
&lt;/span&gt;, there is a very easy way to find a cut in &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
G
&lt;/script&gt;
&lt;/span&gt; that have this exact value. All we need to do is to find an edge in the tree that have weight &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
x
&lt;/script&gt;
&lt;/span&gt;, suppose that edge is &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
uv\in E_{T}
&lt;/script&gt;
&lt;/span&gt;, and the desired cut in &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
G
&lt;/script&gt;
&lt;/span&gt; is given by &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
S_{T|u}
&lt;/script&gt;
&lt;/span&gt;.
&lt;/div&gt;
&lt;div class=&quot;Indented&quot;&gt;
One interesting question to ask is, &lt;i&gt;what cut-equivalent trees can tell us about “general” cuts?&lt;/i&gt; The answer is given in the following theorem.
&lt;/div&gt;
&lt;div class=&quot;Theorem&quot;&gt;
[Krauthgamer and Pogrow, 2017]. Let &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
G=\left(V,E_{G},w_{G}\right)
&lt;/script&gt;
&lt;/span&gt; be a weighted undirected graph with &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
n
&lt;/script&gt;
&lt;/span&gt; vertices, and let &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
T=\left(V,E_{T},w_{T}\right)
&lt;/script&gt;
&lt;/span&gt; be a cut-equivalent tree of &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
G
&lt;/script&gt;
&lt;/span&gt;. Then for &lt;b&gt;any&lt;/b&gt; &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
S\subseteq V
&lt;/script&gt;
&lt;/span&gt;&lt;span class=&quot;MathJax_Preview&quot;&gt;
&lt;script type=&quot;math/tex;mode=display&quot;&gt;

w_{G}\left(S\right)\le w_{T}\left(S\right)\le\left(n-1\right)\cdot w_{G}\left(S\right)

&lt;/script&gt;
&lt;/span&gt;
&lt;/div&gt;
&lt;div class=&quot;Proof&quot;&gt;
We start with the left-hand side. Recall that the value of a cut &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
S
&lt;/script&gt;
&lt;/span&gt; is the sum of weights of all the “crossing edges”, meaning, edges which have endpoints in both parts of the partition. Then, combined with the second property of the tree, and the fact that &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
w_{T}\left(st\right)=w_{T}\left(S_{T|s}\right)
&lt;/script&gt;
&lt;/span&gt; for any edge &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
st\in E_{T}
&lt;/script&gt;
&lt;/span&gt;, we get&lt;span class=&quot;MathJax_Preview&quot;&gt;
&lt;script type=&quot;math/tex;mode=display&quot;&gt;
\begin{aligned}
w_{T}\left(S\right) &amp; =\sum_{st\in E_{T},s\in S,t\notin S}w_{T}\left(st\right)\\
 &amp; =\sum_{st\in E_{T},s\in S,t\notin S}w_{G}\left(S_{T|s}\right)
\end{aligned}
&lt;/script&gt;
&lt;/span&gt;
so it is suffice to show that any crossing edge in the sum of the original graph &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
w_{G}\left(S\right)
&lt;/script&gt;
&lt;/span&gt;, contributes also to a sum of &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
w_{G}\left(S_{T|s}\right)
&lt;/script&gt;
&lt;/span&gt; for &lt;i&gt;some&lt;/i&gt; tree-edge &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
st\in E_{T}
&lt;/script&gt;
&lt;/span&gt; such that &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
s\in S,t\notin S
&lt;/script&gt;
&lt;/span&gt;. So fix some crossing edge &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
uv\in E_{G}
&lt;/script&gt;
&lt;/span&gt; (&lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
u\in S,v\in V\backslash S
&lt;/script&gt;
&lt;/span&gt;) from the original graph, and consider the unique path connecting &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
u
&lt;/script&gt;
&lt;/span&gt; and &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
v
&lt;/script&gt;
&lt;/span&gt; over the tree. Since we starting the path with a vertex from &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
S
&lt;/script&gt;
&lt;/span&gt; and ending with a vertex in &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
V\backslash S
&lt;/script&gt;
&lt;/span&gt;, there must be an edge &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
st\in E_{T}
&lt;/script&gt;
&lt;/span&gt; along the path such that &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
s\in S
&lt;/script&gt;
&lt;/span&gt; and &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
t\in V\backslash S
&lt;/script&gt;
&lt;/span&gt;. That edge &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
st
&lt;/script&gt;
&lt;/span&gt; separates &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
u
&lt;/script&gt;
&lt;/span&gt; from &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
v
&lt;/script&gt;
&lt;/span&gt; in the tree, so &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
u\in S_{T|s}
&lt;/script&gt;
&lt;/span&gt; and &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
v\notin S_{T|s}
&lt;/script&gt;
&lt;/span&gt;. Since &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
uv\in E_{G}
&lt;/script&gt;
&lt;/span&gt; then it contributes to &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
w_{G}\left(S_{T|s}\right)
&lt;/script&gt;
&lt;/span&gt;, which is what we wanted to prove.&lt;br /&gt;
We proceed to show the second inequality. For each &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
st\in E_{T}
&lt;/script&gt;
&lt;/span&gt; in the sum of &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
w_{T}\left(S\right)
&lt;/script&gt;
&lt;/span&gt;, we know that &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
w_{T}\left(st\right)\le w_{G}\left(S\right)
&lt;/script&gt;
&lt;/span&gt; since the weight of the tree-edge &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
w_{T}\left(st\right)
&lt;/script&gt;
&lt;/span&gt; is equal to the &lt;i&gt;min &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
st
&lt;/script&gt;
&lt;/span&gt;-cut&lt;/i&gt; in &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
G
&lt;/script&gt;
&lt;/span&gt;, thus in particular smaller or equal to the value of the cut &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
S
&lt;/script&gt;
&lt;/span&gt; (which also separates &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
s
&lt;/script&gt;
&lt;/span&gt; from &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
t
&lt;/script&gt;
&lt;/span&gt; but might not be of minimum weight). The inequality follows by summing over all the crossing edges in &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
S
&lt;/script&gt;
&lt;/span&gt; over &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
T
&lt;/script&gt;
&lt;/span&gt;, which is at most &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
n-1
&lt;/script&gt;
&lt;/span&gt; edges.
&lt;/div&gt;
&lt;div class=&quot;Unindented&quot;&gt;

&lt;/div&gt;
&lt;h1 class=&quot;Section&quot;&gt;
&lt;a class=&quot;toc&quot; name=&quot;toc-Section-4&quot;&gt;4&lt;/a&gt; The Inequalities are Tight
&lt;/h1&gt;
&lt;div class=&quot;Unindented&quot;&gt;
We conclude this post with examples for cases in which one of the inequalities became an equality. 
&lt;/div&gt;
&lt;div class=&quot;Indented&quot;&gt;
For the first inequality, take any graph &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
G
&lt;/script&gt;
&lt;/span&gt; and a corresponding cut equivalent tree &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
T
&lt;/script&gt;
&lt;/span&gt;. Fix an arbitrary tree-edge &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
st\in E_{T}
&lt;/script&gt;
&lt;/span&gt;. The cut &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
S=S_{T|s}
&lt;/script&gt;
&lt;/span&gt; is the min &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
st
&lt;/script&gt;
&lt;/span&gt;-cut in &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
T
&lt;/script&gt;
&lt;/span&gt; and by the first property of the tree &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
w_{G}\left(S\right)=w_{T}\left(S\right)
&lt;/script&gt;
&lt;/span&gt;.
&lt;/div&gt;
&lt;div class=&quot;Indented&quot;&gt;
For the second inequality, consider the complete graph on &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
n
&lt;/script&gt;
&lt;/span&gt; vertices with all its edges weighted &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
1
&lt;/script&gt;
&lt;/span&gt;. Its cut-equivalent tree must be a star in which every edge weighed &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
n-1
&lt;/script&gt;
&lt;/span&gt;. See example of an eight vertices star in the figure below (taken from Wikipedia).
&lt;/div&gt;
&lt;div class=&quot;Indented&quot;&gt;
&lt;div class=&quot;Frameless&quot; style=&quot;width: 100%;&quot;&gt;
&lt;div class=&quot;center&quot;&gt;
&lt;img alt=&quot;figure star_graph.png&quot; class=&quot;embedded&quot; src=&quot;/site/assets/imgs/2017-10-08-cut-equivalent-trees/star_graph.png&quot; style=&quot;width: 5cm; max-width: 1200px; height: auto; max-height: 1200px;&quot; /&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;Indented&quot;&gt;
Suppose the vertex in the center of the star is &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
v
&lt;/script&gt;
&lt;/span&gt;. The cut &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
S=\left\{ v\right\} 
&lt;/script&gt;
&lt;/span&gt; has weight of &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
n-1
&lt;/script&gt;
&lt;/span&gt; over &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
G
&lt;/script&gt;
&lt;/span&gt;, however, it has weight &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\left(n-1\right)^{2}
&lt;/script&gt;
&lt;/span&gt; in the star &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
T
&lt;/script&gt;
&lt;/span&gt; which is exactly &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\left(n-1\right)\cdot w_{G}\left(S\right)
&lt;/script&gt;
&lt;/span&gt;.
&lt;/div&gt;</content><author><name>Eran Amar</name></author><category term="graphs" /><category term="last_theory_lunch_weizmann" /><summary type="html">Warning: MathJax requires JavaScript to correctly process the mathematics on this page. Please enable JavaScript on your browser. &amp;lt;/hr&amp;gt;</summary></entry><entry><title type="html">On the Hardness of Counting Problems - Part 2</title><link href="https://eranamar.github.io/site/2017/07/18/On-the-Hardness-of-Counting-Problems-Part-2.html" rel="alternate" type="text/html" title="On the Hardness of Counting Problems - Part 2" /><published>2017-07-18T00:00:00+03:00</published><updated>2017-07-18T00:00:00+03:00</updated><id>https://eranamar.github.io/site/2017/07/18/On-the-Hardness-of-Counting-Problems---Part-2</id><content type="html" xml:base="https://eranamar.github.io/site/2017/07/18/On-the-Hardness-of-Counting-Problems-Part-2.html">&lt;script type=&quot;math/tex&quot;&gt;
\newcommand{\lyxlock}{}
&lt;/script&gt;

&lt;noscript&gt;
&lt;div class=&quot;warning&quot;&gt;
Warning: &lt;a href=&quot;http://www.mathjax.org/&quot;&gt;MathJax&lt;/a&gt; requires JavaScript to correctly process the mathematics on this page. Please enable JavaScript on your browser.
&lt;/div&gt;&lt;hr /&gt;
&amp;lt;/hr&amp;gt;&lt;/noscript&gt;

&lt;h1 class=&quot;Section&quot;&gt;
&lt;a class=&quot;toc&quot; name=&quot;toc-Section-1&quot;&gt;1&lt;/a&gt; Recap
&lt;/h1&gt;
&lt;div class=&quot;Unindented&quot;&gt;
The &lt;a class=&quot;URL&quot; href=&quot;https://eranamar.github.io/site/2017/07/06/On-the-Hardness-of-Counting-Problems-Part-1.html&quot;&gt;previous post&lt;/a&gt; discussed the &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\mathcal{P},\mathcal{NP}
&lt;/script&gt;
&lt;/span&gt; and &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\#\mathcal{P}
&lt;/script&gt;
&lt;/span&gt; families. We said that the hierarchy between decision problems from &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\mathcal{P},\mathcal{NP}
&lt;/script&gt;
&lt;/span&gt; do not preserved when moving to their Counting versions. We defined &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
CNF
&lt;/script&gt;
&lt;/span&gt; and &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
DNF
&lt;/script&gt;
&lt;/span&gt; formulas (see section 2 in previous post), and the problems &lt;i&gt;CNF-SAT &lt;/i&gt;that is &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\mathcal{NP}
&lt;/script&gt;
&lt;/span&gt;-complete and &lt;i&gt;DNF-SAT&lt;/i&gt; that is in &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\mathcal{P}
&lt;/script&gt;
&lt;/span&gt;. We used the relation between their Counting versions to show that &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\#DNF
&lt;/script&gt;
&lt;/span&gt; and &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\#CNF
&lt;/script&gt;
&lt;/span&gt; are equally hard to be solved exactly. The relation is as follows: if &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\phi
&lt;/script&gt;
&lt;/span&gt; is a &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
n
&lt;/script&gt;
&lt;/span&gt; variables &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
CNF
&lt;/script&gt;
&lt;/span&gt; formula, then &lt;span class=&quot;MathJax_Preview&quot;&gt;
&lt;script type=&quot;math/tex;mode=display&quot;&gt;

\#CNF\left(\phi\right)+\#DNF\left(\neg\phi\right)=2^{n}

&lt;/script&gt;
&lt;/span&gt;
Furthermore, we showed that both problems are &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\#\mathcal{P}
&lt;/script&gt;
&lt;/span&gt;-complete, demonstrating that even an “easy” decision problem like &lt;i&gt;DNF-SAT&lt;/i&gt; can be very hard when considering its Counting counterpart. 
&lt;/div&gt;
&lt;div class=&quot;Indented&quot;&gt;
This post we will show that there is some hierarchy inside &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\#\mathcal{P}
&lt;/script&gt;
&lt;/span&gt; when considering &lt;i&gt;approximated solutions&lt;/i&gt; instead of exact solutions.
&lt;/div&gt;
&lt;h1 class=&quot;Section&quot;&gt;
&lt;a class=&quot;toc&quot; name=&quot;toc-Section-2&quot;&gt;2&lt;/a&gt; Approximation Algorithm for &lt;i&gt;#DNF-SAT&lt;/i&gt;
&lt;/h1&gt;
&lt;h2 class=&quot;Subsection&quot;&gt;
&lt;a class=&quot;toc&quot; name=&quot;toc-Subsection-2.1&quot;&gt;2.1&lt;/a&gt; Deterministic Approximation
&lt;/h2&gt;
&lt;div class=&quot;Unindented&quot;&gt;
Let &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\psi=\bigvee_{i=1}^{m}C_{i}
&lt;/script&gt;
&lt;/span&gt; be a &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
DNF
&lt;/script&gt;
&lt;/span&gt; formula, and &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
k^{*}=\#DNF\left(\psi\right)
&lt;/script&gt;
&lt;/span&gt;. We want to find a polynomial time algorithm that yields some &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
k
&lt;/script&gt;
&lt;/span&gt; which is an approximation for &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
k^{*}
&lt;/script&gt;
&lt;/span&gt;. Formally, for an approximation factor of &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
p&gt;1
&lt;/script&gt;
&lt;/span&gt;, &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
k^{*}\le k\le p\cdot k^{*}
&lt;/script&gt;
&lt;/span&gt;. We will talk more about the approximation parameter later.
&lt;/div&gt;
&lt;div class=&quot;Indented&quot;&gt;
First note that if a clause contains a variable and its negation then immediately we can conclude that there are no satisfying assignments (s.a.) for that clause as it contains a contradiction, so we will omit it from the formula (can be done in linear time). So from now on, assume that &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\psi
&lt;/script&gt;
&lt;/span&gt; do not contain any contradiction. For the rest of this discussion, we say that a boolean variable &lt;i&gt;appear&lt;/i&gt; in a clause &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
C
&lt;/script&gt;
&lt;/span&gt; if either it or its negation contained in &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
C
&lt;/script&gt;
&lt;/span&gt;.
&lt;/div&gt;
&lt;div class=&quot;Indented&quot;&gt;
Let’s focus on an arbitrary clause &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
C_{i}\in\psi
&lt;/script&gt;
&lt;/span&gt; . We can easily count the number of s.a. it has; it is exactly &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\#DNF\left(C_{i}\right)=2^{t}
&lt;/script&gt;
&lt;/span&gt; when &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
t\in\left\{ 0,1,..,n-1\right\} 
&lt;/script&gt;
&lt;/span&gt; is the number of variables that do not appear in &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
C_{i}
&lt;/script&gt;
&lt;/span&gt;. That is true because the value of any variable in &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
C_{i}
&lt;/script&gt;
&lt;/span&gt; is determined by its appearance (if it has negation or not) so only variables which are not in &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
C_{i}
&lt;/script&gt;
&lt;/span&gt; can be either &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
True
&lt;/script&gt;
&lt;/span&gt; or &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
False
&lt;/script&gt;
&lt;/span&gt; and having two options.
&lt;/div&gt;
&lt;div class=&quot;Indented&quot;&gt;
Moreover, we can &lt;b&gt;efficiently &lt;/b&gt;sample at uniform any s.a. for that clause. Simply iterate over the &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
n
&lt;/script&gt;
&lt;/span&gt; variables, if a variable appears in &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
C_{i}
&lt;/script&gt;
&lt;/span&gt; then it have only one allowed value so assign it that value, and if it is not appear in &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
C_{i}
&lt;/script&gt;
&lt;/span&gt; then toss a coin and assign &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
True
&lt;/script&gt;
&lt;/span&gt; or &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
False
&lt;/script&gt;
&lt;/span&gt; accordingly. 
&lt;/div&gt;
&lt;div class=&quot;Indented&quot;&gt;
Trivial approximation algorithm will calculate the exact &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\#DNF\left(C_{i}\right)
&lt;/script&gt;
&lt;/span&gt; for each &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
C_{i}
&lt;/script&gt;
&lt;/span&gt; in &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\psi
&lt;/script&gt;
&lt;/span&gt; and returns their sum &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
k=\sum_{i=1}^{m}\#DNF\left(C_{i}\right)
&lt;/script&gt;
&lt;/span&gt;. However, we may have s.a. that were counted more than once (if they are satisfying more than a single clause). Thus the approximation factor of that algorithm is &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
m
&lt;/script&gt;
&lt;/span&gt;, because in the worst case all the clauses have the same set of satisfying assignments so we counted each s.a. &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
m
&lt;/script&gt;
&lt;/span&gt; times, yielding &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
k\le m\cdot k^{*}
&lt;/script&gt;
&lt;/span&gt;.
&lt;/div&gt;
&lt;div class=&quot;Indented&quot;&gt;
We can improve that algorithm by using the inclusion-exclusion principle: instead of accumulating the number of s.a. for each clause, accumulate the number of s.a. that &lt;i&gt;weren’t count so far&lt;/i&gt;.
&lt;/div&gt;
&lt;div class=&quot;Indented&quot;&gt;
Unfortunately, finding which assignment was already counted forces us to enumerate all possible assignments, which obviously takes exponential time. Hence we will give a probabilistic estimation for that, instead. When working with estimations, we need to state the success probability for our estimation and it is also preferable that we will have a way to increase that probability (mostly at the cost of more computations and drawing more random samples). 
&lt;/div&gt;
&lt;div class=&quot;Indented&quot;&gt;
Next section we will describe how to get an estimation of &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
k
&lt;/script&gt;
&lt;/span&gt; such that &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\left(1-p\right)k^{*}\le k\le\left(1+p\right)k^{*}
&lt;/script&gt;
&lt;/span&gt; for &lt;b&gt;any&lt;/b&gt; &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
p
&lt;/script&gt;
&lt;/span&gt;, even a polynomially small one (i.e. &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
p=\frac{1}{poly\left(n\right)}
&lt;/script&gt;
&lt;/span&gt;) with a very high probability. 
&lt;/div&gt;
&lt;h2 class=&quot;Subsection&quot;&gt;
&lt;a class=&quot;toc&quot; name=&quot;toc-Subsection-2.2&quot;&gt;2.2&lt;/a&gt; Probabilistic Approximation
&lt;/h2&gt;
&lt;div class=&quot;Unindented&quot;&gt;
The overall procedure is still simple: iterate over each clause &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
C_{i}
&lt;/script&gt;
&lt;/span&gt; and estimate the &lt;i&gt;fraction&lt;/i&gt; of s.a. for &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
C_{i}
&lt;/script&gt;
&lt;/span&gt; that were not counted before (as a number between zero and one), denote that estimation by &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\tilde{k}_{i}
&lt;/script&gt;
&lt;/span&gt;, let &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
S_{i}
&lt;/script&gt;
&lt;/span&gt; be the total number of s.a. for &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
C_{i}
&lt;/script&gt;
&lt;/span&gt; calculated as mentioned in the deterministic approximation section. Then output &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
k=\sum_{i=1}^{m}\tilde{k}_{i}\cdot S_{i}
&lt;/script&gt;
&lt;/span&gt;.
&lt;/div&gt;
&lt;div class=&quot;Indented&quot;&gt;
It left to show how to compute &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\tilde{k}_{i}
&lt;/script&gt;
&lt;/span&gt;, so we do the following. Let &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
t=c\left(\frac{m}{p}\right)^{2}\ln m
&lt;/script&gt;
&lt;/span&gt;, when &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
c
&lt;/script&gt;
&lt;/span&gt; will be determined later. Sample &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
t
&lt;/script&gt;
&lt;/span&gt; independent times, an uniformly random s.a. for &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
C_{i}
&lt;/script&gt;
&lt;/span&gt;. For each assignment define a corresponding binary variable &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
X_{j}
&lt;/script&gt;
&lt;/span&gt; that is &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
1
&lt;/script&gt;
&lt;/span&gt; if it is not satisfying any previous clause, and &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
0
&lt;/script&gt;
&lt;/span&gt; otherwise. Note that evaluating all &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\left\{ X_{j}\right\} _{j=1}^{t}
&lt;/script&gt;
&lt;/span&gt; takes &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\mathcal{O}\left(poly\left(n,m\right)\cdot t\right)
&lt;/script&gt;
&lt;/span&gt; time. Then return &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\tilde{k}_{i}=\frac{1}{t}\sum_{j=1}^{t}X_{j}
&lt;/script&gt;
&lt;/span&gt;. That completes our probabilistic approximation algorithm for &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\#DNF
&lt;/script&gt;
&lt;/span&gt;.
&lt;/div&gt;
&lt;h3 class=&quot;Subsubsection-&quot;&gt;
&lt;a class=&quot;toc&quot; name=&quot;toc-Subsubsection--1&quot;&gt;&lt;/a&gt;Analysis
&lt;/h3&gt;
&lt;div class=&quot;Unindented&quot;&gt;
We need to analyze the quality of approximation of each &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\tilde{k_{i}}
&lt;/script&gt;
&lt;/span&gt;, then show that with high probability &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\sum_{i=1}^{m}\tilde{k}_{i}\cdot S_{i}
&lt;/script&gt;
&lt;/span&gt; is within the claimed approximation bounds. For the first part, we focus on a single estimation &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\tilde{k}_{i}
&lt;/script&gt;
&lt;/span&gt; for the clause &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
C_{i}
&lt;/script&gt;
&lt;/span&gt;. 
&lt;/div&gt;
&lt;div class=&quot;Indented&quot;&gt;
Let &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
S_{i}
&lt;/script&gt;
&lt;/span&gt; be the number of all s.a. for &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
C_{i}
&lt;/script&gt;
&lt;/span&gt; and let &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
s_{i}
&lt;/script&gt;
&lt;/span&gt; be the number of s.a. for &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
C_{i}
&lt;/script&gt;
&lt;/span&gt; that &lt;i&gt;aren’t satisfying any clause before &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
C_{i}
&lt;/script&gt;
&lt;/span&gt;&lt;/i&gt;. Out goal is to show that &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\tilde{k}_{i}
&lt;/script&gt;
&lt;/span&gt; is, with high probability, close to &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\frac{s_{i}}{S_{i}}
&lt;/script&gt;
&lt;/span&gt;. Observe that all the variables &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\left\{ X_{j}\right\} _{j=1}^{t}
&lt;/script&gt;
&lt;/span&gt; for estimating &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\tilde{k}_{i}
&lt;/script&gt;
&lt;/span&gt; were actually sampled i.i.d from a Bernoulli distribution with parameter &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
q_{i}=\frac{s_{i}}{S_{i}}
&lt;/script&gt;
&lt;/span&gt; (which is also its expectation). As a result &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\mathbb{E}\left[\tilde{k}_{i}\right]=q_{i}
&lt;/script&gt;
&lt;/span&gt;, so apply &lt;a class=&quot;URL&quot; href=&quot;https://eranamar.github.io/site/2017/03/24/Comparing-Chernoff-Hoeffding-bounds.html&quot;&gt;Hoeffding inequality&lt;/a&gt; to get &lt;span class=&quot;MathJax_Preview&quot;&gt;
&lt;script type=&quot;math/tex;mode=display&quot;&gt;
\begin{aligned}
\mathbf{P}\left[\left|\tilde{k}_{i}-q_{i}\right|&gt;\frac{p}{m}\right] &amp; \le2\exp\left(\frac{-2\left(\frac{p}{m}\right)^{2}t^{2}}{t}\right)\\
 &amp; =2\exp\left(-2c\ln m\right)=2m^{-2c}
\end{aligned}
&lt;/script&gt;
&lt;/span&gt;
which means that with high probability the estimator is “successful”, that is,&lt;span class=&quot;MathJax_Preview&quot;&gt;
&lt;script type=&quot;math/tex;mode=display&quot;&gt;

q_{i}-\frac{p}{m}\le\tilde{k}_{i}\le q_{i}+\frac{p}{m}

&lt;/script&gt;
&lt;/span&gt;
and equivalently, &lt;span class=&quot;MathJax_Preview&quot;&gt;
&lt;script type=&quot;math/tex;mode=display&quot;&gt;

s_{i}-S_{i}\frac{p}{m}\le\tilde{k}_{i}\cdot S_{i}\le s_{i}+S_{i}\frac{p}{m}

&lt;/script&gt;
&lt;/span&gt;
If all the estimators &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\tilde{k}_{1},\tilde{k}_{2},..
&lt;/script&gt;
&lt;/span&gt; are successful, then &lt;span class=&quot;MathJax_Preview&quot;&gt;
&lt;script type=&quot;math/tex;mode=display&quot;&gt;

k\le\sum_{i=1}^{m}\left(s_{i}+S_{i}\frac{p}{m}\right)=k^{*}+\sum_{i=1}^{m}S_{i}\frac{p}{m}\le k^{*}+\frac{p}{m}\left(mk^{*}\right)=\left(1+p\right)k^{*}

&lt;/script&gt;
&lt;/span&gt;
and also similarly &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
k\ge\left(1-p\right)k^{*}
&lt;/script&gt;
&lt;/span&gt;, which are exactly the approximation bounds that we want to achieve. To conclude the analysis, note that by applying the union bound, all the estimators will be successful with probability &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\ge1-\sum_{i=1}^{m}2m^{-2c}=1-\frac{2}{m^{2c-1}}
&lt;/script&gt;
&lt;/span&gt;.
&lt;/div&gt;
&lt;h3 class=&quot;Subsubsection-&quot;&gt;
&lt;a class=&quot;toc&quot; name=&quot;toc-Subsubsection--2&quot;&gt;&lt;/a&gt;Trade off between the parameters
&lt;/h3&gt;
&lt;div class=&quot;Unindented&quot;&gt;
It is interesting to examine the relation between the different parameters, and how each affect the running time, success probability, and the quality of approximation.
&lt;/div&gt;
&lt;div class=&quot;Indented&quot;&gt;
Consider the parameter &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
t
&lt;/script&gt;
&lt;/span&gt;, which is the number of samples the algorithm has to draw to estimate each &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\tilde{k}_{i}
&lt;/script&gt;
&lt;/span&gt;. That &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
t
&lt;/script&gt;
&lt;/span&gt; depends linearly on the parameter &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
c
&lt;/script&gt;
&lt;/span&gt; which controls the “success probability” of all the estimators (simultaneously). On the one hand, large &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
c
&lt;/script&gt;
&lt;/span&gt; gives a success probability that is extremely close to &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
1
&lt;/script&gt;
&lt;/span&gt;. But on the other hand, it increase the number of samples &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
t
&lt;/script&gt;
&lt;/span&gt; per clause, and the total running time of the algorithm, which is &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\mathcal{O}\left(poly\left(n,m\right)\cdot c\cdot p^{-2}\right)
&lt;/script&gt;
&lt;/span&gt;.
&lt;/div&gt;
&lt;div class=&quot;Indented&quot;&gt;
Similarly, the better approximation we want for &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
k^{*}
&lt;/script&gt;
&lt;/span&gt;, the smaller &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
p
&lt;/script&gt;
&lt;/span&gt; that we should set (even smaller than &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
1
&lt;/script&gt;
&lt;/span&gt;), then the number of samples and the running time increase inversely proportional to &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
p^{2}
&lt;/script&gt;
&lt;/span&gt;.
&lt;/div&gt;
&lt;h1 class=&quot;Section&quot;&gt;
&lt;a class=&quot;toc&quot; name=&quot;toc-Section-3&quot;&gt;3&lt;/a&gt; What About Approximating &lt;i&gt;#CNF-SAT&lt;/i&gt;?
&lt;/h1&gt;
&lt;div class=&quot;Unindented&quot;&gt;
Previous section dealt with approximating, either in the deterministic or probabilistic manner, the &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\#DNF
&lt;/script&gt;
&lt;/span&gt; problem. Unfortunately, as oppose to that we did with exact solutions, approximating &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\#DNF
&lt;/script&gt;
&lt;/span&gt; do not help us approximating &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\#CNF
&lt;/script&gt;
&lt;/span&gt;. We will prove that by proving a stronger claim.
&lt;/div&gt;
&lt;div class=&quot;Claim&quot;&gt;
Let &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
P
&lt;/script&gt;
&lt;/span&gt; be any &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\mathcal{NP}
&lt;/script&gt;
&lt;/span&gt;-complete problem, and denote &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\#P
&lt;/script&gt;
&lt;/span&gt; its Counting versions. There is no polynomial-time approximation algorithm of &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\#P
&lt;/script&gt;
&lt;/span&gt; to &lt;b&gt;any factor&lt;/b&gt;, unless &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\mathcal{P}=\mathcal{NP}
&lt;/script&gt;
&lt;/span&gt;.
&lt;/div&gt;
&lt;div class=&quot;Proof&quot;&gt;
Assume that &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\mathcal{P}\ne\mathcal{NP}
&lt;/script&gt;
&lt;/span&gt;. Suppose toward contradiction that we have some polynomial-time approximation algorithm for &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\#P
&lt;/script&gt;
&lt;/span&gt;, and denote it by &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
Alg
&lt;/script&gt;
&lt;/span&gt;. Given an instance &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
x
&lt;/script&gt;
&lt;/span&gt; for the &lt;b&gt;decision&lt;/b&gt; problem &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
P
&lt;/script&gt;
&lt;/span&gt;, simulate &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
Alg\left(x\right)
&lt;/script&gt;
&lt;/span&gt; and get an approximation for &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\#P\left(x\right)
&lt;/script&gt;
&lt;/span&gt;. Then declare &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
No
&lt;/script&gt;
&lt;/span&gt; as the output of the decision problem if that approximation is zero, and &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
Yes
&lt;/script&gt;
&lt;/span&gt; otherwise. Note that this reduction runs in polynomial time. Moreover, the Counting versions have zero solutions if and only if &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
P\left(x\right)=No
&lt;/script&gt;
&lt;/span&gt;. Since any multiplicative approximation of zero is still zero, we can use the approximation algorithm for the counting problem to efficiently solve the &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\mathcal{NP}
&lt;/script&gt;
&lt;/span&gt;-complete decision problem, contradicting that &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\mathcal{P}\ne\mathcal{NP}
&lt;/script&gt;
&lt;/span&gt;.
&lt;/div&gt;
&lt;h1 class=&quot;Section&quot;&gt;
&lt;a class=&quot;toc&quot; name=&quot;toc-Section-4&quot;&gt;4&lt;/a&gt; &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
DNF
&lt;/script&gt;
&lt;/span&gt; Formulas are Not &lt;i&gt;Always&lt;/i&gt; Easy!
&lt;/h1&gt;
&lt;div class=&quot;Unindented&quot;&gt;
During this and the previous post, we mentioned &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
DNF
&lt;/script&gt;
&lt;/span&gt; formulas as something which is easy to solve. We showed that &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
DNFSAT\in\mathcal{P}
&lt;/script&gt;
&lt;/span&gt;, and always compared it to its “difficult” variation - the &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
CNF
&lt;/script&gt;
&lt;/span&gt; version. However, a &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
DNF
&lt;/script&gt;
&lt;/span&gt; formula can also be “difficult”. It just depends what we are asking. For example, deciding if a &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
DNF
&lt;/script&gt;
&lt;/span&gt; formula &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\psi
&lt;/script&gt;
&lt;/span&gt; is a tautology (i.e. evaluated to &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
True
&lt;/script&gt;
&lt;/span&gt; for any assignment) is an &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\mathcal{NP}
&lt;/script&gt;
&lt;/span&gt;-complete problem. One can show that by noting that &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\phi:=\neg\psi
&lt;/script&gt;
&lt;/span&gt; is a &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
CNF
&lt;/script&gt;
&lt;/span&gt; formula, and &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\phi
&lt;/script&gt;
&lt;/span&gt; is a &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
No
&lt;/script&gt;
&lt;/span&gt; instance for &lt;i&gt;CNF-SAT&lt;/i&gt; if and only if &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\psi
&lt;/script&gt;
&lt;/span&gt; is a &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
Yes
&lt;/script&gt;
&lt;/span&gt; instance for the &lt;i&gt;DNF-TAUTOLOGY&lt;/i&gt; problem. Thus, the problem are equally hard.
&lt;/div&gt;
&lt;div class=&quot;Indented&quot;&gt;
Similarly, we can define an “easy” problem for &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
CNF
&lt;/script&gt;
&lt;/span&gt; formulas: decide whether a &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
CNF
&lt;/script&gt;
&lt;/span&gt; formula &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\phi
&lt;/script&gt;
&lt;/span&gt; is a tautology can be done in polynomial time, by checking if its negation &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\psi:=\neg\phi
&lt;/script&gt;
&lt;/span&gt; has a s.a. which is polynomial since &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
DNFSAT\in\mathcal{P}
&lt;/script&gt;
&lt;/span&gt; and &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\psi
&lt;/script&gt;
&lt;/span&gt; is a &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
DNF
&lt;/script&gt;
&lt;/span&gt; formula.
&lt;/div&gt;
&lt;div class=&quot;Indented&quot;&gt;
As a conclusion, the hardness of those decision problems depends not only on the form of the formula but also on what are we asking to decide.
&lt;/div&gt;</content><author><name>Eran Amar</name></author><category term="complexity" /><category term="approximation" /><summary type="html">Warning: MathJax requires JavaScript to correctly process the mathematics on this page. Please enable JavaScript on your browser. &amp;lt;/hr&amp;gt;</summary></entry><entry><title type="html">On the Hardness of Counting Problems - Part 1</title><link href="https://eranamar.github.io/site/2017/07/06/On-the-Hardness-of-Counting-Problems-Part-1.html" rel="alternate" type="text/html" title="On the Hardness of Counting Problems - Part 1" /><published>2017-07-06T00:00:00+03:00</published><updated>2017-07-06T00:00:00+03:00</updated><id>https://eranamar.github.io/site/2017/07/06/On-the-Hardness-of-Counting-Problems---Part-1</id><content type="html" xml:base="https://eranamar.github.io/site/2017/07/06/On-the-Hardness-of-Counting-Problems-Part-1.html">&lt;script type=&quot;math/tex&quot;&gt;
\newcommand{\lyxlock}{}
&lt;/script&gt;

&lt;noscript&gt;
&lt;div class=&quot;warning&quot;&gt;
Warning: &lt;a href=&quot;http://www.mathjax.org/&quot;&gt;MathJax&lt;/a&gt; requires JavaScript to correctly process the mathematics on this page. Please enable JavaScript on your browser.
&lt;/div&gt;&lt;hr /&gt;
&amp;lt;/hr&amp;gt;&lt;/noscript&gt;

&lt;h1 class=&quot;Section&quot;&gt;
&lt;a class=&quot;toc&quot; name=&quot;toc-Section-1&quot;&gt;1&lt;/a&gt; What is a Counting Problem?
&lt;/h1&gt;
&lt;div class=&quot;Unindented&quot;&gt;
Every undergraduate student in Computer Science knows the &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\mathcal{P}
&lt;/script&gt;
&lt;/span&gt; and &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\mathcal{NP}
&lt;/script&gt;
&lt;/span&gt; families and the legendary question “is &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\mathcal{P}
&lt;/script&gt;
&lt;/span&gt; equals &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\mathcal{NP}
&lt;/script&gt;
&lt;/span&gt;?”. However, there is another interesting family that is not always covered in undergraduate courses; that is the &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\#\mathcal{P}
&lt;/script&gt;
&lt;/span&gt; (“sharp P”) family. In this post we will define and discuss this family and two concrete similar-but-different problems from it that demonstrate interesting properties about its hardness. 
&lt;/div&gt;
&lt;div class=&quot;Indented&quot;&gt;
Formally, &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\mathcal{P}
&lt;/script&gt;
&lt;/span&gt; is the family of decision problems that can be solved in polynomial time. A known example is the &lt;i&gt;Perfect Matching&lt;/i&gt; problem: given a graph, determine whether it has a perfect matching or not. A perfect matching is a set of edges that touches all the vertices in the graph and any pair of edges have disjoint endpoints.
&lt;/div&gt;
&lt;div class=&quot;Indented&quot;&gt;
The family &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\mathcal{NP}
&lt;/script&gt;
&lt;/span&gt; contains all the decision problems that has polynomial time algorithm over the non-deterministic computational model (we won’t get into that). We know that &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\mathcal{P}\subseteq\mathcal{NP}
&lt;/script&gt;
&lt;/span&gt;, but we don’t know if the other direction also holds. A famous &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\mathcal{NP}
&lt;/script&gt;
&lt;/span&gt;-complete example is the &lt;i&gt;Hamiltonian Cycle&lt;/i&gt; problem: given a graph, determine whether it contains a cycle that visits every vertex exactly once. We say “complete” to note that the problem is harder at least as any other problem inside that family, that is, if we could solve it efficiently (i.e. in polynomial time) then we could solve any other problem in the family efficiently. When a problem &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
P_{1}
&lt;/script&gt;
&lt;/span&gt; is at least harder as other problem &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
P_{2}
&lt;/script&gt;
&lt;/span&gt; we denote it &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
P_{1}\ge P_{2}
&lt;/script&gt;
&lt;/span&gt;. 
&lt;/div&gt;
&lt;div class=&quot;Indented&quot;&gt;
Any problem in either &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\mathcal{P}
&lt;/script&gt;
&lt;/span&gt; or &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\mathcal{NP}
&lt;/script&gt;
&lt;/span&gt; can be rephrased slightly different. We can ask “&lt;i&gt;how many&lt;/i&gt; perfect matching this graph contains?” rather than “is there a perfect matching in this graph?”. When asking&lt;i&gt; how much&lt;/i&gt; instead of &lt;i&gt;is there&lt;/i&gt; the problem become a Counting problem. Following that, the formal definition of &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\#\mathcal{P}
&lt;/script&gt;
&lt;/span&gt; is: the family the Counting version of any problem in &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\mathcal{NP}
&lt;/script&gt;
&lt;/span&gt;.
&lt;/div&gt;
&lt;div class=&quot;Indented&quot;&gt;
Notice that for any problem &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
P\in\mathcal{P}\cup\mathcal{NP}
&lt;/script&gt;
&lt;/span&gt; we have &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
P\le\#P
&lt;/script&gt;
&lt;/span&gt; because having a count of the desired property can, in particular, distinguish between the cases that this count is &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
0
&lt;/script&gt;
&lt;/span&gt; or higher, that is, decide whether that property exists or not. Hence, we can safely state the general hierarchy, that &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\mathcal{P}\le\mathcal{NP}\le\#\mathcal{P}
&lt;/script&gt;
&lt;/span&gt;.
&lt;/div&gt;
&lt;div class=&quot;Indented&quot;&gt;
Let &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
P_{1},P_{2}
&lt;/script&gt;
&lt;/span&gt; be the &lt;i&gt;Perfect Matching&lt;/i&gt; and &lt;i&gt;Hamiltonian Cycle&lt;/i&gt; problems respectively, and let &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\#P_{1},\#P_{2}
&lt;/script&gt;
&lt;/span&gt; be their Counting versions. It is interesting to see whether the hierarchy between problems from &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\mathcal{P}
&lt;/script&gt;
&lt;/span&gt; and &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\mathcal{NP}
&lt;/script&gt;
&lt;/span&gt; preserved for their Counting versions as well. For instance, for the problems above, we know that &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
P_{1}\le P_{2}
&lt;/script&gt;
&lt;/span&gt; since &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\mathcal{P}\subseteq\mathcal{NP}
&lt;/script&gt;
&lt;/span&gt; and &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
P_{2}
&lt;/script&gt;
&lt;/span&gt; is &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\mathcal{NP}
&lt;/script&gt;
&lt;/span&gt;-complete, is that implies also &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\#P_{1}\le\#P_{2}
&lt;/script&gt;
&lt;/span&gt;?
&lt;/div&gt;
&lt;div class=&quot;Indented&quot;&gt;
The short answer is no. In the next section we will show that in a detailed discussion.
&lt;/div&gt;
&lt;h1 class=&quot;Section&quot;&gt;
&lt;a class=&quot;toc&quot; name=&quot;toc-Section-2&quot;&gt;2&lt;/a&gt; Counting Makes Problems Much Harder
&lt;/h1&gt;
&lt;div class=&quot;Unindented&quot;&gt;
We start with two basic definitions from the field of boolean logic.
&lt;/div&gt;
&lt;div class=&quot;Definition&quot;&gt;
A &lt;i&gt;Conjunctive Normal Form&lt;/i&gt; (&lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
CNF
&lt;/script&gt;
&lt;/span&gt;) formula &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\phi
&lt;/script&gt;
&lt;/span&gt; other a set of &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
n
&lt;/script&gt;
&lt;/span&gt; boolean variables is defined as &lt;span class=&quot;MathJax_Preview&quot;&gt;
&lt;script type=&quot;math/tex;mode=display&quot;&gt;

\phi=\bigwedge_{i=1}^{m}C_{i}

&lt;/script&gt;
&lt;/span&gt;
where each of its &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
m
&lt;/script&gt;
&lt;/span&gt; clauses is of the form &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
C_{i}=\bigvee_{j=1}^{\left|C_{i}\right|}\ell_{i,j}
&lt;/script&gt;
&lt;/span&gt;, that is, the clause is a disjunction of some number of literals. A literal &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\ell_{i,j}
&lt;/script&gt;
&lt;/span&gt; is a variable or its negation. Note that since there are &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
n
&lt;/script&gt;
&lt;/span&gt; variables then &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\left|C_{i}\right|\le2n
&lt;/script&gt;
&lt;/span&gt;.
&lt;/div&gt;
&lt;div class=&quot;Unindented&quot;&gt;

&lt;/div&gt;
&lt;div class=&quot;Definition&quot;&gt;
A &lt;i&gt;Disjunctive Normal Form&lt;/i&gt; (&lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
DNF
&lt;/script&gt;
&lt;/span&gt;) formula &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\psi
&lt;/script&gt;
&lt;/span&gt; other a set of &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
n
&lt;/script&gt;
&lt;/span&gt; boolean variables is defined analogously to the &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
CNF
&lt;/script&gt;
&lt;/span&gt; version, as &lt;span class=&quot;MathJax_Preview&quot;&gt;
&lt;script type=&quot;math/tex;mode=display&quot;&gt;

\psi=\bigvee_{i=1}^{m}C_{i}

&lt;/script&gt;
&lt;/span&gt;
where each of its &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
m
&lt;/script&gt;
&lt;/span&gt; clauses is of the form &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
C_{i}=\bigwedge_{j=1}^{\left|C_{i}\right|}\ell_{i,j}
&lt;/script&gt;
&lt;/span&gt;.
&lt;/div&gt;
&lt;div class=&quot;Unindented&quot;&gt;
The &lt;i&gt;CNF-SAT&lt;/i&gt; problem, gets as an input a &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
CNF
&lt;/script&gt;
&lt;/span&gt; boolean formula, and decides whether that formula has a &lt;i&gt;satisfying assignment (s.a.)&lt;/i&gt; or not. That is, an assignment of &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
True/False
&lt;/script&gt;
&lt;/span&gt; for each of its variables such that the formula evaluates to &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
True
&lt;/script&gt;
&lt;/span&gt;. The &lt;i&gt;DNF-SAT&lt;/i&gt; is defined the same but for &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
DNF
&lt;/script&gt;
&lt;/span&gt; formulas rather than &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
CNF
&lt;/script&gt;
&lt;/span&gt; ones.
&lt;/div&gt;
&lt;div class=&quot;Indented&quot;&gt;
We will need the following facts in the coming discussion:
&lt;/div&gt;
&lt;ol&gt;
&lt;li&gt;
The &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\neg
&lt;/script&gt;
&lt;/span&gt; operator (negation) transforms any &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
CNF
&lt;/script&gt;
&lt;/span&gt; formula &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\phi
&lt;/script&gt;
&lt;/span&gt; to a &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
DNF
&lt;/script&gt;
&lt;/span&gt; formula and vice versa. 
&lt;/li&gt;
&lt;li&gt;
For &lt;i&gt;any&lt;/i&gt; boolean formula &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\phi
&lt;/script&gt;
&lt;/span&gt; over &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
n
&lt;/script&gt;
&lt;/span&gt; variables (regardless its form), there are exactly &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
2^{n}
&lt;/script&gt;
&lt;/span&gt; possible assignments each of which satisfy exactly one from &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\left\{ \phi,\neg\phi\right\} 
&lt;/script&gt;
&lt;/span&gt;. 
&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&quot;Unindented&quot;&gt;

&lt;/div&gt;
&lt;div class=&quot;Indented&quot;&gt;
It is very easy to solve &lt;i&gt;DNF-SAT&lt;/i&gt; efficiently, meaning, in polynomial time. Given a &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
DNF
&lt;/script&gt;
&lt;/span&gt; formula &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\psi
&lt;/script&gt;
&lt;/span&gt;, iterate over its clauses until you find a satisfiable clause then declare that &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\psi
&lt;/script&gt;
&lt;/span&gt; is satisfiable, however, if you failed to find such a clause then declare that &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\psi
&lt;/script&gt;
&lt;/span&gt; is not satisfiable. Observe that any clause of the form &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
C_{i}=\bigwedge_{j=1}^{\left|C_{i}\right|}\ell_{i,j}
&lt;/script&gt;
&lt;/span&gt; is satisfiable if and only if it does not contains a variable and its negation; which we can check with a single pass over the literals of &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
C_{i}
&lt;/script&gt;
&lt;/span&gt;. As a result, &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
DNFSAT\in\mathcal{P}
&lt;/script&gt;
&lt;/span&gt;.
&lt;/div&gt;
&lt;div class=&quot;Indented&quot;&gt;
In contrast to &lt;i&gt;DNF-SAT&lt;/i&gt;, the &lt;i&gt;CNF-SAT&lt;/i&gt; is know to be &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\mathcal{NP}
&lt;/script&gt;
&lt;/span&gt;-complete, so we &lt;i&gt;believe&lt;/i&gt; that it cannot be solved in polynomial time. Similar to the claim from the previous section, we conclude that &lt;i&gt;CNF-SAT&lt;/i&gt; is “at least harder” as &lt;i&gt;DNF-SAT&lt;/i&gt;, that is, &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
DNFSAT\le CNFSAT
&lt;/script&gt;
&lt;/span&gt;. However, as regard to the Counting versions of those problems, we can show the opposite inequality; that &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\#CNFSAT\le\#DNFSAT
&lt;/script&gt;
&lt;/span&gt;. 
&lt;/div&gt;
&lt;div class=&quot;Indented&quot;&gt;
To prove that, we need to show that if we could solve &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\#DNFSAT
&lt;/script&gt;
&lt;/span&gt; efficiently, then we could solve &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\#CNFSAT
&lt;/script&gt;
&lt;/span&gt; efficiently. So suppose we have a magical algorithm that can solve &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\#DNFSAT
&lt;/script&gt;
&lt;/span&gt; in polynomial time. Given a &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
CNF
&lt;/script&gt;
&lt;/span&gt; formula &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\phi
&lt;/script&gt;
&lt;/span&gt; over &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
n
&lt;/script&gt;
&lt;/span&gt; boolean variables, construct &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\psi=\neg\phi
&lt;/script&gt;
&lt;/span&gt; and feed it to the magical algorithm. Let its output be the number &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
t
&lt;/script&gt;
&lt;/span&gt;, then return &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
2^{n}-t
&lt;/script&gt;
&lt;/span&gt;. 
&lt;/div&gt;
&lt;div class=&quot;Indented&quot;&gt;
The correctness of that reduction follows from the two facts we stated earlier. Note that also all the procedures can be executed in polynomial time, so we solved &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\#CNFSAT
&lt;/script&gt;
&lt;/span&gt; in polynomial time using an efficient solver for &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\#DNFSAT
&lt;/script&gt;
&lt;/span&gt;, therefore, &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\#CNFSAT\le\#DNFSAT
&lt;/script&gt;
&lt;/span&gt;.
&lt;/div&gt;
&lt;div class=&quot;Indented&quot;&gt;
Actually, if we will look closely on that reduction, we will see that it should work perfectly for the other direction as well, that is, solving &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\#DNFSAT
&lt;/script&gt;
&lt;/span&gt; by a an efficient algorithm for the &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\#CNFSAT
&lt;/script&gt;
&lt;/span&gt;, so we may conclude that both problems are &lt;b&gt;equally hard&lt;/b&gt;. This is an evidence that the hierarchy between decision problems do not preserved for their Counting versions. Putting it differently, we can say that Counting makes problems much harder, such that even an “easy” problems from &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\mathcal{P}
&lt;/script&gt;
&lt;/span&gt; become harder as the entire &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\mathcal{NP}
&lt;/script&gt;
&lt;/span&gt; when you consider its Counting version.
&lt;/div&gt;
&lt;h1 class=&quot;Section&quot;&gt;
&lt;a class=&quot;toc&quot; name=&quot;toc-Section-3&quot;&gt;3&lt;/a&gt; &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\#DNF
&lt;/script&gt;
&lt;/span&gt; is Also &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\#\mathcal{P}
&lt;/script&gt;
&lt;/span&gt;-Complete
&lt;/h1&gt;
&lt;div class=&quot;Unindented&quot;&gt;
Since &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\#DNF
&lt;/script&gt;
&lt;/span&gt; and &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\#CNF
&lt;/script&gt;
&lt;/span&gt; are equally hard, it is enough to show that &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\#CNF
&lt;/script&gt;
&lt;/span&gt; is &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\#\mathcal{P}
&lt;/script&gt;
&lt;/span&gt;-complete; for that we need a reduction from any problem in &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\#\mathcal{P}
&lt;/script&gt;
&lt;/span&gt; to &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\#CNF
&lt;/script&gt;
&lt;/span&gt;. Recall the Cook-Levin reduction which proves that &lt;i&gt;CNF-SAT&lt;/i&gt; is &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\mathcal{NP}
&lt;/script&gt;
&lt;/span&gt;-complete. That reduction can be applied to any &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
P\in\mathcal{NP}
&lt;/script&gt;
&lt;/span&gt; and produce a polynomial procedure that converts any input &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
x
&lt;/script&gt;
&lt;/span&gt; for the original problem &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
P
&lt;/script&gt;
&lt;/span&gt;, to a &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
CNF
&lt;/script&gt;
&lt;/span&gt; formula &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\phi
&lt;/script&gt;
&lt;/span&gt; for the problem &lt;i&gt;CNF-SAT&lt;/i&gt;, such that &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\phi
&lt;/script&gt;
&lt;/span&gt; is satisfiable if and only if the decision problem &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
P
&lt;/script&gt;
&lt;/span&gt; says &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
Yes
&lt;/script&gt;
&lt;/span&gt; for the original input &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
x
&lt;/script&gt;
&lt;/span&gt;. That way, any efficient solver for &lt;i&gt;CNF-SAT&lt;/i&gt; solves &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
P
&lt;/script&gt;
&lt;/span&gt; efficiently, so &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
P\le CNFSAT
&lt;/script&gt;
&lt;/span&gt;. 
&lt;/div&gt;
&lt;div class=&quot;Indented&quot;&gt;
An important property of the Cook-Levin reduction is that it keeps the number of s.a. for &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\phi
&lt;/script&gt;
&lt;/span&gt; &lt;u&gt;exactly&lt;/u&gt; as the number of witnesses for the original input &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
x
&lt;/script&gt;
&lt;/span&gt; of &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
P
&lt;/script&gt;
&lt;/span&gt;. That means, that we can use the same reduction to convert any Counting problem &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\#P\in\#\mathcal{P}
&lt;/script&gt;
&lt;/span&gt; to &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\#CNF
&lt;/script&gt;
&lt;/span&gt;. That is, the reduction will yields a procedure to convert any input &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
x
&lt;/script&gt;
&lt;/span&gt; for &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\#P
&lt;/script&gt;
&lt;/span&gt; to a formula &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\phi
&lt;/script&gt;
&lt;/span&gt; for &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\#CNF
&lt;/script&gt;
&lt;/span&gt; such that the number of s.a. of &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\phi
&lt;/script&gt;
&lt;/span&gt; is the solution for &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\#P\left(x\right)
&lt;/script&gt;
&lt;/span&gt;. As a result, &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\#CNF
&lt;/script&gt;
&lt;/span&gt; is &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\#\mathcal{P}
&lt;/script&gt;
&lt;/span&gt;-complete, and then also &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\#DNF
&lt;/script&gt;
&lt;/span&gt;.
&lt;/div&gt;
&lt;div class=&quot;Indented&quot;&gt;
Following the conclusion from previous section, we can say further that even a simple problem from &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\mathcal{P}
&lt;/script&gt;
&lt;/span&gt;, can have a Counting version that is not just “harder” but harder as &lt;i&gt;any other problem&lt;/i&gt; in &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\#\mathcal{P}
&lt;/script&gt;
&lt;/span&gt;.
&lt;/div&gt;
&lt;h1 class=&quot;Section&quot;&gt;
&lt;a class=&quot;toc&quot; name=&quot;toc-Section-4&quot;&gt;4&lt;/a&gt; Is There a Structure inside &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\#\mathcal{P}
&lt;/script&gt;
&lt;/span&gt;?
&lt;/h1&gt;
&lt;div class=&quot;Unindented&quot;&gt;
Going back to the &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\#CNF
&lt;/script&gt;
&lt;/span&gt; and &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\#DNF
&lt;/script&gt;
&lt;/span&gt; problems, we saw that they are related via the relation &lt;span class=&quot;MathJax_Preview&quot;&gt;
&lt;script type=&quot;math/tex;mode=display&quot;&gt;

\#CNF\left(\phi\right)+\#DNF\left(\neg\phi\right)=2^{n}

&lt;/script&gt;
&lt;/span&gt;
 for any &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
CNF
&lt;/script&gt;
&lt;/span&gt; formula &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\phi
&lt;/script&gt;
&lt;/span&gt; over &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
n
&lt;/script&gt;
&lt;/span&gt; boolean variables. We exploited that relation to show that the problems are equally “hard” when talking about &lt;b&gt;exact-solutions&lt;/b&gt;. However, an hierarchy emerged once we moved to consider&lt;b&gt; approximated solutions&lt;/b&gt; for those problems. Therefore, there is some kind of structure for the family &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\#\mathcal{P}
&lt;/script&gt;
&lt;/span&gt; under the appropriate notion of “solving” the problems.
&lt;/div&gt;
&lt;div class=&quot;Indented&quot;&gt;
Next post we will discuss an approximation algorithm for &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\#DNF
&lt;/script&gt;
&lt;/span&gt; and the hardness of approximating &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\#CNF
&lt;/script&gt;
&lt;/span&gt;, showing that the additive relation from above it not enough for constructing an approximation algorithm for &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\#CNF
&lt;/script&gt;
&lt;/span&gt; based on approximation for &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\#DNF
&lt;/script&gt;
&lt;/span&gt;.
&lt;/div&gt;</content><author><name>Eran Amar</name></author><category term="complexity" /><category term="approximation" /><summary type="html">Warning: MathJax requires JavaScript to correctly process the mathematics on this page. Please enable JavaScript on your browser. &amp;lt;/hr&amp;gt;</summary></entry><entry><title type="html">Approximation Algorithm for the Steiner Tree Problem</title><link href="https://eranamar.github.io/site/2017/07/02/Approximation-Algorithm-for-the-Steiner-Tree-Problem.html" rel="alternate" type="text/html" title="Approximation Algorithm for the Steiner Tree Problem" /><published>2017-07-02T00:00:00+03:00</published><updated>2017-07-02T00:00:00+03:00</updated><id>https://eranamar.github.io/site/2017/07/02/Approximation-Algorithm-for-the-Steiner-Tree-Problem</id><content type="html" xml:base="https://eranamar.github.io/site/2017/07/02/Approximation-Algorithm-for-the-Steiner-Tree-Problem.html">&lt;script type=&quot;math/tex&quot;&gt;
\newcommand{\lyxlock}{}
&lt;/script&gt;

&lt;noscript&gt;
&lt;div class=&quot;warning&quot;&gt;
Warning: &lt;a href=&quot;http://www.mathjax.org/&quot;&gt;MathJax&lt;/a&gt; requires JavaScript to correctly process the mathematics on this page. Please enable JavaScript on your browser.
&lt;/div&gt;&lt;hr /&gt;
&amp;lt;/hr&amp;gt;&lt;/noscript&gt;

&lt;h1 class=&quot;Section&quot;&gt;
&lt;a class=&quot;toc&quot; name=&quot;toc-Section-1&quot;&gt;1&lt;/a&gt; The Steiner Tree Problem
&lt;/h1&gt;
&lt;div class=&quot;Unindented&quot;&gt;
An instance of the &lt;i&gt;Steiner Tree&lt;/i&gt; problem is a connected graph &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
G
&lt;/script&gt;
&lt;/span&gt; on a set of &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
n
&lt;/script&gt;
&lt;/span&gt; vertices &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
V\left(G\right)
&lt;/script&gt;
&lt;/span&gt; and &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
m
&lt;/script&gt;
&lt;/span&gt; edges &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
E
&lt;/script&gt;
&lt;/span&gt;&lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\left(G\right)
&lt;/script&gt;
&lt;/span&gt; equipped with a positive weight function &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
w:E\left(G\right)\to\mathbb{R}_{&gt;0}
&lt;/script&gt;
&lt;/span&gt;. Given a set of terminals &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
T\subseteq V\left(G\right)
&lt;/script&gt;
&lt;/span&gt;, a valid solution is s set &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
S\subseteq E\left(G\right)
&lt;/script&gt;
&lt;/span&gt; that induces a sub-graph in which any pair of terminals &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
t_{1},t_{2}\in T
&lt;/script&gt;
&lt;/span&gt; is connected. The weight of a solution &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
S
&lt;/script&gt;
&lt;/span&gt; is defined by &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
w\left(S\right)=\sum_{e\in S}w\left(e\right)
&lt;/script&gt;
&lt;/span&gt;, and we want to find a valid solution with minimum weight, usually denoted &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
S^{*}
&lt;/script&gt;
&lt;/span&gt;. Note that since the initial graph is connected there is always a valid solution. 
&lt;/div&gt;
&lt;div class=&quot;Indented&quot;&gt;
Finding an exact optimal solution is NP-Complete. However, there is polynomial time approximation algorithm that yields a factor 2 approximation. We say that a solution &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
S
&lt;/script&gt;
&lt;/span&gt; is 2-approximation for the problem if &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
w\left(S\right)\le2\cdot w\left(S^{*}\right)
&lt;/script&gt;
&lt;/span&gt; for some optimal solution &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
S^{*}
&lt;/script&gt;
&lt;/span&gt;.
&lt;/div&gt;
&lt;h1 class=&quot;Section&quot;&gt;
&lt;a class=&quot;toc&quot; name=&quot;toc-Section-2&quot;&gt;2&lt;/a&gt; Adding Assumptions “for Free”
&lt;/h1&gt;
&lt;div class=&quot;Unindented&quot;&gt;
Given a graph &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
G
&lt;/script&gt;
&lt;/span&gt; and weight-function &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
w
&lt;/script&gt;
&lt;/span&gt;, consider the following construction: Let &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\tilde{G}
&lt;/script&gt;
&lt;/span&gt; be a clique on the same set of vertices &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
V\left(\tilde{G}\right)=V\left(G\right)
&lt;/script&gt;
&lt;/span&gt;, that is, &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
E\left(\tilde{G}\right)=\left\{ \left(u,v\right)\mid u\ne v\in V\left(G\right)\right\} 
&lt;/script&gt;
&lt;/span&gt;. Define the weight function &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\tilde{w}
&lt;/script&gt;
&lt;/span&gt; as follows, &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\forall u,v\in V\left(\tilde{G}\right)
&lt;/script&gt;
&lt;/span&gt; let &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\tilde{w}\left(u,v\right)
&lt;/script&gt;
&lt;/span&gt; be the weight of the shortest path from &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
u
&lt;/script&gt;
&lt;/span&gt; to &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
v
&lt;/script&gt;
&lt;/span&gt; in the original &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
G
&lt;/script&gt;
&lt;/span&gt;. When “shortest path” is defined to be the path with minimum&lt;i&gt; sum of weights&lt;/i&gt; among all the simple paths that from &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
u
&lt;/script&gt;
&lt;/span&gt; to &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
v
&lt;/script&gt;
&lt;/span&gt;. Furthermore, it worth noting that by its definition, &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\tilde{w}
&lt;/script&gt;
&lt;/span&gt; obeys the triangle inequality, meaning that for any triple &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
u,v,w\in V\left(\tilde{G}\right)
&lt;/script&gt;
&lt;/span&gt;, if &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
e_{1}=\left(u,v\right)
&lt;/script&gt;
&lt;/span&gt;, &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
e_{2}=\left(v,w\right)
&lt;/script&gt;
&lt;/span&gt; and &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
e_{3}=\left(u,w\right)
&lt;/script&gt;
&lt;/span&gt; then &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\tilde{w}\left(e_{3}\right)\le\tilde{w}\left(e_{1}\right)+\tilde{w}\left(e_{2}\right)
&lt;/script&gt;
&lt;/span&gt;. 
&lt;/div&gt;
&lt;div class=&quot;Indented&quot;&gt;
Fix some &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
T\subseteq V\left(G\right)
&lt;/script&gt;
&lt;/span&gt;, we will show that the weight of any optimal solution for the original instance &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\left(G,w\right)
&lt;/script&gt;
&lt;/span&gt; is &lt;b&gt;exactly&lt;/b&gt; the same weight as of any optimal solution for &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\left(\tilde{G},\tilde{w}\right)
&lt;/script&gt;
&lt;/span&gt;. We will do that by showing two inequalities: let &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
S^{*},\tilde{S}^{*}
&lt;/script&gt;
&lt;/span&gt; be optimal solutions for the original and the modified instances respectively. Then &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
w\left(S^{*}\right)\le w\left(\tilde{S}^{*}\right)
&lt;/script&gt;
&lt;/span&gt; and &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
w\left(\tilde{S}^{*}\right)\le w\left(S^{*}\right)
&lt;/script&gt;
&lt;/span&gt;.
&lt;/div&gt;
&lt;div class=&quot;Indented&quot;&gt;
Obviously, the inequality &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
w\left(\tilde{S}^{*}\right)\le w\left(S^{*}\right)
&lt;/script&gt;
&lt;/span&gt; holds, because &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\tilde{G}
&lt;/script&gt;
&lt;/span&gt; contains all the edges of &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
G
&lt;/script&gt;
&lt;/span&gt; and for any edge &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
e
&lt;/script&gt;
&lt;/span&gt; in &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
G
&lt;/script&gt;
&lt;/span&gt; its weight over the modified instance &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\tilde{G}
&lt;/script&gt;
&lt;/span&gt; have &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\tilde{w}\left(e\right)\le w\left(e\right)
&lt;/script&gt;
&lt;/span&gt;, by the definition of &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\tilde{w}
&lt;/script&gt;
&lt;/span&gt;. Therefore, the optimal weight over &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\tilde{G}
&lt;/script&gt;
&lt;/span&gt; can only be equal to or smaller than the one of &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
G
&lt;/script&gt;
&lt;/span&gt;.
&lt;/div&gt;
&lt;div class=&quot;Indented&quot;&gt;
The other direction is less trivial. Take any &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\tilde{S}^{*}
&lt;/script&gt;
&lt;/span&gt; and convert it to be a valid solution over the original &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
G
&lt;/script&gt;
&lt;/span&gt; as follows: for any &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
e\in\tilde{S}^{*}
&lt;/script&gt;
&lt;/span&gt;, if &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
e\in E\left(G\right)
&lt;/script&gt;
&lt;/span&gt; and &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
w\left(e\right)\le\tilde{w}\left(e\right)
&lt;/script&gt;
&lt;/span&gt; then add &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
e\in S^{*}
&lt;/script&gt;
&lt;/span&gt;. Otherwise, take all the edges along the shortest path connecting the endpoints of &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
e
&lt;/script&gt;
&lt;/span&gt; other the original graph &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
G
&lt;/script&gt;
&lt;/span&gt; and add them to &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
S^{*}
&lt;/script&gt;
&lt;/span&gt;. Note that the entire weight of that path cannot exceeds &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\tilde{w}\left(e\right)
&lt;/script&gt;
&lt;/span&gt; by the definition of &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\tilde{w}
&lt;/script&gt;
&lt;/span&gt;. Therefore we end up with a valid solution &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
S^{*}
&lt;/script&gt;
&lt;/span&gt;, that also have &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
w\left(S^{*}\right)\le w\left(\tilde{S}^{*}\right)
&lt;/script&gt;
&lt;/span&gt;. In conclusion, &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
w\left(S^{*}\right)=w\left(\tilde{S}^{*}\right)
&lt;/script&gt;
&lt;/span&gt;.
&lt;/div&gt;
&lt;div class=&quot;Indented&quot;&gt;
The proof above gave us a concrete polynomial-time procedure to convert any valid solution &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\tilde{S}
&lt;/script&gt;
&lt;/span&gt; over &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\tilde{G}
&lt;/script&gt;
&lt;/span&gt; to a valid solution &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
S
&lt;/script&gt;
&lt;/span&gt; over &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
G
&lt;/script&gt;
&lt;/span&gt; such that &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
w\left(S\right)\le w\left(\tilde{S}\right)
&lt;/script&gt;
&lt;/span&gt;. From that we can conclude that it is suffice to find a 2-approximation for the “easier” instance &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\left(\tilde{G},\tilde{w}\right)
&lt;/script&gt;
&lt;/span&gt; and then converts it to a 2-approximation solution for the original instance &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\left(G,w\right)
&lt;/script&gt;
&lt;/span&gt;, note also that the construction of &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\tilde{G},\tilde{w}
&lt;/script&gt;
&lt;/span&gt; from &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
G,w
&lt;/script&gt;
&lt;/span&gt; can be done in polynomial time (for example use &lt;a class=&quot;URL&quot; href=&quot;https://en.wikipedia.org/wiki/Dijkstra%27s_algorithm&quot;&gt;Dijkstra's algorithm&lt;/a&gt; for computing the shortest paths).
&lt;/div&gt;
&lt;div class=&quot;Indented&quot;&gt;
In other words, we can assume for free (i.e. without losing anything) that &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
G
&lt;/script&gt;
&lt;/span&gt; is a clique and &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
w
&lt;/script&gt;
&lt;/span&gt; have the triangle inequality, and design an approximation algorithm that deals only with such instances.
&lt;/div&gt;
&lt;h1 class=&quot;Section&quot;&gt;
&lt;a class=&quot;toc&quot; name=&quot;toc-Section-3&quot;&gt;3&lt;/a&gt; Approximation Algorithm for the Easier Problem
&lt;/h1&gt;
&lt;div class=&quot;Unindented&quot;&gt;
Let &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
G
&lt;/script&gt;
&lt;/span&gt; be a clique, &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
w
&lt;/script&gt;
&lt;/span&gt; be a weight function that obeys the triangle inequality, and &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
T
&lt;/script&gt;
&lt;/span&gt; is a set of terminals. Use any known polynomial time algorithm to get a &lt;i&gt;Minimum Spanning Tree (MST)&lt;/i&gt; on &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
T
&lt;/script&gt;
&lt;/span&gt; (for instance, use &lt;a class=&quot;URL&quot; href=&quot;https://en.wikipedia.org/wiki/Kruskal%27s_algorithm&quot;&gt;Kruskal's algorithm&lt;/a&gt;), let the edges of that tree be &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
S\subseteq E\left(G\right)
&lt;/script&gt;
&lt;/span&gt;. Output &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
S
&lt;/script&gt;
&lt;/span&gt; as the approximated solution for the &lt;i&gt;Steiner Tree&lt;/i&gt; problem.
&lt;/div&gt;
&lt;div class=&quot;Indented&quot;&gt;
Putting it differently, we claim that &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
w\left(S\right)\le2w\left(S^{*}\right)
&lt;/script&gt;
&lt;/span&gt;, when &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
S^{*}
&lt;/script&gt;
&lt;/span&gt; is some optimal solution for the &lt;i&gt;Steiner Tree&lt;/i&gt; problem for that “easier” instance. 
&lt;/div&gt;
&lt;div class=&quot;Indented&quot;&gt;
And now we will prove that. 
&lt;/div&gt;
&lt;div class=&quot;Indented&quot;&gt;
Let &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
S^{*}
&lt;/script&gt;
&lt;/span&gt; be some optimal solution for the &lt;i&gt;Steiner Tree&lt;/i&gt; problem. It must be a tree because otherwise we have a redundant edge such that removing it will decrease the weight of the solution and keep it valid (the terminals will stay connected); in contradiction to the optimality of &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
S^{*}
&lt;/script&gt;
&lt;/span&gt;. Run a &lt;i&gt;Depth First Search (DFS)&lt;/i&gt; at the root of &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
S^{*}
&lt;/script&gt;
&lt;/span&gt;, traverse all the nodes in the tree and return back to the root. Memorize all the nodes traversed that way (with repetitions) and denote that sequence &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
P
&lt;/script&gt;
&lt;/span&gt;. By the way we build &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
P
&lt;/script&gt;
&lt;/span&gt;, it is a cycle that touches all the vertices of &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
T
&lt;/script&gt;
&lt;/span&gt; (and maybe also others) and uses twice any edge of &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
S^{*}
&lt;/script&gt;
&lt;/span&gt;, once for the forward pass and once for the backward pass, so it has a length &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
k:=2\left|S^{*}\right|
&lt;/script&gt;
&lt;/span&gt;. Suppose that &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
P=\left(u_{1},...,u_{k}\right)
&lt;/script&gt;
&lt;/span&gt;, then we conclude that &lt;span class=&quot;MathJax_Preview&quot;&gt;
&lt;script type=&quot;math/tex;mode=display&quot;&gt;

w\left(P\right)=\sum_{i=1}^{k-1}w\left(\left(u_{i},u_{i+1}\right)\right)=2\cdot w\left(S^{*}\right)

&lt;/script&gt;
&lt;/span&gt;
&lt;/div&gt;
&lt;div class=&quot;Indented&quot;&gt;
Define the following order on &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
T
&lt;/script&gt;
&lt;/span&gt;: for any two terminals &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
t_{1},t_{2}\in T
&lt;/script&gt;
&lt;/span&gt;, we say that &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
t_{1}
&lt;/script&gt;
&lt;/span&gt; comes before &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
t_{2}
&lt;/script&gt;
&lt;/span&gt; if the first appearance of &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
t_{1}
&lt;/script&gt;
&lt;/span&gt; in &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
P
&lt;/script&gt;
&lt;/span&gt; comes before the first appearance of &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
t_{2}
&lt;/script&gt;
&lt;/span&gt; in &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
P
&lt;/script&gt;
&lt;/span&gt;. Let &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\left(t_{1},...,t_{\left|T\right|}\right)
&lt;/script&gt;
&lt;/span&gt; be the sequence of ordered terminals, note that it is also defines &lt;i&gt;a path&lt;/i&gt; because &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
G
&lt;/script&gt;
&lt;/span&gt; is a clique, that is, &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\left(t_{i},t_{i+1}\right)\in E\left(G\right)
&lt;/script&gt;
&lt;/span&gt; for any &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
i
&lt;/script&gt;
&lt;/span&gt;. Denote that path &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\tilde{P}
&lt;/script&gt;
&lt;/span&gt;.
&lt;/div&gt;
&lt;div class=&quot;Indented&quot;&gt;
By the triangle inequality, for any pair &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
t_{i},t_{i+1}\in T
&lt;/script&gt;
&lt;/span&gt; the weighed subpath in &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\tilde{P}
&lt;/script&gt;
&lt;/span&gt;, which is the weight of a single edge, is less or equal to the weighted length in &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
P
&lt;/script&gt;
&lt;/span&gt; (which may use more than one edge), thus &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
w\left(\tilde{P}\right)\le w\left(P\right)
&lt;/script&gt;
&lt;/span&gt;. 
&lt;/div&gt;
&lt;div class=&quot;Indented&quot;&gt;
Since &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\tilde{P}
&lt;/script&gt;
&lt;/span&gt; touches all the terminals in &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
T
&lt;/script&gt;
&lt;/span&gt; exactly once, it has no cycles, hence it is also a spanning tree over the vertices &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
T
&lt;/script&gt;
&lt;/span&gt; and edges of the clique. Recall that the proposed solution &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
S
&lt;/script&gt;
&lt;/span&gt; is a minimum spanning tree on &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
T
&lt;/script&gt;
&lt;/span&gt;, therefore &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
w\left(S\right)\le w\left(\tilde{P}\right)
&lt;/script&gt;
&lt;/span&gt;. We conclude that &lt;span class=&quot;MathJax_Preview&quot;&gt;
&lt;script type=&quot;math/tex;mode=display&quot;&gt;

w\left(S\right)\le w\left(\tilde{P}\right)\le w\left(P\right)=2\cdot w\left(S^{*}\right)

&lt;/script&gt;
&lt;/span&gt;
as required.
&lt;/div&gt;</content><author><name>Eran Amar</name></author><category term="algorithms" /><category term="approximation" /><category term="graphs" /><summary type="html">Warning: MathJax requires JavaScript to correctly process the mathematics on this page. Please enable JavaScript on your browser. &amp;lt;/hr&amp;gt;</summary></entry><entry><title type="html">Probabilistic Approximation Algorithm for Set Cover</title><link href="https://eranamar.github.io/site/2017/06/15/Probabilistic-Approximation-Algorithm-for-Set-Cover.html" rel="alternate" type="text/html" title="Probabilistic Approximation Algorithm for Set Cover" /><published>2017-06-15T00:00:00+03:00</published><updated>2017-06-15T00:00:00+03:00</updated><id>https://eranamar.github.io/site/2017/06/15/Probabilistic-Approximation-Algorithm-for-Set-Cover</id><content type="html" xml:base="https://eranamar.github.io/site/2017/06/15/Probabilistic-Approximation-Algorithm-for-Set-Cover.html">&lt;script type=&quot;math/tex&quot;&gt;
\newcommand{\lyxlock}{}
&lt;/script&gt;

&lt;noscript&gt;
&lt;div class=&quot;warning&quot;&gt;
Warning: &lt;a href=&quot;http://www.mathjax.org/&quot;&gt;MathJax&lt;/a&gt; requires JavaScript to correctly process the mathematics on this page. Please enable JavaScript on your browser.
&lt;/div&gt;&lt;hr /&gt;
&amp;lt;/hr&amp;gt;&lt;/noscript&gt;

&lt;h1 class=&quot;Section&quot;&gt;
&lt;a class=&quot;toc&quot; name=&quot;toc-Section-1&quot;&gt;1&lt;/a&gt; The Weighted Set Cover Problem
&lt;/h1&gt;
&lt;div class=&quot;Unindented&quot;&gt;
In the &lt;i&gt;Weighted Set Cover&lt;/i&gt; (WSC) problem, the input is a triple &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\left(U,\mathcal{F},w\right)
&lt;/script&gt;
&lt;/span&gt; where &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
U
&lt;/script&gt;
&lt;/span&gt; is a universe of &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
n
&lt;/script&gt;
&lt;/span&gt; elements, &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\mathcal{F}=\left\{ A_{1},A_{2},..,A_{m}\right\} 
&lt;/script&gt;
&lt;/span&gt; is a family of &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
m
&lt;/script&gt;
&lt;/span&gt; sets such that each &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
A_{i}\subseteq U
&lt;/script&gt;
&lt;/span&gt; and &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\bigcup_{A\in\mathcal{F}}A=U
&lt;/script&gt;
&lt;/span&gt;, and &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
w:\mathcal{F}\to\mathbb{R}_{&gt;0}
&lt;/script&gt;
&lt;/span&gt; is a weight function that assigns positive weight to each set in &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\mathcal{F}
&lt;/script&gt;
&lt;/span&gt;. A solution &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
S\subseteq\mathcal{F}
&lt;/script&gt;
&lt;/span&gt; for the &lt;i&gt;WSC&lt;/i&gt; problem is &lt;i&gt;valid&lt;/i&gt; if and only if &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\bigcup_{A\in S}A=U
&lt;/script&gt;
&lt;/span&gt;, the weight of the solution is &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
w\left(S\right)=\sum_{A\in S}w\left(A\right)
&lt;/script&gt;
&lt;/span&gt;. Note that there is always a valid solution, and the goal in the WSC problem is to find such one with minimum weight. 
&lt;/div&gt;
&lt;div class=&quot;Indented&quot;&gt;
Weighted Set Cover is “hard” in many aspects. First, it is hard to efficiently find the &lt;i&gt;exact solution&lt;/i&gt;, that is, the problem is NP-Complete so no time-efficient algorithm is known for it. Moreover, it is also hard to approximate the solution better than a &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\log n
&lt;/script&gt;
&lt;/span&gt; factor. Formally, we said that a solution &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
S
&lt;/script&gt;
&lt;/span&gt; is a &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\log n
&lt;/script&gt;
&lt;/span&gt; approximation for WSC if &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
w\left(S\right)\le w\left(S^{*}\right)\cdot\log n
&lt;/script&gt;
&lt;/span&gt;, when &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
S^{*}
&lt;/script&gt;
&lt;/span&gt; is an optimal solution with minimum weight. The WSC is &lt;i&gt;hard to approximate&lt;/i&gt; in the sense that any &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\left(1-\epsilon\right)\cdot\log n
&lt;/script&gt;
&lt;/span&gt; approximation for that problem is NP-Complete by itself, and that is for any &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\epsilon&gt;0
&lt;/script&gt;
&lt;/span&gt;.
&lt;/div&gt;
&lt;div class=&quot;Indented&quot;&gt;
In this post we will describe a probabilistic &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
c\cdot\log n
&lt;/script&gt;
&lt;/span&gt; approximation algorithm for WSC which runs in &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\mathcal{O}\left(poly\left(n,m\right)\right)
&lt;/script&gt;
&lt;/span&gt; time, and &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
c
&lt;/script&gt;
&lt;/span&gt; is some positive constant that controls the success probability of the algorithm.
&lt;/div&gt;
&lt;h1 class=&quot;Section&quot;&gt;
&lt;a class=&quot;toc&quot; name=&quot;toc-Section-2&quot;&gt;2&lt;/a&gt; Equivalent Formulation
&lt;/h1&gt;
&lt;div class=&quot;Unindented&quot;&gt;
We can reformulate the Weighted Set Cover problem as a system of linear equations as follows: For any set &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
A_{i}
&lt;/script&gt;
&lt;/span&gt; define an indicator variable &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
X_{i}\in\left\{ 0,1\right\} 
&lt;/script&gt;
&lt;/span&gt; and let &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
w\left(X_{i}\right):=w\left(A_{i}\right)\cdot X_{i}
&lt;/script&gt;
&lt;/span&gt;, thus if &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
X_{i}=1
&lt;/script&gt;
&lt;/span&gt; then &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
w\left(X_{i}\right)=w\left(A_{i}\right)
&lt;/script&gt;
&lt;/span&gt;, and &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
w\left(X_{i}\right)=0
&lt;/script&gt;
&lt;/span&gt; otherwise. The objective is then to minimize &lt;span class=&quot;MathJax_Preview&quot;&gt;
&lt;script type=&quot;math/tex;mode=display&quot;&gt;

\sum_{i=1}^{m}w\left(X_{i}\right)

&lt;/script&gt;
&lt;/span&gt;
 subject to the &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
n
&lt;/script&gt;
&lt;/span&gt; following linear constrains &lt;span class=&quot;MathJax_Preview&quot;&gt;
&lt;script type=&quot;math/tex;mode=display&quot;&gt;

\forall u\in U:\quad\sum_{i\text{ s.t. }u\in A_{i}}X_{i}\ge1

&lt;/script&gt;
&lt;/span&gt;
&lt;/div&gt;
&lt;div class=&quot;Indented&quot;&gt;
Given a solution &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
l=\left(x_{1},..,x_{m}\right)\in\left\{ 0,1\right\} ^{m}
&lt;/script&gt;
&lt;/span&gt; to that system of equations, we can define the corresponding solution for WSC as &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
S=\left\{ A_{i}\in\mathcal{F}\mid x_{i}=1\right\} 
&lt;/script&gt;
&lt;/span&gt;. Note that by this construction &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
S
&lt;/script&gt;
&lt;/span&gt; must be &lt;i&gt;valid&lt;/i&gt;, moreover, the weights are the same: &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
w\left(l\right)=w\left(S\right)
&lt;/script&gt;
&lt;/span&gt;, so if &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
w\left(l\right)
&lt;/script&gt;
&lt;/span&gt; is minimal then also &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
w\left(S\right)
&lt;/script&gt;
&lt;/span&gt;. The proof of the other direction (from WSC to the system of equations) is similar.
&lt;/div&gt;
&lt;div class=&quot;Indented&quot;&gt;
Because the linear-time mapping from any optimal solution of one problem to an optimal solution for the other, we can conclude that solving this system of equations is NP-Hard. However, if we relax the “integer requirement”, i.e. that &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
X_{i}\in\left\{ 0,1\right\} 
&lt;/script&gt;
&lt;/span&gt;, then the problem becomes much easier. That is, when &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
X_{i}\in\left[0,1\right]
&lt;/script&gt;
&lt;/span&gt; for any &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
i
&lt;/script&gt;
&lt;/span&gt;, that system becomes a convex optimization problem, which we can solved with a polynomial-time algorithm. From now on, we will refer only to the convex version, and denote its (exact) solution as &lt;i&gt;fractional solution&lt;/i&gt;.
&lt;/div&gt;
&lt;div class=&quot;Indented&quot;&gt;
So suppose we have a fractional optimal solution for the linear system &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
l^{*}=\left(x_{1},..,x_{m}\right)\in\left[0,1\right]^{m}
&lt;/script&gt;
&lt;/span&gt;. Note that &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
w\left(l^{*}\right)\le w\left(S^{*}\right)
&lt;/script&gt;
&lt;/span&gt; for any optimal solution &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
S^{*}
&lt;/script&gt;
&lt;/span&gt; for WSC, because the convex formulation allows for more possible valid solutions so the minimum weight can only be smaller than of &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
w\left(S^{*}\right)
&lt;/script&gt;
&lt;/span&gt;. 
&lt;/div&gt;
&lt;div class=&quot;Indented&quot;&gt;
How do we get from &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
l^{*}
&lt;/script&gt;
&lt;/span&gt; a solution for the WSC? The nice trick here is &lt;b&gt;probabilistic rounding&lt;/b&gt;. That is, we will treat each &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
x_{i}
&lt;/script&gt;
&lt;/span&gt; as the probability for selecting &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
A_{i}
&lt;/script&gt;
&lt;/span&gt;. 
&lt;/div&gt;
&lt;div class=&quot;Indented&quot;&gt;
We define the following procedure &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
Alg\left(U,\mathcal{F},w\right)
&lt;/script&gt;
&lt;/span&gt; as an helper function:
&lt;/div&gt;
&lt;ol&gt;
&lt;li&gt;
Repeat for &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
t=1,...,\left(2\log n\right)
&lt;/script&gt;
&lt;/span&gt; times:&lt;ol&gt;
&lt;li&gt;
Initialize &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
S_{t}=\emptyset
&lt;/script&gt;
&lt;/span&gt;.
&lt;/li&gt;
&lt;li&gt;
Solve the convex optimization version of the WSC to get an optimal fractional solution &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
l_{t}^{*}
&lt;/script&gt;
&lt;/span&gt;.
&lt;/li&gt;
&lt;li&gt;
For each &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
A_{i}\in\mathcal{F}
&lt;/script&gt;
&lt;/span&gt;, add it to &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
S_{t}
&lt;/script&gt;
&lt;/span&gt; with probability &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
x_{i}\in l_{t}^{*}
&lt;/script&gt;
&lt;/span&gt;.
&lt;/li&gt;
&lt;li&gt;
Let the “solution” for the current iteration be &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
S_{t}
&lt;/script&gt;
&lt;/span&gt;.
&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;
Output &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\bigcup_{t=1}^{2\log n}S_{t}
&lt;/script&gt;
&lt;/span&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&quot;Unindented&quot;&gt;
The final algorithm is just applying the &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
Alg\left(U,\mathcal{F},w\right)
&lt;/script&gt;
&lt;/span&gt; procedure &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
c
&lt;/script&gt;
&lt;/span&gt; independent times, and keeping the candidate solutions &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
S^{\left(1\right)},...,S^{\left(c\right)}
&lt;/script&gt;
&lt;/span&gt;, then returning the &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
S_{final}
&lt;/script&gt;
&lt;/span&gt; solution with minimum weight among those candidates. 
&lt;/div&gt;
&lt;div class=&quot;Indented&quot;&gt;
Note that all the procedures above have polynomial time (in &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
n
&lt;/script&gt;
&lt;/span&gt; and &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
m
&lt;/script&gt;
&lt;/span&gt;), therefore the total running time of the algorithm is &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\mathcal{O}\left(poly\left(n,m\right)\right)
&lt;/script&gt;
&lt;/span&gt;.
&lt;/div&gt;
&lt;h1 class=&quot;Section&quot;&gt;
&lt;a class=&quot;toc&quot; name=&quot;toc-Section-3&quot;&gt;3&lt;/a&gt; The Solution is &lt;i&gt;Approximately&lt;/i&gt; Optimal
&lt;/h1&gt;
&lt;div class=&quot;Unindented&quot;&gt;
We want to show that with high probability &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
w\left(S_{final}\right)\le c\cdot\log n\cdot w\left(S^{*}\right)
&lt;/script&gt;
&lt;/span&gt;. It is easy to see that for each iteration of the sub-procedure &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
Alg
&lt;/script&gt;
&lt;/span&gt;, the intermediate set &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
S_{t}
&lt;/script&gt;
&lt;/span&gt; has expected weight equals to the weight of the optimal fractional solution. Formally, &lt;span class=&quot;MathJax_Preview&quot;&gt;
&lt;script type=&quot;math/tex;mode=display&quot;&gt;

\mathbb{E}\left[w\left(S_{t}\right)\right]=\sum_{i=1}^{m}w\left(A_{i}\right)\mathbb{E}\left[X_{i}\right]=\sum_{i=1}^{m}w\left(A_{i}\right)x_{i}=w\left(l_{t}^{*}\right)

&lt;/script&gt;
&lt;/span&gt;
note that the optimal value of all the fractional solutions is the same so we will remove the subscript &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
t
&lt;/script&gt;
&lt;/span&gt;. Next, we continue to calculate the expected weight of the output solution of the sub-procedure, that is, the weight of the candidate &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
S^{\left(i\right)}
&lt;/script&gt;
&lt;/span&gt;
&lt;/div&gt;
&lt;div class=&quot;Indented&quot;&gt;
&lt;span class=&quot;MathJax_Preview&quot;&gt;
&lt;script type=&quot;math/tex;mode=display&quot;&gt;
\begin{aligned}
\mathbb{E}\left[w\left(S^{\left(i\right)}\right)\right] &amp; =\mathbb{E}\left[w\left(\bigcup_{t=1}^{2\log n}S_{t}\right)\right]\\
 &amp; \le\sum_{t=1}^{2\log n}\mathbb{E}\left[w\left(S_{t}\right)\right]\\
 &amp; =2\log n\cdot w\left(l^{*}\right)\\
 &amp; \le2\log n\cdot w\left(S^{*}\right)
\end{aligned}
&lt;/script&gt;
&lt;/span&gt;
It left to show that with high probability all the candidates &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\left\{ S^{\left(i\right)}\right\} _{i}
&lt;/script&gt;
&lt;/span&gt; are within the weight bound of &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
c\cdot\log n\cdot w\left(S^{*}\right)
&lt;/script&gt;
&lt;/span&gt;, and because &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
S_{final}
&lt;/script&gt;
&lt;/span&gt; is being selected from those candidates, we conclude that it also has &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\mathbb{E}\left[w\left(S_{final}\right)\right]\le c\cdot\log n\cdot w\left(S^{*}\right)
&lt;/script&gt;
&lt;/span&gt;. In order to get high probability for a single candidate, we can use Markov’s inequality as follows. Define a “failure” of a candidate &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
S^{\left(k\right)}
&lt;/script&gt;
&lt;/span&gt; as &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
w\left(S^{\left(k\right)}\right)\ge c\cdot\log n\cdot w\left(S^{*}\right)
&lt;/script&gt;
&lt;/span&gt;, then the probability of a single candidate to fail is bounded by &lt;span class=&quot;MathJax_Preview&quot;&gt;
&lt;script type=&quot;math/tex;mode=display&quot;&gt;

\mathbb{P}\left[w\left(S^{\left(k\right)}\right)\ge c\cdot\log n\cdot w\left(S^{*}\right)\right]\le\frac{\mathbb{E}\left[w\left(S^{\left(k\right)}\right)\right]}{c\cdot\log n\cdot w\left(S^{*}\right)}\le\frac{2}{c}

&lt;/script&gt;
&lt;/span&gt;
So with probability of at least &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
1-\frac{2}{c}
&lt;/script&gt;
&lt;/span&gt; the candidate has &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
w\left(S^{\left(k\right)}\right)\le c\cdot\log n\cdot w\left(S^{*}\right)
&lt;/script&gt;
&lt;/span&gt; as required.
&lt;/div&gt;
&lt;div class=&quot;Indented&quot;&gt;
When considering the final solution &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
S_{final}
&lt;/script&gt;
&lt;/span&gt;, it fails only when all the candidates fail and the probability for that is &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\le\left(\frac{2}{c}\right)^{c}
&lt;/script&gt;
&lt;/span&gt;. So we have high constant probability to get a solution that is &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
c\cdot\log n
&lt;/script&gt;
&lt;/span&gt; approximation for the optimal solution.
&lt;/div&gt;
&lt;h1 class=&quot;Section&quot;&gt;
&lt;a class=&quot;toc&quot; name=&quot;toc-Section-4&quot;&gt;4&lt;/a&gt; The Solution is &lt;i&gt;Probably&lt;/i&gt; Valid
&lt;/h1&gt;
&lt;div class=&quot;Unindented&quot;&gt;
What is the probability that the returned solution &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
S_{final}
&lt;/script&gt;
&lt;/span&gt; is not valid? that is, there is at least one element &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
u\in U
&lt;/script&gt;
&lt;/span&gt; that is not covered by &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
S_{final}
&lt;/script&gt;
&lt;/span&gt;. We analyze that by first considering an arbitrary element &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
u
&lt;/script&gt;
&lt;/span&gt; and an intermediate solution &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
S_{t}
&lt;/script&gt;
&lt;/span&gt; of the sub procedure &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
Alg
&lt;/script&gt;
&lt;/span&gt;. Suppose that &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
u
&lt;/script&gt;
&lt;/span&gt; belongs to &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
k
&lt;/script&gt;
&lt;/span&gt; sets, and for simplicity suppose they are &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
A_{1},...,A_{k}
&lt;/script&gt;
&lt;/span&gt;. We know that their corresponding variables have &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\sum_{i=1}^{k}x_{i}\ge1
&lt;/script&gt;
&lt;/span&gt; by the requirements of the linear system. The probability to leave all these sets outside &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
S_{t}
&lt;/script&gt;
&lt;/span&gt; is &lt;span class=&quot;MathJax_Preview&quot;&gt;
&lt;script type=&quot;math/tex;mode=display&quot;&gt;

\prod_{i=1}^{k}\left(1-x_{i}\right)\le\prod_{i=1}^{k}e^{-x_{i}}\le e^{-1}

&lt;/script&gt;
&lt;/span&gt;
that is, the probability that an intermediate solution &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
S_{t}
&lt;/script&gt;
&lt;/span&gt; will not cover &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
u
&lt;/script&gt;
&lt;/span&gt; is up to &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
e^{-1}
&lt;/script&gt;
&lt;/span&gt;.
&lt;/div&gt;
&lt;div class=&quot;Indented&quot;&gt;
Next, we calculate the probability that &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
u
&lt;/script&gt;
&lt;/span&gt; is not covered by a &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
S_{final}
&lt;/script&gt;
&lt;/span&gt; where &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
S_{final}=S^{\left(i\right)}
&lt;/script&gt;
&lt;/span&gt; for some selected candidate &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
S^{\left(i\right)}
&lt;/script&gt;
&lt;/span&gt;. Then it must be that &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
u
&lt;/script&gt;
&lt;/span&gt; is not covered by any intermediate solution &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
S_{1},..,S_{2\log n}
&lt;/script&gt;
&lt;/span&gt; of the procedure &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
Alg
&lt;/script&gt;
&lt;/span&gt;, and that will happen with probability &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\le\prod_{t=1}^{2\log n}e^{-1}=\frac{1}{n^{2}}
&lt;/script&gt;
&lt;/span&gt;. Applying the union-bound on all the &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
n
&lt;/script&gt;
&lt;/span&gt; elements, we conclude that with probability of at most &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\frac{1}{n}
&lt;/script&gt;
&lt;/span&gt;, the selected candidate &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
S^{\left(i\right)}
&lt;/script&gt;
&lt;/span&gt; will not cover the entire universe. In other words, with at least &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
1-\frac{1}{n}
&lt;/script&gt;
&lt;/span&gt; probability, &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
S_{final}
&lt;/script&gt;
&lt;/span&gt; is a valid solution.
&lt;/div&gt;</content><author><name>Eran Amar</name></author><category term="algorithms" /><category term="approximation" /><category term="probability_theory" /><summary type="html">Warning: MathJax requires JavaScript to correctly process the mathematics on this page. Please enable JavaScript on your browser. &amp;lt;/hr&amp;gt;</summary></entry><entry><title type="html">Visualizing high-dimensional data with t-SNE</title><link href="https://eranamar.github.io/site/2017/06/11/Visualizing-high-dimensional-data-with-t-SNE.html" rel="alternate" type="text/html" title="Visualizing high-dimensional data with t-SNE" /><published>2017-06-11T00:00:00+03:00</published><updated>2017-06-11T00:00:00+03:00</updated><id>https://eranamar.github.io/site/2017/06/11/Visualizing-high-dimensional-data-with-t-SNE</id><content type="html" xml:base="https://eranamar.github.io/site/2017/06/11/Visualizing-high-dimensional-data-with-t-SNE.html">&lt;script type=&quot;math/tex&quot;&gt;
\newcommand{\lyxlock}{}
&lt;/script&gt;

&lt;noscript&gt;
&lt;div class=&quot;warning&quot;&gt;
Warning: &lt;a href=&quot;http://www.mathjax.org/&quot;&gt;MathJax&lt;/a&gt; requires JavaScript to correctly process the mathematics on this page. Please enable JavaScript on your browser.
&lt;/div&gt;&lt;hr /&gt;
&amp;lt;/hr&amp;gt;&lt;/noscript&gt;

&lt;div class=&quot;Unindented&quot;&gt;
&lt;b&gt;Guest author:&lt;/b&gt; thanks to Aviv Netanyahu for writing this post!
&lt;/div&gt;
&lt;h1 class=&quot;Section&quot;&gt;
&lt;a class=&quot;toc&quot; name=&quot;toc-Section-1&quot;&gt;1&lt;/a&gt; What is visualization and why do we need it?
&lt;/h1&gt;
&lt;div class=&quot;Unindented&quot;&gt;
Before working on a dataset we would like to understand it. After working on it, we want to communicate our conclusions with others easily. When dealing with high-dimensional data, it’s hard to get a ’feel’ for the data by just looking at numbers, and we will advance pretty slowly. For example, common visualization methods are histograms and scatter plots, which capture only one or two parameters at a time, meaning we would have to look at many histograms (one for each feature). However, by visualizing our data we may instantly be able to recognize structure. In order to do this we would like to find a representation of our data in &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
2
&lt;/script&gt;
&lt;/span&gt;D or &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
3
&lt;/script&gt;
&lt;/span&gt;D.
&lt;/div&gt;
&lt;h1 class=&quot;Section&quot;&gt;
&lt;a class=&quot;toc&quot; name=&quot;toc-Section-2&quot;&gt;2&lt;/a&gt; Our goal
&lt;/h1&gt;
&lt;div class=&quot;Unindented&quot;&gt;
Find an embedding of high-dimensional data to 2D or 3D (for simplicity, will assume &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
2
&lt;/script&gt;
&lt;/span&gt;D from now on). &lt;br /&gt;
Formally, we want to learn &lt;span class=&quot;MathJax_Preview&quot;&gt;
&lt;script type=&quot;math/tex;mode=display&quot;&gt;

\{\mathbf{x}_{1},...,\mathbf{x}_{N}\}\to\{\mathbf{y}_{1},...,\mathbf{y}_{N}\}

&lt;/script&gt;
&lt;/span&gt;
 (&lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\{\mathbf{x}_{1},...,\mathbf{x}_{N}\}\subseteq\mathbb{R}^{n}
&lt;/script&gt;
&lt;/span&gt; is our data, &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\{\mathbf{y}_{1},...,\mathbf{y}_{N}\}\subseteq\mathbb{R}^{2}
&lt;/script&gt;
&lt;/span&gt; is the embedding) such that the structure of the original data is preserved after the embedding.
&lt;/div&gt;
&lt;h1 class=&quot;Section&quot;&gt;
&lt;a class=&quot;toc&quot; name=&quot;toc-Section-3&quot;&gt;3&lt;/a&gt; So why not PCA?
&lt;/h1&gt;
&lt;div class=&quot;Unindented&quot;&gt;
PCA projects high-dimensional data onto a lower dimension determined by the directions where the data varies most in. The result is a linear projection which focuses on preserving distance between &lt;b&gt;dissimilar&lt;/b&gt; data points. This is problematic:
&lt;/div&gt;
&lt;ol&gt;
&lt;li&gt;
Linear sometimes isn’t good enough.
&lt;/li&gt;
&lt;li&gt;
We claim structure is mostly determined by &lt;b&gt;similar&lt;/b&gt; data points.
&lt;/li&gt;
&lt;/ol&gt;
&lt;h1 class=&quot;Section&quot;&gt;
&lt;a class=&quot;toc&quot; name=&quot;toc-Section-4&quot;&gt;4&lt;/a&gt; SNE (Hinton&amp;amp;Roweis)
&lt;/h1&gt;
&lt;div class=&quot;Unindented&quot;&gt;
This algorithm for high-dimensional data visualization focuses on preserving high-dimensional ’neighbors’ in low-dimension.
&lt;/div&gt;
&lt;div class=&quot;Indented&quot;&gt;
Assumption - ’neighbors’ in high dimension have small Euclidean distance. SNE converts the Euclidean distances to similarities using Gaussian distribution:&lt;span class=&quot;MathJax_Preview&quot;&gt;
&lt;script type=&quot;math/tex;mode=display&quot;&gt;

p_{j|i}=\frac{\exp\left(-||\mathbf{x}_{i}-\mathbf{x}_{j}||^{2}/2\sigma_{i}^{2}\right)}{\sum\limits _{k\neq i}\exp\left(-||\mathbf{x}_{i}-\mathbf{x}_{k}||^{2}/2\sigma_{i}^{2}\right)}

&lt;/script&gt;
&lt;/span&gt;
&lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
p_{j|i}
&lt;/script&gt;
&lt;/span&gt; is the probability that &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
j
&lt;/script&gt;
&lt;/span&gt; is the neighbor of &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
i
&lt;/script&gt;
&lt;/span&gt; in high-dimension.&lt;span class=&quot;MathJax_Preview&quot;&gt;
&lt;script type=&quot;math/tex;mode=display&quot;&gt;

q_{j|i}=\frac{\exp\left(-||\mathbf{y}_{i}-\mathbf{y}_{j}||^{2}\right)}{\sum\limits _{k\neq i}\exp\left(-||\mathbf{y}_{i}-\mathbf{y}_{k}||^{2}\right)}

&lt;/script&gt;
&lt;/span&gt;
&lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
q_{j|i}
&lt;/script&gt;
&lt;/span&gt; is the probability that &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
j
&lt;/script&gt;
&lt;/span&gt; is the neighbor of &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
i
&lt;/script&gt;
&lt;/span&gt; in low-dimension. &lt;br /&gt;
Note - choosing &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\sigma_{i}
&lt;/script&gt;
&lt;/span&gt; for &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
p_{j|i}
&lt;/script&gt;
&lt;/span&gt; is done by determining the perplexity, i.e. the effective number of neighbors for each data point. Then &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\forall i
&lt;/script&gt;
&lt;/span&gt;, &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\sigma_{i}
&lt;/script&gt;
&lt;/span&gt; is chosen such that &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\mathbf{x}_{i}
&lt;/script&gt;
&lt;/span&gt; has according number of neighbors in the multivariate Gaussian with mean &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\mathbf{x}_{i}
&lt;/script&gt;
&lt;/span&gt; and covariance matrix &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\sigma_{i}\cdot I
&lt;/script&gt;
&lt;/span&gt;. &lt;br /&gt;
&lt;br /&gt;
By mapping each &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\mathbf{x}_{i}\in\mathbb{R}^{n}
&lt;/script&gt;
&lt;/span&gt; to &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\mathbf{y}_{i}\in\mathbb{R}^{2}
&lt;/script&gt;
&lt;/span&gt; such that &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\forall i,j,\,p_{j|i}
&lt;/script&gt;
&lt;/span&gt; is close as possible to &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
q_{j|i}
&lt;/script&gt;
&lt;/span&gt;, we can preserve similarities. The algorithm finds such a mapping by &lt;b&gt;gradient descent&lt;/b&gt; w.r.t. the following loss (cost) function:&lt;span class=&quot;MathJax_Preview&quot;&gt;
&lt;script type=&quot;math/tex;mode=display&quot;&gt;

C=\sum_{i}KL(P_{i}||Q_{i})=\sum_{i}\sum_{j}p_{j|i}\log\frac{p_{j|i}}{q_{j|i}}

&lt;/script&gt;
&lt;/span&gt;
where &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
P_{i}=(p_{1|i},...,p_{N|i}),\,Q_{i}=(q_{1|i},...,q_{N|i})
&lt;/script&gt;
&lt;/span&gt; and the initialization of low-dimensional data is random around the origin. 
&lt;/div&gt;
&lt;div class=&quot;Indented&quot;&gt;
Notice the loss function, Kullback–Leibler (KL) divergence, is a natural way to measure similarity between two distributions.&lt;br /&gt;
Also notice that this loss puts more emphasis on preserving the local structure of the data. KL-div is asymmetric, so different kinds of errors have a different affect:
&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;
Type 1 error: &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
p_{j|i}
&lt;/script&gt;
&lt;/span&gt; is &lt;b&gt;large&lt;/b&gt; (i.e. two points were originally close) and &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
q_{j|i}
&lt;/script&gt;
&lt;/span&gt; &lt;b&gt;small&lt;/b&gt; (i.e. these points were mapped too far), we pay a &lt;b&gt;large&lt;/b&gt; penalty.
&lt;/li&gt;
&lt;li&gt;
Type 2 error: &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
p_{j|i}
&lt;/script&gt;
&lt;/span&gt; is &lt;b&gt;small&lt;/b&gt; (i.e. two points were originally far away) and &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
q_{j|i}
&lt;/script&gt;
&lt;/span&gt; &lt;b&gt;large&lt;/b&gt; (i.e. these points were mapped too close), we pay a &lt;b&gt;small&lt;/b&gt; penalty.
&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&quot;Unindented&quot;&gt;
This is good, as structure is preserved better by focusing on keeping close points together. This is easy to see in the following example: think of “unrolling” this swiss roll (like unrolling a carpet). Close points will stay within the same distance, far points won’t. This is true for many manifolds (spaces that locally resemble Euclidean space near each point) besides the swiss roll.
&lt;/div&gt;
&lt;div class=&quot;Indented&quot;&gt;
&lt;div class=&quot;Frameless&quot; style=&quot;width: 100%;&quot;&gt;
&lt;div class=&quot;center&quot;&gt;
&lt;img alt=&quot;figure swiss_roll.png&quot; class=&quot;embedded&quot; src=&quot;/site/assets/imgs/2017-06-11-t-SNE/swiss_roll.png&quot; style=&quot;width: 336px; max-width: 672px; height: 244px; max-height: 489px;&quot; /&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;h2 class=&quot;Subsection&quot;&gt;
&lt;a class=&quot;toc&quot; name=&quot;toc-Subsection-4.1&quot;&gt;4.1&lt;/a&gt; The crowding problem
&lt;/h2&gt;
&lt;div class=&quot;Unindented&quot;&gt;
The main problem with SNE - mapped points tend to “crowd” together, like in this example: images of 5 MNIST digits mapped with SNE to 2D and then marked by labels
&lt;/div&gt;
&lt;div class=&quot;Indented&quot;&gt;
&lt;div class=&quot;Frameless&quot; style=&quot;width: 100%;&quot;&gt;
&lt;div class=&quot;center&quot;&gt;
&lt;img alt=&quot;figure crowding.jpg&quot; class=&quot;embedded&quot; src=&quot;/site/assets/imgs/2017-06-11-t-SNE/crowding.jpg&quot; style=&quot;width: 237px; max-width: 475px; height: 230px; max-height: 461px;&quot; /&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;Indented&quot;&gt;
This happens because when reducing the dimensionality we need more “space” in which to represent our data-points. You can think of a sphere flattened to a circle where all distances are preserved (as much as possible) - the radius of the circle will have to be larger than the radius of the sphere!
&lt;/div&gt;
&lt;div class=&quot;Indented&quot;&gt;
On one hand this causes type &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
1
&lt;/script&gt;
&lt;/span&gt; error (close points mapped too far), which forces far mapped points to come closer together. On the other, causes type &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
2
&lt;/script&gt;
&lt;/span&gt; error (far points mapped close) which forces them to move away from each other. Type &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
2
&lt;/script&gt;
&lt;/span&gt; error makes us pay a small price, however if many points cause error &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
2
&lt;/script&gt;
&lt;/span&gt;, the price will be higher, forcing the points to indeed move. What we just described causes the mapped points to correct themselves to the center such that they end up very close to each other. Consider the MNIST example above. If we did not know the labels we couldn’t make much sense of the mapping.
&lt;/div&gt;
&lt;h1 class=&quot;Section&quot;&gt;
&lt;a class=&quot;toc&quot; name=&quot;toc-Section-5&quot;&gt;5&lt;/a&gt; T-SNE (van der Maaten&amp;amp;Hinton)
&lt;/h1&gt;
&lt;h2 class=&quot;Subsection&quot;&gt;
&lt;a class=&quot;toc&quot; name=&quot;toc-Subsection-5.1&quot;&gt;5.1&lt;/a&gt; Solving the crowding problem
&lt;/h2&gt;
&lt;div class=&quot;Unindented&quot;&gt;
Instead of mapped points correcting themselves to minimize the loss, we can do this by increasing &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
q_{j|i}
&lt;/script&gt;
&lt;/span&gt; in advance. Recall, the loss is: &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\sum\limits _{i}\sum\limits _{j}p_{j|i}\log\frac{p_{j|i}}{q_{j|i}}
&lt;/script&gt;
&lt;/span&gt;, thus larger &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
q_{j|i}
&lt;/script&gt;
&lt;/span&gt; minimizes it. We do this by defining: &lt;span class=&quot;MathJax_Preview&quot;&gt;
&lt;script type=&quot;math/tex;mode=display&quot;&gt;

q_{ij}=\frac{(1+||\mathbf{y}_{i}-\mathbf{y}_{j}||)^{-1}}{\sum\limits _{k\neq l}(1+||\mathbf{y}_{k}-\mathbf{y}_{l}||)^{-1}}

&lt;/script&gt;
&lt;/span&gt;
using Cauchy distribution instead of Gaussian distribution. This increases &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
q_{j|i}
&lt;/script&gt;
&lt;/span&gt; since Cauchy distribution has a heavier tail than Gaussian distribution:
&lt;/div&gt;
&lt;div class=&quot;Indented&quot;&gt;
&lt;div class=&quot;Frameless&quot; style=&quot;width: 100%;&quot;&gt;
&lt;div class=&quot;center&quot;&gt;
&lt;img alt=&quot;figure cauchy.jpg&quot; class=&quot;embedded&quot; src=&quot;/site/assets/imgs/2017-06-11-t-SNE/cauchy.jpg&quot; style=&quot;width: 398px; max-width: 797px; height: 274px; max-height: 548px;&quot; /&gt;
&lt;/div&gt;
&lt;/div&gt;
(Hence the name of the algorithm - Cauchy distribution is a T-student distribution with &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
1
&lt;/script&gt;
&lt;/span&gt; degree of freedom).
&lt;/div&gt;
&lt;div class=&quot;Indented&quot;&gt;
Note also that we changed the probability from conditional to joint probability (this was done for technical optimization reasons). For the same reason, &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
p_{j|i}
&lt;/script&gt;
&lt;/span&gt; was converted to &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
p_{ij}=\frac{p_{j|i}+p_{i|j}}{2N}
&lt;/script&gt;
&lt;/span&gt;. We can still use Gaussian distribution for the original data since we are trying to compensate for error in the &lt;b&gt;mapped&lt;/b&gt; space.
&lt;/div&gt;
&lt;div class=&quot;Indented&quot;&gt;
Now the performance on MNIST is much better:
&lt;/div&gt;
&lt;div class=&quot;Indented&quot;&gt;
&lt;div class=&quot;Frameless&quot; style=&quot;width: 100%;&quot;&gt;
&lt;div class=&quot;center&quot;&gt;
&lt;img alt=&quot;figure mnist.png&quot; class=&quot;embedded&quot; src=&quot;/site/assets/imgs/2017-06-11-t-SNE/mnist.png&quot; style=&quot;width: 378px; max-width: 757px; height: 214px; max-height: 429px;&quot; /&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;Indented&quot;&gt;
It’s obvious that global structure is preserved and crowding is resolved. Notice also that when zooming in on the mapping of &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
1
&lt;/script&gt;
&lt;/span&gt; digits, the local structure is preserved as well - digits with same orientation were mapped close to each other.
&lt;/div&gt;
&lt;h1 class=&quot;Section&quot;&gt;
&lt;a class=&quot;toc&quot; name=&quot;toc-Section-6&quot;&gt;6&lt;/a&gt; Barnes-Hut approximation (van der Maaten)
&lt;/h1&gt;
&lt;div class=&quot;Unindented&quot;&gt;
Computing the gradient for each mapped point each iteration is very costly, especially when the dataset is very large. At each iteration, &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\forall i
&lt;/script&gt;
&lt;/span&gt;, we compute:&lt;span class=&quot;MathJax_Preview&quot;&gt;
&lt;script type=&quot;math/tex;mode=display&quot;&gt;

\frac{\partial C}{\partial\mathbf{y}_{i}}=4\sum_{j\neq i}\frac{(p_{ij}-q_{ij})}{1+||\mathbf{y}_{i}-\mathbf{y}_{j}||^{2}}\cdot(\mathbf{y}_{i}-\mathbf{y}_{j})

&lt;/script&gt;
&lt;/span&gt;
We can think of &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\mathbf{y}_{i}-\mathbf{y}_{j}
&lt;/script&gt;
&lt;/span&gt; as a spring between these two points (it might be too tight/loose depending on if the points were mapped to far/close accordingly). The fraction can be thought of as exertion/compression of the spring, in other words the correction we do in this iteration. We calculate this for &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
N
&lt;/script&gt;
&lt;/span&gt; mapped points, and derive &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
C
&lt;/script&gt;
&lt;/span&gt; by all data-points, so for each iteration we have &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\mathcal{O}(N^{2})
&lt;/script&gt;
&lt;/span&gt; computations. This limits us to datasets with only few thousands of points! However, we can reduce the computation time to &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\mathcal{O}(N\log N)
&lt;/script&gt;
&lt;/span&gt; by reducing the number of computations per iteration. The main idea - forces exerted by a group of points on a point that is relatively far away are all very similar. Therefore we can calculate &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\mathbf{y}_{i}-\mathbf{y}_{j^{*}}
&lt;/script&gt;
&lt;/span&gt;where &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\mathbf{y}_{j^{*}}
&lt;/script&gt;
&lt;/span&gt; is the average of the group of far away points, instead of &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\mathbf{y}_{i}-\mathbf{y}_{j}
&lt;/script&gt;
&lt;/span&gt; for each &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\mathbf{y}_{j}
&lt;/script&gt;
&lt;/span&gt; in the far away group.
&lt;/div&gt;
&lt;h1 class=&quot;Section&quot;&gt;
&lt;a class=&quot;toc&quot; name=&quot;toc-Section-7&quot;&gt;7&lt;/a&gt; Some applications
&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;
Visualize word embeddings - &lt;a class=&quot;URL&quot; href=&quot;http://nlp.yvespeirsman.be/blog/visualizing-word-embeddings-with-tsne/&quot;&gt;http://nlp.yvespeirsman.be/blog/visualizing-word-embeddings-with-tsne/&lt;/a&gt;
&lt;/li&gt;
&lt;li&gt;
Multiple maps word embeddings - &lt;a class=&quot;URL&quot; href=&quot;http://homepage.tudelft.nl/19j49/multiplemaps/Multiple_maps_t-SNE/Multiple_maps_t-SNE.html&quot;&gt;http://homepage.tudelft.nl/19j49/multiplemaps/Multiple_maps_t-SNE/Multiple_maps_t-SNE.html&lt;/a&gt;
&lt;/li&gt;
&lt;li&gt;
Visualization of genetic disease phenotype similarities by multiple maps t-SNE - &lt;a class=&quot;URL&quot; href=&quot;https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4243097/&quot;&gt;https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4243097/&lt;/a&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 class=&quot;Section&quot;&gt;
&lt;a class=&quot;toc&quot; name=&quot;toc-Section-8&quot;&gt;8&lt;/a&gt; When can t-SNE fail?
&lt;/h1&gt;
&lt;div class=&quot;Unindented&quot;&gt;
When the data is noisy or on a highly varying manifold, the local linearity assumption we make (by converting Euclidean distances to similarities) does not hold. What can we do? - smooth data with PCA (in case of noise) or use Autoencoders (in case of highly varying manifold).
&lt;/div&gt;</content><author><name>Aviv Netanyahu</name></author><category term="guest_author" /><category term="visualization" /><category term="dimensionality_reduction" /><summary type="html">Warning: MathJax requires JavaScript to correctly process the mathematics on this page. Please enable JavaScript on your browser. &amp;lt;/hr&amp;gt;</summary></entry><entry><title type="html">Greedy Algorithm for Multiway-Cut in Trees</title><link href="https://eranamar.github.io/site/2017/05/26/Greedy-Algorithm-for-Multiway-Cut-in-Trees.html" rel="alternate" type="text/html" title="Greedy Algorithm for Multiway-Cut in Trees" /><published>2017-05-26T00:00:00+03:00</published><updated>2017-05-26T00:00:00+03:00</updated><id>https://eranamar.github.io/site/2017/05/26/Greedy-Algorithm-for-Multiway-Cut-in-Trees</id><content type="html" xml:base="https://eranamar.github.io/site/2017/05/26/Greedy-Algorithm-for-Multiway-Cut-in-Trees.html">&lt;script type=&quot;math/tex&quot;&gt;
\newcommand{\lyxlock}{}
&lt;/script&gt;

&lt;noscript&gt;
&lt;div class=&quot;warning&quot;&gt;
Warning: &lt;a href=&quot;http://www.mathjax.org/&quot;&gt;MathJax&lt;/a&gt; requires JavaScript to correctly process the mathematics on this page. Please enable JavaScript on your browser.
&lt;/div&gt;&lt;hr /&gt;
&amp;lt;/hr&amp;gt;&lt;/noscript&gt;

&lt;h1 class=&quot;Section&quot;&gt;
&lt;a class=&quot;toc&quot; name=&quot;toc-Section-1&quot;&gt;1&lt;/a&gt; The Multiway Cut Problem
&lt;/h1&gt;
&lt;div class=&quot;Unindented&quot;&gt;
The &lt;i&gt;Multiway Cut&lt;/i&gt; (MC) problem is a generalization of the known&lt;i&gt; Min-Cut&lt;/i&gt; problem. The input is a triple &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\left(G,T,w\right)
&lt;/script&gt;
&lt;/span&gt; where &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
G
&lt;/script&gt;
&lt;/span&gt; is an undirected graph with a set &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
V\left(G\right)
&lt;/script&gt;
&lt;/span&gt; of &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
n
&lt;/script&gt;
&lt;/span&gt; vertices and a set &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
E\left(G\right)
&lt;/script&gt;
&lt;/span&gt; of &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
m
&lt;/script&gt;
&lt;/span&gt; edges, &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
T\subset V\left(G\right)
&lt;/script&gt;
&lt;/span&gt; is the set of &lt;i&gt;terminals&lt;/i&gt;, and &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
w:E\left(G\right)\to\mathbb{R}_{&gt;0}
&lt;/script&gt;
&lt;/span&gt; is a function that assign positive weight to each edge in the graph. A valid &lt;i&gt;cut&lt;/i&gt; &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
C\subseteq E\left(G\right)
&lt;/script&gt;
&lt;/span&gt; is a set of edges such that any two vertices &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
t_{1},t_{2}\in T
&lt;/script&gt;
&lt;/span&gt; are disconnected over the sub-graph &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
H:=\left(V\left(G\right),E\left(G\right)\backslash C\right)
&lt;/script&gt;
&lt;/span&gt;. The &lt;i&gt;weight&lt;/i&gt; of a given cut &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
C
&lt;/script&gt;
&lt;/span&gt; is the sum of wights of its edges, that is, &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
w\left(C\right)=\sum_{e\in C}w\left(e\right)
&lt;/script&gt;
&lt;/span&gt;. A solution for the &lt;i&gt;MC&lt;/i&gt; problem is a valid cut of minimum weight.
&lt;/div&gt;
&lt;div class=&quot;Indented&quot;&gt;
Let &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
k=\left|T\right|
&lt;/script&gt;
&lt;/span&gt;. Note that when &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
k=2
&lt;/script&gt;
&lt;/span&gt; the problem is reduced to the regular &lt;i&gt;Min-Cut&lt;/i&gt; problem. For general graphs, any &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
k&gt;2
&lt;/script&gt;
&lt;/span&gt; makes the problem NP-Hard. However, there are efficient algorithms for &lt;i&gt;Multiway-Cut&lt;/i&gt; in &lt;b&gt;trees&lt;/b&gt;. A tree is a connected acyclic graph. It is easy to see that if our graph is a tree, any two vertices in it must be connected by exactly one path. Moreover, &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
m=n-1
&lt;/script&gt;
&lt;/span&gt;. We will use these properties later when we prove that the algorithm gives an optimal solution.
&lt;/div&gt;
&lt;h1 class=&quot;Section&quot;&gt;
&lt;a class=&quot;toc&quot; name=&quot;toc-Section-2&quot;&gt;2&lt;/a&gt; Efficient Algorithm for &lt;i&gt;MC&lt;/i&gt; in Trees
&lt;/h1&gt;
&lt;div class=&quot;Unindented&quot;&gt;
Let &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\left(G,T,w\right)
&lt;/script&gt;
&lt;/span&gt; be the input to the algorithm, and &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
G
&lt;/script&gt;
&lt;/span&gt; is a tree. To simplify the analysis later on, we will work slightly differently; instead of trying to find a small-weight set &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
C\subseteq E\left(G\right)
&lt;/script&gt;
&lt;/span&gt; &lt;i&gt;to discard&lt;/i&gt; from the graph, we will try to find a large-weight set &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
S\subseteq E\left(G\right)
&lt;/script&gt;
&lt;/span&gt; &lt;i&gt;to&lt;/i&gt; &lt;i&gt;keep&lt;/i&gt; in the graph. Note that obviously &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
S=V\left(G\right)\backslash C
&lt;/script&gt;
&lt;/span&gt; and &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
C=V\left(G\right)\backslash S
&lt;/script&gt;
&lt;/span&gt;. Therefore, finding &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
S
&lt;/script&gt;
&lt;/span&gt; with maximum weight is equivalent to finding &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
C
&lt;/script&gt;
&lt;/span&gt; with minimum weight.
&lt;/div&gt;
&lt;div class=&quot;Indented&quot;&gt;
The idea is to start with a trivial (and probably not optimal) solution &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
S=\emptyset
&lt;/script&gt;
&lt;/span&gt;, that is, we don’t keep any edge in the graph such that all the terminals are separated, and we will improve &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
S
&lt;/script&gt;
&lt;/span&gt; iteratively. 
&lt;/div&gt;
&lt;div class=&quot;Indented&quot;&gt;
We start off with some definitions: 
&lt;/div&gt;
&lt;div class=&quot;Indented&quot;&gt;
A &lt;i&gt;connected component&lt;/i&gt; (CC) of a vertex &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
u
&lt;/script&gt;
&lt;/span&gt; over a graph &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
G
&lt;/script&gt;
&lt;/span&gt; is the set of all vertices that can be reached from &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
u
&lt;/script&gt;
&lt;/span&gt; in &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
G
&lt;/script&gt;
&lt;/span&gt;. Note that if &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\left|V\left(G\right)\right|=n
&lt;/script&gt;
&lt;/span&gt; then there are at most &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
n
&lt;/script&gt;
&lt;/span&gt; CCs in &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
G
&lt;/script&gt;
&lt;/span&gt; (each vertex has its own CC, which is the case when the graph has no edges). 
&lt;/div&gt;
&lt;div class=&quot;Indented&quot;&gt;
A vertex &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
t
&lt;/script&gt;
&lt;/span&gt; inside some CC is a &lt;i&gt;master node&lt;/i&gt; if it is a terminal vertex. We then say that all the other vertices in that CC are &lt;i&gt;dominated&lt;/i&gt; by &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
t
&lt;/script&gt;
&lt;/span&gt;.
&lt;/div&gt;
&lt;div class=&quot;Indented&quot;&gt;
Now it is time to describe the algorithm:
&lt;/div&gt;
&lt;ol&gt;
&lt;li&gt;
Start by sorting the &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
n-1
&lt;/script&gt;
&lt;/span&gt; edges of &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
E
&lt;/script&gt;
&lt;/span&gt; in descending order according to their weights. Let &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
e_{1},e_{2},..,e_{n-1}
&lt;/script&gt;
&lt;/span&gt; be the ordered sequence such that &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\forall i,\:w\left(e_{i}\right)&gt;w\left(e_{i+1}\right)
&lt;/script&gt;
&lt;/span&gt;. 
&lt;/li&gt;
&lt;li&gt;
Initialize a trivial solution &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
S_{0}=\emptyset
&lt;/script&gt;
&lt;/span&gt;. Maintain a set &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
R_{0}=\left\{ \left\{ v\right\} \mid v\in V\left(G\right)\right\} 
&lt;/script&gt;
&lt;/span&gt; of all the CCs in the resulting graph (each vertex is its own CC).
&lt;/li&gt;
&lt;li&gt;
For each &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
i=1,...,n-1
&lt;/script&gt;
&lt;/span&gt; do the following: &lt;ol&gt;
&lt;li&gt;
Consider the endpoints of the edge &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
e_{i}=\left\{ v_{1},v_{2}\right\} 
&lt;/script&gt;
&lt;/span&gt; and let &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
CC_{1},CC_{2}
&lt;/script&gt;
&lt;/span&gt; be the connected components of &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
v_{1},v_{2}
&lt;/script&gt;
&lt;/span&gt; respectively. If at least one of them do not has a master node, update &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
S_{i}=S_{i-1}\cup\left\{ e_{i}\right\} 
&lt;/script&gt;
&lt;/span&gt; and let &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
R_{i}
&lt;/script&gt;
&lt;/span&gt; be the same as &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
R_{i-1}
&lt;/script&gt;
&lt;/span&gt; but with &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
CC_{1},CC_{2}
&lt;/script&gt;
&lt;/span&gt; merged into a new single connected component. Otherwise &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
S_{i}=S_{i-1}
&lt;/script&gt;
&lt;/span&gt; and &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
R_{i}=R_{i-1}
&lt;/script&gt;
&lt;/span&gt;. 
&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;
Return the set &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
S_{n-1}
&lt;/script&gt;
&lt;/span&gt;.
&lt;/li&gt;
&lt;/ol&gt;
&lt;h1 class=&quot;Section&quot;&gt;
&lt;a class=&quot;toc&quot; name=&quot;toc-Section-3&quot;&gt;3&lt;/a&gt; The Solution is Correct and Optimal
&lt;/h1&gt;
&lt;div class=&quot;Unindented&quot;&gt;
It is easy to see that &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
S_{n-1}
&lt;/script&gt;
&lt;/span&gt; is a valid solution; we started with all the terminals separated in their own CC, and in each iteration we never connect two CCs that have different masters (i.e. terminals). Therefore, in the returned set, all the connected components has at most one master, meaning that the terminals are separated.
&lt;/div&gt;
&lt;div class=&quot;Indented&quot;&gt;
The fact that &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
S_{n-1}
&lt;/script&gt;
&lt;/span&gt; has maximum weight follows by the two following claims:
&lt;/div&gt;
&lt;ol&gt;
&lt;li&gt;
Any optimal solution &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
S^{*}\subseteq E\left(G\right)
&lt;/script&gt;
&lt;/span&gt; has &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\left|S^{*}\right|=n-k
&lt;/script&gt;
&lt;/span&gt;. Moreover, &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\left|S_{n-1}\right|=n-k
&lt;/script&gt;
&lt;/span&gt;.
&lt;/li&gt;
&lt;li&gt;
For any iteration &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
i
&lt;/script&gt;
&lt;/span&gt; of the algorithm, there is an (possibly different) optimal solution &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
S^{*}
&lt;/script&gt;
&lt;/span&gt; such that &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
S_{i}\subseteq S^{*}
&lt;/script&gt;
&lt;/span&gt;.
&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&quot;Unindented&quot;&gt;
So we conclude that there exists some optimal &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
S^{*}
&lt;/script&gt;
&lt;/span&gt; such that &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
S_{n-1}=S^{*}
&lt;/script&gt;
&lt;/span&gt;, thus &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
S_{n-1}
&lt;/script&gt;
&lt;/span&gt; has maximum weight.
&lt;/div&gt;
&lt;div class=&quot;Indented&quot;&gt;
We move to state and prove those claims formally.
&lt;/div&gt;
&lt;div class=&quot;Claim&quot;&gt;
Let &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\mathcal{X}
&lt;/script&gt;
&lt;/span&gt; be the set of all maximum-wight solutions for &lt;i&gt;Multiway-Cut&lt;/i&gt; for the instance &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\left(G,T,w\right)
&lt;/script&gt;
&lt;/span&gt; and &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
G
&lt;/script&gt;
&lt;/span&gt; is a tree. Then any &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
S^{*}\in\mathcal{X}
&lt;/script&gt;
&lt;/span&gt; have &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\left|S^{*}\right|=n-k
&lt;/script&gt;
&lt;/span&gt;. Moreover, &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\left|S_{n-1}\right|=n-k
&lt;/script&gt;
&lt;/span&gt;.
&lt;/div&gt;
&lt;div class=&quot;Proof&quot;&gt;
Since we started from a graph that is a tree, the number of CCs in the final sub-graph is exactly &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
n-\left|S\right|
&lt;/script&gt;
&lt;/span&gt;, for any &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
S\subseteq E\left(G\right)
&lt;/script&gt;
&lt;/span&gt;. Let &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
S^{*}
&lt;/script&gt;
&lt;/span&gt; be some optimal solution. It left to show that the sub-graph &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
H^{*}=\left(V\left(G\right),S^{*}\right)
&lt;/script&gt;
&lt;/span&gt; has exactly &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
k
&lt;/script&gt;
&lt;/span&gt; connected components:&lt;br /&gt;
&lt;br /&gt;
Assume that there are less than &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
k
&lt;/script&gt;
&lt;/span&gt;, then we must have two terminals which live in the same CC - invalidating the solution &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
S^{*}
&lt;/script&gt;
&lt;/span&gt;. If we assume that there are more than &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
k
&lt;/script&gt;
&lt;/span&gt; CCs, then we must have a connected component without a master, so we can safely connect it to some other CC with some edge &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
e
&lt;/script&gt;
&lt;/span&gt; that is not in &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
S^{*}
&lt;/script&gt;
&lt;/span&gt; (and such edge exists since &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
G
&lt;/script&gt;
&lt;/span&gt; is connected). That way, we get a new valid solution with greater weight than the weight of &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
S^{*}
&lt;/script&gt;
&lt;/span&gt; which is a contradiction.&lt;br /&gt;
&lt;br /&gt;
Similarly, we prove that &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
S_{n-1}
&lt;/script&gt;
&lt;/span&gt; has &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
k
&lt;/script&gt;
&lt;/span&gt; CCs: If it has less than &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
k
&lt;/script&gt;
&lt;/span&gt;, there must be two terminals in the same CCs, and that contradicts the correctness of &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
S_{n-1}
&lt;/script&gt;
&lt;/span&gt;. If it has more than &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
k
&lt;/script&gt;
&lt;/span&gt; CCs after &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
n-1
&lt;/script&gt;
&lt;/span&gt; iterations, there must be a CC without a master, so we may connect it with some edge, let it be &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
e_{i}
&lt;/script&gt;
&lt;/span&gt;, to other CC without invalidating the solution. But that &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
e_{i}
&lt;/script&gt;
&lt;/span&gt; wasn’t picked when the algorithm considered it - meaning that it could cause a violation in the sub-graph of the &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
i
&lt;/script&gt;
&lt;/span&gt;th iteration, and since that sub-graph is contained in the sub-graph of the last iteration then we can’t add &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
e_{i}
&lt;/script&gt;
&lt;/span&gt; to our solution - a contradiction.
&lt;/div&gt;
&lt;div class=&quot;Unindented&quot;&gt;
Note that since any optimal solution have exactly &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
k
&lt;/script&gt;
&lt;/span&gt; CCs, we have that each CC must contains one terminal. So in the final sub-graph defined by the solution, any &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
u\in V\left(G\right)
&lt;/script&gt;
&lt;/span&gt; is dominated by exactly one master mode &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
t\in T
&lt;/script&gt;
&lt;/span&gt;.
&lt;/div&gt;
&lt;div class=&quot;Claim&quot;&gt;
Let &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\mathcal{X}
&lt;/script&gt;
&lt;/span&gt; be the set of all optimal solutions for the instance &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\left(G,T,w\right)
&lt;/script&gt;
&lt;/span&gt; and &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
G
&lt;/script&gt;
&lt;/span&gt; in a tree. For any &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
i\in\left\{ 0,1,..,n-1\right\} 
&lt;/script&gt;
&lt;/span&gt; let &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\mathcal{X}_{i}=\left\{ S^{*}\in\mathcal{X}\mid S_{i}\subset S^{*}\right\} 
&lt;/script&gt;
&lt;/span&gt; be the set of optimal solutions such that &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
S_{i}
&lt;/script&gt;
&lt;/span&gt; contained in them. Then, for any &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
i
&lt;/script&gt;
&lt;/span&gt;, &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\mathcal{X}_{i}\ne\emptyset
&lt;/script&gt;
&lt;/span&gt;.
&lt;/div&gt;
&lt;div class=&quot;Proof&quot;&gt;
For &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
i=0
&lt;/script&gt;
&lt;/span&gt; we have &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
S_{0}=\emptyset
&lt;/script&gt;
&lt;/span&gt; thus &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\mathcal{X}_{0}=\mathcal{X}
&lt;/script&gt;
&lt;/span&gt; which is not empty. Assume toward contradiction that the claim is false, and let &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
i
&lt;/script&gt;
&lt;/span&gt; be the smallest such that &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\mathcal{X}_{i}=\emptyset
&lt;/script&gt;
&lt;/span&gt;, so we know that &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\mathcal{X}_{i-1}
&lt;/script&gt;
&lt;/span&gt; is not empty, and hence &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
S_{i-1}\ne S_{i}
&lt;/script&gt;
&lt;/span&gt;. In other words, during the &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
i
&lt;/script&gt;
&lt;/span&gt;th iteration, the algorithm added the edge &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
e_{i}=\left\{ v,u\right\} 
&lt;/script&gt;
&lt;/span&gt; to &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
S_{i-1}
&lt;/script&gt;
&lt;/span&gt;, causing &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\mathcal{X}_{i}
&lt;/script&gt;
&lt;/span&gt; to be empty.&lt;br /&gt;
&lt;br /&gt;
Fix some &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
S^{*}\in\mathcal{X}_{i-1}
&lt;/script&gt;
&lt;/span&gt;. Denote &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
H_{i-1}=\left(V\left(G\right),S_{i-1}\right)
&lt;/script&gt;
&lt;/span&gt; and &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
H^{*}=\left(V\left(G\right),S^{*}\right)
&lt;/script&gt;
&lt;/span&gt; the subgraphs of &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
G
&lt;/script&gt;
&lt;/span&gt;. From the update rule of the algorithm, at least one of &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\left\{ u,v\right\} 
&lt;/script&gt;
&lt;/span&gt; is not dominated by a master over &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
H_{i-1}
&lt;/script&gt;
&lt;/span&gt;, w.l.o.g assume it is &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
u
&lt;/script&gt;
&lt;/span&gt;. Let &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
r\in T
&lt;/script&gt;
&lt;/span&gt; be the master that dominates &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
u
&lt;/script&gt;
&lt;/span&gt; over &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
H^{*}
&lt;/script&gt;
&lt;/span&gt;, and consider the path connecting &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
r\rightsquigarrow u
&lt;/script&gt;
&lt;/span&gt;, note that any edge along that path belongs to &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
S^{*}
&lt;/script&gt;
&lt;/span&gt;. Since the path does not exists in &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
H_{n-1}
&lt;/script&gt;
&lt;/span&gt; and in particular in &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
H_{i-1}
&lt;/script&gt;
&lt;/span&gt;, there is at least one edge that is part of the path and not in &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
S_{i-1}
&lt;/script&gt;
&lt;/span&gt;, let &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
e_{j}
&lt;/script&gt;
&lt;/span&gt; be such one with minimum weight.&lt;br /&gt;
&lt;br /&gt;
Observe that it is impossible that &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
w\left(e_{j}\right)&gt;w\left(e_{i}\right)
&lt;/script&gt;
&lt;/span&gt; because it means that the algorithm already rejected &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
e_{j}
&lt;/script&gt;
&lt;/span&gt; on the &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
j
&lt;/script&gt;
&lt;/span&gt;th iteration and since it was a violation for &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
H_{j}
&lt;/script&gt;
&lt;/span&gt; and &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
H_{j}\subset H_{i-1}
&lt;/script&gt;
&lt;/span&gt; then it is also a violation for &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
H_{i-1}
&lt;/script&gt;
&lt;/span&gt; therefore &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
e_{j}
&lt;/script&gt;
&lt;/span&gt; does not belongs to any optimal solution in &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\mathcal{X}_{i-1}
&lt;/script&gt;
&lt;/span&gt;, in contradiction that &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
e_{j}\in S^{*}\in\mathcal{X}_{i-1}
&lt;/script&gt;
&lt;/span&gt;.&lt;br /&gt;
&lt;br /&gt;
So suppose &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
w\left(e_{j}\right)\le w\left(e_{i}\right)
&lt;/script&gt;
&lt;/span&gt;. Note that in the sub-graph &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
H^{*}
&lt;/script&gt;
&lt;/span&gt; induced by &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
S^{*}
&lt;/script&gt;
&lt;/span&gt;, &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
v
&lt;/script&gt;
&lt;/span&gt; must be dominated my some terminal &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
t\in T
&lt;/script&gt;
&lt;/span&gt;. Because &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
H^{*}
&lt;/script&gt;
&lt;/span&gt; is a sub-graph of a tree, if &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
t=r
&lt;/script&gt;
&lt;/span&gt; then we can close a cycle by adding &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
e_{i}
&lt;/script&gt;
&lt;/span&gt; to &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
S^{*}
&lt;/script&gt;
&lt;/span&gt;, thus &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
t\ne r
&lt;/script&gt;
&lt;/span&gt;. Consider the sub-graph &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
H'=\left(V\left(G\right),S^{*}\cup\left\{ e_{i}\right\} \right)
&lt;/script&gt;
&lt;/span&gt;. The edge &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
e_{i}
&lt;/script&gt;
&lt;/span&gt; connects now the terminals &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
t
&lt;/script&gt;
&lt;/span&gt; and &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
r
&lt;/script&gt;
&lt;/span&gt;, and that is the only violation in &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
H'
&lt;/script&gt;
&lt;/span&gt;. Since &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
H'
&lt;/script&gt;
&lt;/span&gt; is a sub-graph of a tree there is only one path connecting &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
t
&lt;/script&gt;
&lt;/span&gt; and &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
r
&lt;/script&gt;
&lt;/span&gt; and it must contains the path &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
r\rightsquigarrow u
&lt;/script&gt;
&lt;/span&gt;, so removing the edge &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
e_{j}
&lt;/script&gt;
&lt;/span&gt; will break the connection between &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
t,r
&lt;/script&gt;
&lt;/span&gt; leading to a valid solution &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
S'=\left(S^{*}\cup\left\{ e_{i}\right\} \right)\backslash\left\{ e_{j}\right\} 
&lt;/script&gt;
&lt;/span&gt;. By the assumption that &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
w\left(e_{j}\right)\le w\left(e_{i}\right)
&lt;/script&gt;
&lt;/span&gt; the weight of &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
S'
&lt;/script&gt;
&lt;/span&gt; can only increase (in fact, the optimality of &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
S^{*}
&lt;/script&gt;
&lt;/span&gt; forces &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
w\left(e_{j}\right)=w\left(e_{i}\right)
&lt;/script&gt;
&lt;/span&gt;) and we get an optimal solution that contains &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
S_{i}
&lt;/script&gt;
&lt;/span&gt;, therefore &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\mathcal{X}_{i}\ne\emptyset
&lt;/script&gt;
&lt;/span&gt;, contradiction. 
&lt;/div&gt;
&lt;h1 class=&quot;Section&quot;&gt;
&lt;a class=&quot;toc&quot; name=&quot;toc-Section-4&quot;&gt;4&lt;/a&gt; Running Time and Similar Algorithms
&lt;/h1&gt;
&lt;div class=&quot;Unindented&quot;&gt;
Note that &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\left|E\left(G\right)\right|=n-1
&lt;/script&gt;
&lt;/span&gt;, so step 1 of the algorithm takes &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\mathcal{O}\left(n\log n\right)
&lt;/script&gt;
&lt;/span&gt;. Step 2 is order of &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
n
&lt;/script&gt;
&lt;/span&gt;, times the cost of the operations inside the loop. There are data structures such as Union-Find that allow us to track the CCs of the current sub-graph in amortize small running time that is smaller than &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\log n
&lt;/script&gt;
&lt;/span&gt;. Therefore, the total running time is bounded by &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\mathcal{O}
&lt;/script&gt;
&lt;/span&gt;&lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\left(n\log n\right)
&lt;/script&gt;
&lt;/span&gt;. 
&lt;/div&gt;
&lt;div class=&quot;Indented&quot;&gt;
Note that the algorithm presented in section 2, is similar to Kruskal’s algorithm for finding the minimum spanning tree. In both cases, the greedy approach leads to an optimal solution. 
&lt;/div&gt;</content><author><name>Eran Amar</name></author><category term="algorithms" /><category term="graphs" /><summary type="html">Warning: MathJax requires JavaScript to correctly process the mathematics on this page. Please enable JavaScript on your browser. &amp;lt;/hr&amp;gt;</summary></entry><entry><title type="html">Recurrent Neural Network - Recent Advancements</title><link href="https://eranamar.github.io/site/2017/05/18/Recurrent-Neural-Network-Recent-Advancements.html" rel="alternate" type="text/html" title="Recurrent Neural Network - Recent Advancements" /><published>2017-05-18T00:00:00+03:00</published><updated>2017-05-18T00:00:00+03:00</updated><id>https://eranamar.github.io/site/2017/05/18/Recurrent-Neural-Network---Recent-Advancements</id><content type="html" xml:base="https://eranamar.github.io/site/2017/05/18/Recurrent-Neural-Network-Recent-Advancements.html">&lt;script type=&quot;math/tex&quot;&gt;
\newcommand{\lyxlock}{}
&lt;/script&gt;

&lt;noscript&gt;
&lt;div class=&quot;warning&quot;&gt;
Warning: &lt;a href=&quot;http://www.mathjax.org/&quot;&gt;MathJax&lt;/a&gt; requires JavaScript to correctly process the mathematics on this page. Please enable JavaScript on your browser.
&lt;/div&gt;&lt;hr /&gt;
&amp;lt;/hr&amp;gt;&lt;/noscript&gt;

&lt;h1 class=&quot;Section&quot;&gt;
&lt;a class=&quot;toc&quot; name=&quot;toc-Section-1&quot;&gt;1&lt;/a&gt; Last Post of the Series
&lt;/h1&gt;
&lt;div class=&quot;Unindented&quot;&gt;
This post is the last in the series that discussed Recurrent Neural Networks (RNNs). The first post introduced the &lt;a class=&quot;URL&quot; href=&quot;https://eranamar.github.io/site/2017/04/20/Recurrent-Neural-Network-Introduction.html&quot;&gt;basic recurrent cells and their limitations&lt;/a&gt;, the second post presented the formulation of &lt;a class=&quot;URL&quot; href=&quot;https://eranamar.github.io/site/2017/04/30/Recurrent-Neural-Network-LSTM-and-GRU.html&quot;&gt;gated cells as LSTMs and GRUs&lt;/a&gt;, and the third post overviewed &lt;a class=&quot;URL&quot; href=&quot;https://eranamar.github.io/site/2017/05/12/Recurrent-Neural-Network-Dropout-for-LSTMs.html&quot;&gt;dropout variants for LSTMs&lt;/a&gt;. This post will present some of the recent advancements in the filed of RNNs (mostly related to LSTM units). 
&lt;/div&gt;
&lt;div class=&quot;Indented&quot;&gt;
We start by reviewing some of the notations that we used during the series. 
&lt;/div&gt;
&lt;div class=&quot;Indented&quot;&gt;
We defined &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\mathcal{S}_{\sigma}
&lt;/script&gt;
&lt;/span&gt; to be the family of all affine transformations &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\mathbb{R}^{n}\times\mathbb{R}^{n}\to\mathbb{R}^{m}
&lt;/script&gt;
&lt;/span&gt; for any dimensions &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
n
&lt;/script&gt;
&lt;/span&gt; and &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
m
&lt;/script&gt;
&lt;/span&gt;, followed by an element-wise activation function &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\sigma
&lt;/script&gt;
&lt;/span&gt;, that is,
&lt;/div&gt;
&lt;div class=&quot;Indented&quot;&gt;
&lt;span class=&quot;MathJax_Preview&quot;&gt;
&lt;script type=&quot;math/tex;mode=display&quot;&gt;

\mathcal{S}_{\sigma}=\left\{ \mathbf{x},\mathbf{h}\mapsto\sigma\left(W\mathbf{x}+U\mathbf{h}+\mathbf{b}\right)\mid\forall W,U,\mathbf{b}\right\} 

&lt;/script&gt;
&lt;/span&gt;
and noted that with the &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
sigmoid\left(x\right)=\left(1+e^{-x}\right)^{-1}
&lt;/script&gt;
&lt;/span&gt; as the activation function, all the functions in &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\mathcal{S}_{sig}
&lt;/script&gt;
&lt;/span&gt; are &lt;i&gt;gate&lt;/i&gt; functions, that is, their output belongs to &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\left[0,1\right]^{m}
&lt;/script&gt;
&lt;/span&gt;. 
&lt;/div&gt;
&lt;div class=&quot;Indented&quot;&gt;
Usually we do not specify &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
n
&lt;/script&gt;
&lt;/span&gt; and &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
m
&lt;/script&gt;
&lt;/span&gt;, we assume that whenever there is a matrix multiplication of element-wise operation the dimensions always match, as they are not important for the discussion. 
&lt;/div&gt;
&lt;h1 class=&quot;Section&quot;&gt;
&lt;a class=&quot;toc&quot; name=&quot;toc-Section-2&quot;&gt;2&lt;/a&gt; Variations of the Gate Functions for LSTMs
&lt;/h1&gt;
&lt;h2 class=&quot;Subsection&quot;&gt;
&lt;a class=&quot;toc&quot; name=&quot;toc-Subsection-2.1&quot;&gt;2.1&lt;/a&gt; Recap: LSTM Formulation - The Use of Gates
&lt;/h2&gt;
&lt;div class=&quot;Unindented&quot;&gt;
LSTM layer is a recurrent layer that keeps a memory vector &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\mathbf{c}^{\left(t\right)}
&lt;/script&gt;
&lt;/span&gt; for any time step &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
t
&lt;/script&gt;
&lt;/span&gt;. Upon receiving the current time-step input &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\mathbf{x}^{\left(t\right)}
&lt;/script&gt;
&lt;/span&gt; and the output from previous time-step &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\mathbf{h}^{\left(t-1\right)}
&lt;/script&gt;
&lt;/span&gt;, the layer computes gate activations &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
f^{\left(t\right)},i^{\left(t\right)},o^{\left(t\right)}
&lt;/script&gt;
&lt;/span&gt; by applying a the corresponding gate function &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\mathbf{f},\mathbf{i},\mathbf{o}\in\mathcal{S}_{sig}
&lt;/script&gt;
&lt;/span&gt; on the tuple &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\left(\mathbf{x}^{\left(t\right)},\mathbf{h}^{\left(t-1\right)}\right)
&lt;/script&gt;
&lt;/span&gt;, note that these activations are vectors in &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\left[0,1\right]^{m}
&lt;/script&gt;
&lt;/span&gt;. 
&lt;/div&gt;
&lt;div class=&quot;Indented&quot;&gt;
A new memory-vector is then being computed by &lt;span class=&quot;MathJax_Preview&quot;&gt;
&lt;script type=&quot;math/tex;mode=display&quot;&gt;

\mathbf{c}^{\left(t\right)}=f^{\left(t\right)}\circ\mathbf{c}^{\left(t-1\right)}+i^{\left(t\right)}\circ\mathbf{s}\left(\mathbf{x}^{\left(t\right)},\mathbf{h}^{\left(t-1\right)}\right)

&lt;/script&gt;
&lt;/span&gt;
 where &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\circ
&lt;/script&gt;
&lt;/span&gt; is element-wise multiplication and &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\mathbf{s}\in\mathcal{S}_{tanh}
&lt;/script&gt;
&lt;/span&gt; is the state-transition function. The layer then outputs &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\mathbf{h}^{\left(t\right)}=o^{\left(t\right)}\circ tanh\left(\mathbf{c}^{\left(t\right)}\right)
&lt;/script&gt;
&lt;/span&gt;. 
&lt;/div&gt;
&lt;div class=&quot;Indented&quot;&gt;
The gate functions are of great importance for LSTM layer, they are what allow the layer to learn short and long term dependencies, and they also help avoiding the &lt;i&gt;exploding and vanishing gradients problem&lt;/i&gt;.
&lt;/div&gt;
&lt;h2 class=&quot;Subsection&quot;&gt;
&lt;a class=&quot;toc&quot; name=&quot;toc-Subsection-2.2&quot;&gt;2.2&lt;/a&gt; Simple Variations
&lt;/h2&gt;
&lt;div class=&quot;Unindented&quot;&gt;
The more expressive power a gate function have, the better it can learn short \ long term dependencies. That is, if a gate function is very rich, it can account for subtle changes in the input &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\mathbf{x}^{\left(t\right)}
&lt;/script&gt;
&lt;/span&gt; as well to subtle changes in the “past”, i.e. in &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\mathbf{h}^{\left(t-1\right)}
&lt;/script&gt;
&lt;/span&gt;. One way to enrich a gate function is by making it depends on the previous memory vector &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\mathbf{c}^{\left(t-1\right)}
&lt;/script&gt;
&lt;/span&gt; in addition to the regular tuple &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\left(\mathbf{x}^{\left(t\right)},\mathbf{h}^{\left(t-1\right)}\right)
&lt;/script&gt;
&lt;/span&gt;. That will redefine our gate functions family to be &lt;span class=&quot;MathJax_Preview&quot;&gt;
&lt;script type=&quot;math/tex;mode=display&quot;&gt;

\mathcal{S}_{\sigma}=\left\{ \mathbf{x}^{\left(t\right)},\mathbf{h}^{\left(t-1\right)},\mathbf{c}^{\left(t-1\right)}\mapsto\sigma\left(W\mathbf{x}^{\left(t\right)}+U\mathbf{h}^{\left(t-1\right)}+V\mathbf{c}^{\left(t-1\right)}+\mathbf{b}\right)\right\} 

&lt;/script&gt;
&lt;/span&gt;
for any &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
W,U
&lt;/script&gt;
&lt;/span&gt; and diagonal &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
V
&lt;/script&gt;
&lt;/span&gt;. Such construction can be found in &lt;a class=&quot;URL&quot; href=&quot;https://arxiv.org/abs/1308.0850&quot;&gt;here&lt;/a&gt;, note that we can think of &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
V\mathbf{c}^{\left(t-1\right)}
&lt;/script&gt;
&lt;/span&gt; as a bias vector that is memory-dependent, thus there are formulation in which the vector &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\mathbf{b}
&lt;/script&gt;
&lt;/span&gt; is omitted. 
&lt;/div&gt;
&lt;h2 class=&quot;Subsection&quot;&gt;
&lt;a class=&quot;toc&quot; name=&quot;toc-Subsection-2.3&quot;&gt;2.3&lt;/a&gt; Multiplicative LSTMs
&lt;/h2&gt;
&lt;div class=&quot;Unindented&quot;&gt;
In &lt;a class=&quot;URL&quot; href=&quot;https://arxiv.org/abs/1609.07959&quot;&gt;this paper&lt;/a&gt; from October 2016, the authors took that idea one step further. They wanted to make a unique gate function for each possible input. Recall that any function in &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\mathcal{S}_{\sigma}
&lt;/script&gt;
&lt;/span&gt; is of the form &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\mathbf{x}^{\left(t\right)},\mathbf{h}^{\left(t-1\right)}\mapsto W\mathbf{x}^{\left(t\right)}+U\mathbf{h}^{\left(t-1\right)}+\mathbf{b}
&lt;/script&gt;
&lt;/span&gt;. For simplicity, consider the case where &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\mathbf{b}=\mathbf{0}
&lt;/script&gt;
&lt;/span&gt;. 
&lt;/div&gt;
&lt;div class=&quot;Indented&quot;&gt;
We end up with a sum of two components: one that depends on the current input and one that depends on the past (i.e. &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\mathbf{h}^{\left(t-1\right)}
&lt;/script&gt;
&lt;/span&gt; which encodes information about previous time steps), and the component with larger magnitude will dominate the transition. If &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
W\mathbf{x}^{\left(t\right)}
&lt;/script&gt;
&lt;/span&gt; is larger, the layer will not be sensitive enough to the past, and if &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
U\mathbf{h}^{\left(t-1\right)}
&lt;/script&gt;
&lt;/span&gt; is larger, then the layer will not be sensitive to subtle changes in the input.
&lt;/div&gt;
&lt;div class=&quot;Indented&quot;&gt;
The author noted that since in most cases the input &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\mathbf{x}^{\left(t\right)}
&lt;/script&gt;
&lt;/span&gt; is an 1-hot vector, then multiply by &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
W
&lt;/script&gt;
&lt;/span&gt; is just selecting a specific column. So we may think of any gate function &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\mathbf{s}\in\mathcal{S}_{\sigma}
&lt;/script&gt;
&lt;/span&gt; as a &lt;b&gt;fixed&lt;/b&gt; base affine transformation &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\mathbf{h}\mapsto U\mathbf{h}
&lt;/script&gt;
&lt;/span&gt; combined with input-dependent bias vector &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\mathbf{b}_{\mathbf{x}^{\left(t\right)}}=W\mathbf{x}^{\left(t\right)}
&lt;/script&gt;
&lt;/span&gt;. That is &lt;span class=&quot;MathJax_Preview&quot;&gt;
&lt;script type=&quot;math/tex;mode=display&quot;&gt;

\mathbf{s}\left(\mathbf{x}^{\left(t\right)},\mathbf{h}^{\left(t-1\right)}\right)=U\mathbf{h}^{\left(t-1\right)}+\mathbf{b}_{\mathbf{x}^{\left(t\right)}}

&lt;/script&gt;
&lt;/span&gt;
that formula emphasis the &lt;i&gt;additive&lt;/i&gt; effect of the current input-vector on the transition of &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\mathbf{h}^{\left(t-1\right)}
&lt;/script&gt;
&lt;/span&gt;. 
&lt;/div&gt;
&lt;div class=&quot;Indented&quot;&gt;
The goal in multiplicative LSTM (mLSTM), is to have an &lt;b&gt;unique&lt;/b&gt; affine transformation (in our case, unique matrix &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
U
&lt;/script&gt;
&lt;/span&gt;) for each possible input. Obviously, if the number of possible inputs is very large, the number of the parameters will explode and it won’t be feasible to train the network. To overcome that, the authors of the paper suggested to learn &lt;i&gt;shared&lt;/i&gt; intermediate matrices that will be used to construct an unique &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
U
&lt;/script&gt;
&lt;/span&gt; for each input, and because the factorization is shared, there are less parameters to learn. 
&lt;/div&gt;
&lt;div class=&quot;Indented&quot;&gt;
The factorization is defined as follow: the unique matrix &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
U_{\mathbf{x}^{\left(t\right)}}
&lt;/script&gt;
&lt;/span&gt; is constructed by &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
V_{1}diag\left(T\mathbf{x}^{\left(t\right)}\right)V_{2}
&lt;/script&gt;
&lt;/span&gt; where &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
V_{1},V_{2}
&lt;/script&gt;
&lt;/span&gt; and &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
T
&lt;/script&gt;
&lt;/span&gt; are intermediate matrices which are shared across all the possible inputs, and &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
diag\left(\mathbf{v}\right)
&lt;/script&gt;
&lt;/span&gt; is an operation that maps any vector &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\mathbf{v}
&lt;/script&gt;
&lt;/span&gt; to a square diagonal matrix with the elements of &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\mathbf{v}
&lt;/script&gt;
&lt;/span&gt; on its diagonal.
&lt;/div&gt;
&lt;div class=&quot;Indented&quot;&gt;
Note that the target dimension of &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
T
&lt;/script&gt;
&lt;/span&gt; may be arbitrarily large (in the paper they chose it to be the same as &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\mathbf{h}^{\left(t\right)}
&lt;/script&gt;
&lt;/span&gt;).
&lt;/div&gt;
&lt;div class=&quot;Indented&quot;&gt;
The difference between LSTM and mLSTM is only in the definition of the gate functions family, all the equations for updating the memory cell and the output are the same. In mLSTM the family &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\mathcal{S}_{\sigma}
&lt;/script&gt;
&lt;/span&gt; is being replaced with &lt;span class=&quot;MathJax_Preview&quot;&gt;
&lt;script type=&quot;math/tex;mode=display&quot;&gt;
\begin{aligned}
\mathcal{S}'_{\sigma} &amp; =\left\{ \mathbf{x},\mathbf{h}\mapsto\sigma\left(W\mathbf{x}+U_{\mathbf{x}}\mathbf{h}\right)\right\} \\
 &amp; =\left\{ \mathbf{x},\mathbf{h}\mapsto\sigma\left(\mathbf{b}_{\mathbf{x}}+V_{1}diag\left(T\mathbf{x}\right)V_{2}\mathbf{h}\right)\mid\forall W,V_{1},V_{2},T\right\} 
\end{aligned}
&lt;/script&gt;
&lt;/span&gt;
Note that we can reduce the number of parameters even further by forcing all the gate functions to use the same &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
V_{2}
&lt;/script&gt;
&lt;/span&gt; and &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
T
&lt;/script&gt;
&lt;/span&gt; matrices. That is, each gate will be parametrized only by &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
W
&lt;/script&gt;
&lt;/span&gt; and &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
V_{1}
&lt;/script&gt;
&lt;/span&gt;. 
&lt;/div&gt;
&lt;div class=&quot;Indented&quot;&gt;
Formally, define the following transformation &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\tau:\mathbb{R}^{n}\times\mathbb{R}^{n}\to\mathbb{R}^{m}
&lt;/script&gt;
&lt;/span&gt; such that &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\tau\left(\mathbf{x},\mathbf{h}\right)=T\mathbf{x}\circ V_{2}\mathbf{h}
&lt;/script&gt;
&lt;/span&gt; and then we can define &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\mathcal{S}'_{\sigma}
&lt;/script&gt;
&lt;/span&gt; for some fixed learned transformation &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\tau
&lt;/script&gt;
&lt;/span&gt; as &lt;span class=&quot;MathJax_Preview&quot;&gt;
&lt;script type=&quot;math/tex;mode=display&quot;&gt;
\begin{aligned}
\mathcal{S}'_{\sigma,\tau} &amp; =\left\{ \mathbf{x},\mathbf{h}\mapsto\sigma\left(W\mathbf{x}+V_{1}\tau\left(\mathbf{x},\mathbf{h}\right)\right)\mid\forall W,V_{1}\right\} \\
 &amp; =\left\{ \mathbf{x},\mathbf{h}\mapsto\mathbf{s}\left(\mathbf{x},\tau\left(\mathbf{x},\mathbf{h}\right)\right)\mid\mathbf{s}\in\mathcal{S}_{\sigma}\right\} 
\end{aligned}
&lt;/script&gt;
&lt;/span&gt;
 in other words, mLSTM is an LSTM that apply its gates to the tuple &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\left(\mathbf{x}^{\left(t\right)},\tau\left(\mathbf{x}^{\left(t\right)},\mathbf{h}^{\left(t-1\right)}\right)\right)
&lt;/script&gt;
&lt;/span&gt; rather than &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\left(\mathbf{x}^{\left(t\right)},\mathbf{h}^{\left(t-1\right)}\right)
&lt;/script&gt;
&lt;/span&gt;, and &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\tau
&lt;/script&gt;
&lt;/span&gt; is another learned transformation. If you look again at the exact formula of &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\tau
&lt;/script&gt;
&lt;/span&gt; you will see the &lt;i&gt;multiplicative&lt;/i&gt; effect of the input vector on the transformation of &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\mathbf{h}
&lt;/script&gt;
&lt;/span&gt;. That way, the authors said, &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\mathcal{S}'_{\sigma,\tau}
&lt;/script&gt;
&lt;/span&gt; can yield much richer family of input-dependent transformations for &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\mathbf{h}^{\left(t\right)}
&lt;/script&gt;
&lt;/span&gt;, which can be sensitive to the past as well as to subtle changes in the current input.
&lt;/div&gt;
&lt;h1 class=&quot;Section&quot;&gt;
&lt;a class=&quot;toc&quot; name=&quot;toc-Section-3&quot;&gt;3&lt;/a&gt; Recurrent Batch Normalization
&lt;/h1&gt;
&lt;div class=&quot;Unindented&quot;&gt;
Batch normalization is an operator applied to a layer before going through the non-linearity function in order to “normalize” the values before activation. That operator has two hyper-parameters for tuning and two statistics that it accumulates internally. Formally, given a vector of pre-activation values &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\mathbf{x}
&lt;/script&gt;
&lt;/span&gt;, batch-normalization is &lt;span class=&quot;MathJax_Preview&quot;&gt;
&lt;script type=&quot;math/tex;mode=display&quot;&gt;

BN\left(\mathbf{x};\gamma,\beta\right)=\beta+\gamma\circ\frac{\mathbf{x}-\mathbb{\hat{E}\left[\mathbf{x}\right]}}{\sqrt{\hat{\mathbb{V}}\left[\mathbf{x}\right]+\epsilon}}

&lt;/script&gt;
&lt;/span&gt;
where &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\hat{\mathbb{E}}
&lt;/script&gt;
&lt;/span&gt; and &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\hat{\mathbb{V}}
&lt;/script&gt;
&lt;/span&gt; are the empirical mean and variance of the current batch respectively. &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\gamma,\beta
&lt;/script&gt;
&lt;/span&gt; and &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\epsilon
&lt;/script&gt;
&lt;/span&gt; are vectors, and the division in the operator is being computed element-wise. Note that at inference time, the population statistics are estimated by averaging the empirical statistics across all the batches.
&lt;/div&gt;
&lt;div class=&quot;Indented&quot;&gt;
&lt;a class=&quot;URL&quot; href=&quot;https://arxiv.org/abs/1603.09025&quot;&gt;That paper&lt;/a&gt; from February 2017, applied batch normalization also to the &lt;i&gt;recurrent connections&lt;/i&gt; in LSTM layers, and they showed empirically that it helped the network to converge faster. The usage is simple, each gate function &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\mathbf{i},\mathbf{f},\mathbf{o}\in\mathcal{S}_{sig}
&lt;/script&gt;
&lt;/span&gt; and the transition function &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\mathbf{s}\in\mathcal{S}_{tanh}
&lt;/script&gt;
&lt;/span&gt; computes &lt;span class=&quot;MathJax_Preview&quot;&gt;
&lt;script type=&quot;math/tex;mode=display&quot;&gt;

\mathbf{x}^{\left(t\right)},\mathbf{h}^{\left(t-1\right)}\mapsto\sigma\left(BN\left(W\mathbf{h}^{\left(t-1\right)};\gamma_{h},\beta_{h}\right)+BN\left(W\mathbf{x}^{\left(t\right)};\gamma_{x},\beta_{x}\right)+\mathbf{b}\right)

&lt;/script&gt;
&lt;/span&gt;
 when the hyper-parameters &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\gamma
&lt;/script&gt;
&lt;/span&gt; and &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\beta
&lt;/script&gt;
&lt;/span&gt; are shared across different gates. Then the output of the layer is &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\mathbf{h}^{\left(t\right)}=o^{\left(t\right)}\circ tanh\left(BN\left(\mathbf{c}^{\left(t\right)};\gamma_{c},\beta_{c}\right)\right)
&lt;/script&gt;
&lt;/span&gt;. The authors suggested to set &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\beta_{x}=\beta_{h}=\mathbf{0}
&lt;/script&gt;
&lt;/span&gt; because there is already a bias parameter &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\mathbf{b}
&lt;/script&gt;
&lt;/span&gt; and to prevent redundancy. In addition, they said that sharing the internal &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
BN
&lt;/script&gt;
&lt;/span&gt; statistics across time degrades performance severely. Therefore, one should use “fresh” &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
BN
&lt;/script&gt;
&lt;/span&gt; operators for each time-step with their own internal statistics (but share the &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\beta
&lt;/script&gt;
&lt;/span&gt; and &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\gamma
&lt;/script&gt;
&lt;/span&gt; parameters).
&lt;/div&gt;
&lt;h1 class=&quot;Section&quot;&gt;
&lt;a class=&quot;toc&quot; name=&quot;toc-Section-4&quot;&gt;4&lt;/a&gt; The Ever-growing Field
&lt;/h1&gt;
&lt;div class=&quot;Unindented&quot;&gt;
RNNs is a rapidly growing field and this series only covers a small part of it. There are much more advanced models, some of them are only from few months ago. If you are interested in this field, you may find very interesting stuff &lt;a class=&quot;URL&quot; href=&quot;https://smerity.com/articles/2016/iclr_2017_submissions.html&quot;&gt;here&lt;/a&gt;. 
&lt;/div&gt;</content><author><name>Eran Amar</name></author><category term="neural_networks" /><summary type="html">Warning: MathJax requires JavaScript to correctly process the mathematics on this page. Please enable JavaScript on your browser. &amp;lt;/hr&amp;gt;</summary></entry><entry><title type="html">Recurrent Neural Network - Dropout for LSTMs</title><link href="https://eranamar.github.io/site/2017/05/12/Recurrent-Neural-Network-Dropout-for-LSTMs.html" rel="alternate" type="text/html" title="Recurrent Neural Network - Dropout for LSTMs" /><published>2017-05-12T00:00:00+03:00</published><updated>2017-05-12T00:00:00+03:00</updated><id>https://eranamar.github.io/site/2017/05/12/Recurrent-Neural-Network---Dropout-for-LSTMs</id><content type="html" xml:base="https://eranamar.github.io/site/2017/05/12/Recurrent-Neural-Network-Dropout-for-LSTMs.html">&lt;script type=&quot;math/tex&quot;&gt;
\newcommand{\lyxlock}{}
&lt;/script&gt;

&lt;noscript&gt;
&lt;div class=&quot;warning&quot;&gt;
Warning: &lt;a href=&quot;http://www.mathjax.org/&quot;&gt;MathJax&lt;/a&gt; requires JavaScript to correctly process the mathematics on this page. Please enable JavaScript on your browser.
&lt;/div&gt;&lt;hr /&gt;
&amp;lt;/hr&amp;gt;&lt;/noscript&gt;

&lt;h1 class=&quot;Section&quot;&gt;
&lt;a class=&quot;toc&quot; name=&quot;toc-Section-1&quot;&gt;1&lt;/a&gt; Recap
&lt;/h1&gt;
&lt;div class=&quot;Unindented&quot;&gt;
This is the third post in the series about Recurrent Neural Networks. The &lt;a class=&quot;URL&quot; href=&quot;https://eranamar.github.io/site/2017/04/20/Recurrent-Neural-Network-Introduction.html&quot;&gt;first post &lt;/a&gt;defined the basic notations and the formulation of a Recurrent Cell, the &lt;a class=&quot;URL&quot; href=&quot;https://eranamar.github.io/site/2017/04/30/Recurrent-Neural-Network-LSTM-and-GRU.html&quot;&gt;second post&lt;/a&gt; discussed its extensions such as LSTM and GRU. Recall that LSTM layer receives vector &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\mathbf{x}^{\left(t\right)}
&lt;/script&gt;
&lt;/span&gt; - the input for the current time step &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
t
&lt;/script&gt;
&lt;/span&gt;, and &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\mathbf{c}^{\left(t-1\right)},\mathbf{h}^{\left(t-1\right)}
&lt;/script&gt;
&lt;/span&gt; the memory-vector and the output-vector from previous time-step respectively, then the layer computes a new memory vector &lt;span class=&quot;MathJax_Preview&quot;&gt;
&lt;script type=&quot;math/tex;mode=display&quot;&gt;

\mathbf{c}^{\left(t\right)}=\mathbf{f}\left(\mathbf{x}^{\left(t\right)},\mathbf{h}^{\left(t-1\right)}\right)\circ\mathbf{c}^{\left(t-1\right)}+\mathbf{i}\left(\mathbf{x}^{\left(t\right)},\mathbf{h}^{\left(t-1\right)}\right)\circ\mathbf{s}\left(\mathbf{x}^{\left(t\right)},\mathbf{h}^{\left(t-1\right)}\right)

&lt;/script&gt;
&lt;/span&gt;
where &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\circ
&lt;/script&gt;
&lt;/span&gt; denotes element wise multiplication. Then the layer outputs &lt;span class=&quot;MathJax_Preview&quot;&gt;
&lt;script type=&quot;math/tex;mode=display&quot;&gt;

\mathbf{h}^{\left(t\right)}=\mathbf{o}\left(\mathbf{x}^{\left(t\right)},\mathbf{h}^{\left(t-1\right)}\right)\circ tanh\left(\mathbf{c}^{\left(t\right)}\right)

&lt;/script&gt;
&lt;/span&gt;
where &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\mathbf{f},\mathbf{i},\mathbf{o}\in\mathcal{S}_{sigmoid}
&lt;/script&gt;
&lt;/span&gt; are the &lt;i&gt;forget&lt;/i&gt;, &lt;i&gt;input&lt;/i&gt; and &lt;i&gt;output&lt;/i&gt; gates respectively, and &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\mathbf{s}\in\mathcal{S}_{tanh}
&lt;/script&gt;
&lt;/span&gt; is the state transition function. &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\mathcal{S}_{\sigma}
&lt;/script&gt;
&lt;/span&gt; denotes a family of all affine transformations &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\mathbb{R}^{n}\times\mathbb{R}^{n}\to\mathbb{R}^{m}
&lt;/script&gt;
&lt;/span&gt; following by an element-wise activation function &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\sigma
&lt;/script&gt;
&lt;/span&gt;, for any input-dimension &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
n
&lt;/script&gt;
&lt;/span&gt; and output-dimension &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
m
&lt;/script&gt;
&lt;/span&gt;.
&lt;/div&gt;
&lt;div class=&quot;Indented&quot;&gt;
In this post, we will focus on the different variants of dropout regularization that are being used in LSTM networks. 
&lt;/div&gt;
&lt;h1 class=&quot;Section&quot;&gt;
&lt;a class=&quot;toc&quot; name=&quot;toc-Section-2&quot;&gt;2&lt;/a&gt; Dropout Regularization
&lt;/h1&gt;
&lt;div class=&quot;Unindented&quot;&gt;
Dropout is a very popular regularization mechanism that is being attached to layers of a neural network in order to reduce overfitting and improve generalization. Applying dropout to a layer starts by fixing some &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
p\in\left(0,1\right)
&lt;/script&gt;
&lt;/span&gt;. Then, any time that layer produces an output during training, each one of its neurons is being zeroed-out independently with probability &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
p
&lt;/script&gt;
&lt;/span&gt;, and with probability &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
1-p
&lt;/script&gt;
&lt;/span&gt; it is being scaled by &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\frac{1}{1-p}
&lt;/script&gt;
&lt;/span&gt;. Scaling the output is important because it keeps the expected output-value of the neuron unchanged. During test time, the dropout mechanism is being turned-off, that is, the output of each neuron is being passed as is. 
&lt;/div&gt;
&lt;div class=&quot;Indented&quot;&gt;
For fully-connected layers, we can formulate dropout as follows: Suppose that &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\mathbf{h}
&lt;/script&gt;
&lt;/span&gt; should be the output of some layer that has dropout mechanism. Generate a mask &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\mathbf{z}\in\left\{ 0,1\right\} ^{n}
&lt;/script&gt;
&lt;/span&gt;, by picking each coordinate i.i.d w.p. &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
p
&lt;/script&gt;
&lt;/span&gt; from &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\left\{ 0,1\right\} 
&lt;/script&gt;
&lt;/span&gt;, and output &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\mathbf{h}\circ\mathbf{z}
&lt;/script&gt;
&lt;/span&gt; instead of &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\mathbf{h}
&lt;/script&gt;
&lt;/span&gt;. Note that we hide here the output-scaling for simplicity, and that the mask &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\mathbf{z}
&lt;/script&gt;
&lt;/span&gt; is being generated any time the layer required to produce an output. 
&lt;/div&gt;
&lt;div class=&quot;Indented&quot;&gt;
At first glance it seems trivial to apply dropout to LSTM layers. However, when we come to implement the mechanism we encounter some technical issues that should be addressed. For instance, we need to decide whether to apply the given mask only to the input &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\mathbf{x}^{\left(t\right)}
&lt;/script&gt;
&lt;/span&gt; or also to the recurrent connection (i.e. to &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\mathbf{h}^{\left(t-1\right)}
&lt;/script&gt;
&lt;/span&gt;), and if we choose to apply on both, should it be the same mask or different masks? Should a mask be shared &lt;i&gt;across time&lt;/i&gt; or be generated for each time-step?
&lt;/div&gt;
&lt;div class=&quot;Indented&quot;&gt;
Several works tried to apply dropout to LSTM layers in several naive ways but without success. It seems that just dropping randomly some coordinates from the recurrent connections &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\mathbf{h}^{\left(t-1\right)}
&lt;/script&gt;
&lt;/span&gt; impair the ability of the LSTM layer to learn long\short term dependencies and does not improve generalization. In the next section we will review some works that applied dropout to LSTMs in a way that successfully yields better generalization. 
&lt;/div&gt;
&lt;h1 class=&quot;Section&quot;&gt;
&lt;a class=&quot;toc&quot; name=&quot;toc-Section-3&quot;&gt;3&lt;/a&gt; Variants
&lt;/h1&gt;
&lt;h2 class=&quot;Subsection&quot;&gt;
&lt;a class=&quot;toc&quot; name=&quot;toc-Subsection-3.1&quot;&gt;3.1&lt;/a&gt; Mask Only Inputs; Regenerate Masks
&lt;/h2&gt;
&lt;div class=&quot;Unindented&quot;&gt;
Wojciech Zaremba, Ilya Sutskever and Oriol Vinyals published in 2014 a &lt;a class=&quot;URL&quot; href=&quot;https://arxiv.org/abs/1409.2329v5&quot;&gt;paper&lt;/a&gt; that describe a successful dropout variation for LSTM layers. Their idea was that dropout should be applied only to the inputs of the layer and not to the recurrent connections. Moreover, a new mask should be generated for each time step. 
&lt;/div&gt;
&lt;div class=&quot;Indented&quot;&gt;
Formally, for each time-step &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
t
&lt;/script&gt;
&lt;/span&gt;, generate a mask &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\mathbf{z}^{\left(t\right)}
&lt;/script&gt;
&lt;/span&gt; and compute &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\mathbf{\hat{x}}^{\left(t\right)}:=\mathbf{x}^{\left(t\right)}\circ\mathbf{z}^{\left(t\right)}
&lt;/script&gt;
&lt;/span&gt;. Then continue to compute the LSTM layer as usual but use &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\mathbf{\hat{x}}^{\left(t\right)}
&lt;/script&gt;
&lt;/span&gt; as the input to the layer rather than &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\mathbf{x}^{\left(t\right)}
&lt;/script&gt;
&lt;/span&gt;. 
&lt;/div&gt;
&lt;h2 class=&quot;Subsection&quot;&gt;
&lt;a class=&quot;toc&quot; name=&quot;toc-Subsection-3.2&quot;&gt;3.2&lt;/a&gt; rnnDrop: Mask Only the Memory; Fixed Mask
&lt;/h2&gt;
&lt;div class=&quot;Unindented&quot;&gt;
On 2015, Taesup Moon, Heeyoul Choi, Hoshik Lee and Inchul Song &lt;a class=&quot;URL&quot; href=&quot;https://www.stat.berkeley.edu/~tsmoon/files/Conference/asru2015.pdf&quot;&gt;published&lt;/a&gt; a different dropout variation: &lt;i&gt;rnnDrop&lt;/i&gt;. 
&lt;/div&gt;
&lt;div class=&quot;Indented&quot;&gt;
They suggested to generate a mask for each training sequence and fix it for all the time-steps in that sequence, that is, the mask is being &lt;i&gt;shared across time&lt;/i&gt;. The mask is then being applied to the &lt;i&gt;memory vector&lt;/i&gt; of the layer rather than the input. In their formulation, only the second formula of the LSTM changed: &lt;span class=&quot;MathJax_Preview&quot;&gt;
&lt;script type=&quot;math/tex;mode=display&quot;&gt;

\mathbf{h}^{\left(t\right)}=\mathbf{o}\left(\mathbf{x}^{\left(t\right)},\mathbf{h}^{\left(t-1\right)}\right)\circ tanh\left(\mathbf{c}^{\left(t\right)}\circ\mathbf{z}\right)

&lt;/script&gt;
&lt;/span&gt;
where &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\mathbf{z}
&lt;/script&gt;
&lt;/span&gt; if the fixed mask to the entire current training sequence.
&lt;/div&gt;
&lt;h2 class=&quot;Subsection&quot;&gt;
&lt;a class=&quot;toc&quot; name=&quot;toc-Subsection-3.3&quot;&gt;3.3&lt;/a&gt; Mask Input and Hidden; Fixed Mask
&lt;/h2&gt;
&lt;div class=&quot;Unindented&quot;&gt;
A relatively &lt;a class=&quot;URL&quot; href=&quot;https://arxiv.org/abs/1512.05287&quot;&gt;recent work&lt;/a&gt; of Yarin Gal and Zoubin Ghahramani from 2016 also use a make that is shared across time, however it is being applied to the inputs as well on the &lt;i&gt;recurrent connections&lt;/i&gt;. This is one of the first successful dropout variants that actually apply the mask to the recurrent connection. 
&lt;/div&gt;
&lt;div class=&quot;Indented&quot;&gt;
Formally, for each training sequence generate two masks &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\mathbf{z}_{1},\mathbf{z}_{2}
&lt;/script&gt;
&lt;/span&gt; and compute &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\mathbf{\hat{x}}^{\left(t\right)}:=\mathbf{x}^{\left(t\right)}\circ\mathbf{z}_{1}
&lt;/script&gt;
&lt;/span&gt; and &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\mathbf{\hat{h}}^{\left(t-1\right)}:=\mathbf{h}^{\left(t-1\right)}\circ\mathbf{z}_{2}
&lt;/script&gt;
&lt;/span&gt;. Then use &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\mathbf{\hat{x}}^{\left(t\right)},\mathbf{\hat{h}}^{\left(t-1\right)}
&lt;/script&gt;
&lt;/span&gt; as the input to the “regular” LSTM layer.
&lt;/div&gt;
&lt;h2 class=&quot;Subsection&quot;&gt;
&lt;a class=&quot;toc&quot; name=&quot;toc-Subsection-3.4&quot;&gt;3.4&lt;/a&gt; Mask Gates; Fixed Mask
&lt;/h2&gt;
&lt;div class=&quot;Unindented&quot;&gt;
Another &lt;a class=&quot;URL&quot; href=&quot;https://arxiv.org/abs/1603.05118&quot;&gt;paper&lt;/a&gt; from 2016, of Stanislau Semeniuta, Aliaksei Severyn and Erhardt Barth demonstrate the mask being applied to some of the &lt;i&gt;gates&lt;/i&gt; rather than the input\hidden vectors. For any time-step, generate &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\mathbf{z}^{\left(t\right)}
&lt;/script&gt;
&lt;/span&gt; and then use it to mask the &lt;i&gt;input gate&lt;/i&gt;&lt;span class=&quot;MathJax_Preview&quot;&gt;
&lt;script type=&quot;math/tex;mode=display&quot;&gt;

\mathbf{c}^{\left(t\right)}=\mathbf{f}\left(\mathbf{x}^{\left(t\right)},\mathbf{h}^{\left(t-1\right)}\right)\circ\mathbf{c}^{\left(t-1\right)}+\mathbf{z}^{\left(t\right)}\circ\mathbf{i}\left(\mathbf{x}^{\left(t\right)},\mathbf{h}^{\left(t-1\right)}\right)\circ\mathbf{s}\left(\mathbf{x}^{\left(t\right)},\mathbf{h}^{\left(t-1\right)}\right)

&lt;/script&gt;
&lt;/span&gt;
and the second LSTM equation left unchanged. 
&lt;/div&gt;
&lt;div class=&quot;Indented&quot;&gt;
Small note, the authors also addressed in their paper some issues related to scaling the not-dropped coordinates, which won’t be covered here.
&lt;/div&gt;
&lt;h2 class=&quot;Subsection&quot;&gt;
&lt;a class=&quot;toc&quot; name=&quot;toc-Subsection-3.5&quot;&gt;3.5&lt;/a&gt; Zoneout
&lt;/h2&gt;
&lt;div class=&quot;Unindented&quot;&gt;
The very last dropout variation (to the day I wrote this post) is by &lt;a class=&quot;URL&quot; href=&quot;https://arxiv.org/abs/1606.01305&quot;&gt;David Krueger et al&lt;/a&gt;, from 2017. They suggested to treat the memory vector &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\mathbf{c}^{\left(t\right)}
&lt;/script&gt;
&lt;/span&gt; and the output vector (a.k.a &lt;i&gt;hidden&lt;/i&gt; vector) &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\mathbf{h}^{\left(t\right)}
&lt;/script&gt;
&lt;/span&gt; as follows: each coordinate in each of the vectors either being updated as usual or &lt;i&gt;preserved its value&lt;/i&gt; from previous time-step. As opposed to regular dropout, where “dropping a coordinate” meaning to make it zero, in zoneout it just keeps its previous value - acting as a random identity map that allows better gradients propagation through more time steps. Note that preserving a coordinate in the memory vector should not affect the computation of the hidden vector. Therefore we have to rewrite the formulas for the LSTM layer: given &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\mathbf{x}^{\left(t\right)},\mathbf{h}^{\left(t-1\right)}
&lt;/script&gt;
&lt;/span&gt; and &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\mathbf{c}^{\left(t-1\right)}
&lt;/script&gt;
&lt;/span&gt;. Generate two masks &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\mathbf{z}_{1}^{\left(t\right)},\mathbf{z}_{2}^{\left(t\right)}
&lt;/script&gt;
&lt;/span&gt; for the current time-step &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
t
&lt;/script&gt;
&lt;/span&gt;. Start by computing a candidate memory-vector with the regular formula, &lt;span class=&quot;MathJax_Preview&quot;&gt;
&lt;script type=&quot;math/tex;mode=display&quot;&gt;

\mathbf{\hat{c}}^{\left(t\right)}=\mathbf{f}\left(\mathbf{x}^{\left(t\right)},\mathbf{h}^{\left(t-1\right)}\right)\circ\mathbf{c}^{\left(t-1\right)}+\mathbf{i}\left(\mathbf{x}^{\left(t\right)},\mathbf{h}^{\left(t-1\right)}\right)\circ\mathbf{s}\left(\mathbf{x}^{\left(t\right)},\mathbf{h}^{\left(t-1\right)}\right)

&lt;/script&gt;
&lt;/span&gt;
and then use only &lt;i&gt;some&lt;/i&gt; of its coordinates to update the memory-vector, that is, &lt;span class=&quot;MathJax_Preview&quot;&gt;
&lt;script type=&quot;math/tex;mode=display&quot;&gt;

\mathbf{c}^{\left(t\right)}=\mathbf{z}_{1}^{\left(t\right)}\circ\mathbf{c}^{\left(t-1\right)}+\left(1-\mathbf{z}_{1}^{\left(t\right)}\right)\circ\mathbf{\hat{c}}^{\left(t\right)}

&lt;/script&gt;
&lt;/span&gt;
Similarly, for the hidden-vector, compute a candidate &lt;span class=&quot;MathJax_Preview&quot;&gt;
&lt;script type=&quot;math/tex;mode=display&quot;&gt;

\mathbf{\hat{h}}^{\left(t\right)}=\mathbf{o}\left(\mathbf{x}^{\left(t\right)},\mathbf{h}^{\left(t-1\right)}\right)\circ tanh\left(\mathbf{\hat{c}}^{\left(t\right)}\right)

&lt;/script&gt;
&lt;/span&gt;
and selectively update &lt;span class=&quot;MathJax_Preview&quot;&gt;
&lt;script type=&quot;math/tex;mode=display&quot;&gt;

\mathbf{h}^{\left(t\right)}=\mathbf{z}_{2}^{\left(t\right)}\circ\mathbf{h}^{\left(t-1\right)}+\left(1-\mathbf{z}_{2}^{\left(t\right)}\right)\circ\mathbf{\hat{h}}^{\left(t\right)}

&lt;/script&gt;
&lt;/span&gt;
Observe again that the computation of the candidate hidden-vector is based on &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\mathbf{\hat{c}}^{\left(t\right)}
&lt;/script&gt;
&lt;/span&gt; therefore unaffected by the mask &lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;
\mathbf{z}_{1}^{\left(t\right)}
&lt;/script&gt;
&lt;/span&gt;.
&lt;/div&gt;
&lt;h1 class=&quot;Section&quot;&gt;
&lt;a class=&quot;toc&quot; name=&quot;toc-Section-4&quot;&gt;4&lt;/a&gt; More and More and More
&lt;/h1&gt;
&lt;div class=&quot;Unindented&quot;&gt;
In the last year, dropout for LSTM networks gained more attention, and the list of different variants is growing quickly. This post tried to cover only &lt;i&gt;some&lt;/i&gt; fraction of all the variants available out there. It is left for the curious reader to search the literature for more about this topic. 
&lt;/div&gt;
&lt;div class=&quot;Indented&quot;&gt;
Note that some of the dropout variations discussed above can be applied to basic RNN and GRU cells without much modifications - please refer to the papers themselves for more details. 
&lt;/div&gt;
&lt;div class=&quot;Indented&quot;&gt;
Next post, I will discuss recent advancement in the field of RNNs, such as Multiplicative LSTMs, Recurrent Batch Normalization and more.
&lt;/div&gt;</content><author><name>Eran Amar</name></author><category term="neural_networks" /><summary type="html">Warning: MathJax requires JavaScript to correctly process the mathematics on this page. Please enable JavaScript on your browser. &amp;lt;/hr&amp;gt;</summary></entry></feed>